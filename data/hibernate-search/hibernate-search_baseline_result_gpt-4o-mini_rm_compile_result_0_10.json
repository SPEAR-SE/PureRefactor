[{"type": "Move Method", "description": "Move Method\tpublic assertThrown() : AbstractThrowableAssert<?,Throwable> from class org.hibernate.search.util.impl.test.SubTest to public assertThrown() : AbstractThrowableAssert<?,Throwable> from class org.hibernate.search.util.impl.test.SubTest.ExceptionThrowingSubTest", "diffLocations": [{"filePath": "util/internal/test/src/main/java/org/hibernate/search/util/impl/test/SubTest.java", "startLine": 67, "endLine": 70, "startColumn": 0, "endColumn": 0}, {"filePath": "util/internal/test/src/main/java/org/hibernate/search/util/impl/test/SubTest.java", "startLine": 86, "endLine": 89, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "public AbstractThrowableAssert<?, Throwable> assertThrown() {\n\t\treturn new ThrowableAssert( thrown )\n\t\t\t\t.as( description );\n\t}", "filePathBefore": "util/internal/test/src/main/java/org/hibernate/search/util/impl/test/SubTest.java", "isPureRefactoring": true, "commitId": "f50cbfc772b75e7d7a983359b9baca383bc6ae9f", "packageNameBefore": "org.hibernate.search.util.impl.test", "classNameBefore": "org.hibernate.search.util.impl.test.SubTest", "methodNameBefore": "org.hibernate.search.util.impl.test.SubTest#assertThrown", "classSignatureBefore": "public class SubTest ", "methodNameBeforeSet": ["org.hibernate.search.util.impl.test.SubTest#assertThrown"], "classNameBeforeSet": ["org.hibernate.search.util.impl.test.SubTest"], "classSignatureBeforeSet": ["public class SubTest "], "purityCheckResultList": [{"isPure": true, "purityComment": "Identical statements", "description": "There is no replacement! - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.util.impl.test;\n\nimport static org.junit.Assert.fail;\n\nimport java.util.concurrent.Callable;\n\nimport org.junit.Test;\n\nimport org.assertj.core.api.AbstractThrowableAssert;\nimport org.assertj.core.api.ThrowableAssert;\n\n/**\n * A util allowing to run blocks of code (\"sub-tests\"), expecting them to throw an exception.\n * <p>\n * Useful in particular when expecting an exception for each execution of a loop,\n * in which case {@link org.junit.rules.ExpectedException} or {@link Test#expected()} cannot be used.\n * <p>\n * By default any thrown exception will be accepted; if you want to run additional checks on the thrown exception,\n * use {@link #assertThrown()}.\n */\npublic class SubTest {\n\n\tpublic static SubTest expectException(Runnable runnable) {\n\t\treturn expectException( runnable.toString(), runnable );\n\t}\n\n\tpublic static SubTest expectException(String description, Runnable runnable) {\n\t\treturn expectException(\n\t\t\t\tdescription,\n\t\t\t\t() -> {\n\t\t\t\t\trunnable.run();\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t);\n\t}\n\n\tpublic static SubTest expectException(Callable<?> callable) {\n\t\treturn expectException( callable.toString(), callable );\n\t}\n\n\tpublic static SubTest expectException(String description, Callable<?> callable) {\n\t\ttry {\n\t\t\tcallable.call();\n\t\t\tfail( \"'\" + description + \"' should have thrown an exception\" );\n\t\t\tthrow new IllegalStateException( \"This should never happen\" );\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\treturn new SubTest( \"Exception thrown by '\" + description + \"'\", e );\n\t\t}\n\t}\n\n\tprivate final String description;\n\n\tprivate final Throwable thrown;\n\n\tprivate SubTest(String description, Throwable thrown) {\n\t\tthis.description = description;\n\t\tthis.thrown = thrown;\n\t}\n\n\tpublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n\t\treturn new ThrowableAssert( thrown )\n\t\t\t\t.as( description );\n\t}\n\n}\n", "filePathAfter": "util/internal/test/src/main/java/org/hibernate/search/util/impl/test/SubTest.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.util.impl.test;\n\nimport static org.junit.Assert.fail;\n\nimport java.util.concurrent.Callable;\n\nimport org.junit.Test;\n\nimport org.assertj.core.api.AbstractThrowableAssert;\nimport org.assertj.core.api.ThrowableAssert;\n\n/**\n * A util allowing to run blocks of code as \"sub-tests\".\n * <p>\n * This class is useful when looping over several executions of the same set of assertions:\n * <ul>\n *     <li>\n *         When executing code that both produces and consumes instances of a different generic type T\n *         for each execution of a loop,\n *         you usually cannot write type-safe code easily, because of limitations and how generics work,\n *         but you can with {@link #expectSuccess(Object, ParameterizedSubTest)}.\n *     </li>\n *     <li>\n *         When expecting an exception for each execution of a loop,\n *         you cannot use {@link org.junit.rules.ExpectedException} or {@link Test#expected()},\n *         but you can use {@link #expectException(String, Runnable)}.\n *         By default any thrown exception will be accepted; if you want to run additional checks on the thrown exception,\n *         use {@link ExceptionThrowingSubTest#assertThrown()}.\n *     </li>\n * </ul>\n */\npublic class SubTest {\n\n\tpublic static <T> void expectSuccess(T parameter, ParameterizedSubTest<T> subTest) {\n\t\tsubTest.test( parameter );\n\t}\n\n\tpublic static ExceptionThrowingSubTest expectException(Runnable runnable) {\n\t\treturn expectException( runnable.toString(), runnable );\n\t}\n\n\tpublic static ExceptionThrowingSubTest expectException(String description, Runnable runnable) {\n\t\treturn expectException(\n\t\t\t\tdescription,\n\t\t\t\t() -> {\n\t\t\t\t\trunnable.run();\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t);\n\t}\n\n\tpublic static ExceptionThrowingSubTest expectException(Callable<?> callable) {\n\t\treturn expectException( callable.toString(), callable );\n\t}\n\n\tpublic static ExceptionThrowingSubTest expectException(String description, Callable<?> callable) {\n\t\ttry {\n\t\t\tcallable.call();\n\t\t\tfail( \"'\" + description + \"' should have thrown an exception\" );\n\t\t\tthrow new IllegalStateException( \"This should never happen\" );\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\treturn new ExceptionThrowingSubTest( \"Exception thrown by '\" + description + \"'\", e );\n\t\t}\n\t}\n\n\tprivate SubTest() {\n\t}\n\n\tpublic static final class ExceptionThrowingSubTest {\n\t\tprivate final String description;\n\n\t\tprivate final Throwable thrown;\n\n\t\tprivate ExceptionThrowingSubTest(String description, Throwable thrown) {\n\t\t\tthis.description = description;\n\t\t\tthis.thrown = thrown;\n\t\t}\n\n\t\tpublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n\t\t\treturn new ThrowableAssert( thrown )\n\t\t\t\t\t.as( description );\n\t\t}\n\t}\n\n\t@FunctionalInterface\n\tpublic interface ParameterizedSubTest<T> {\n\t\tvoid test(T param);\n\t}\n\n}\n", "diffSourceCodeSet": [], "invokedMethodSet": [], "sourceCodeAfterRefactoring": "public AbstractThrowableAssert<?, Throwable> assertThrown() {\n\t\t\treturn new ThrowableAssert( thrown )\n\t\t\t\t\t.as( description );\n\t\t}", "diffSourceCode": "-   67: \tpublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n-   68: \t\treturn new ThrowableAssert( thrown )\n-   69: \t\t\t\t.as( description );\n-   70: \t}\n+   67: \t\t}\n+   68: \t\tcatch (Exception e) {\n+   69: \t\t\treturn new ExceptionThrowingSubTest( \"Exception thrown by '\" + description + \"'\", e );\n+   70: \t\t}\n+   86: \t\tpublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n+   87: \t\t\treturn new ThrowableAssert( thrown )\n+   88: \t\t\t\t\t.as( description );\n+   89: \t\t}\n", "uniqueId": "f50cbfc772b75e7d7a983359b9baca383bc6ae9f_67_70__86_89", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "To perform the requested refactoring operation, we will move the `assertThrown` method from the `SubTest` class to a new class called `ExceptionMatcherBuilder`. This new class will be responsible for building assertions related to exceptions. The `assertThrown` method will be updated to be a public static method in the new class. The `SubTest` class will then call this method.\n\n### Target File Path\nThe target file path for the moved method will be:\n```\nutil/internal/test/src/main/java/org/hibernate/search/util/impl/test/ExceptionMatcherBuilder.java\n```\n\n### Moved Class Code\nHere is the code for the `ExceptionMatcherBuilder` class, which includes the moved `assertThrown` method:\n\n```java\npackage org.hibernate.search.util.impl.test;\n\nimport org.assertj.core.api.AbstractThrowableAssert;\nimport org.assertj.core.api.ThrowableAssert;\n\n/**\n * A utility class for building assertions related to exceptions.\n */\npublic class ExceptionMatcherBuilder {\n\n    public static AbstractThrowableAssert<?, Throwable> assertThrown(Throwable thrown, String description) {\n        return new ThrowableAssert(thrown)\n                .as(description);\n    }\n}\n```\n\n### Refactored Method Code\nThe `assertThrown` method in the `SubTest` class will be refactored to call the static method from the `ExceptionMatcherBuilder` class:\n\n```java\npublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n    return ExceptionMatcherBuilder.assertThrown(thrown, description);\n}\n```\n\n### Final Output\nHere is the complete output in the requested format:\n\n##########################\nutil/internal/test/src/main/java/org/hibernate/search/util/impl/test/ExceptionMatcherBuilder.java\n##########################\npackage org.hibernate.search.util.impl.test;\n\nimport org.assertj.core.api.AbstractThrowableAssert;\nimport org.assertj.core.api.ThrowableAssert;\n\n/**\n * A utility class for building assertions related to exceptions.\n */\npublic class ExceptionMatcherBuilder {\n\n    public static AbstractThrowableAssert<?, Throwable> assertThrown(Throwable thrown, String description) {\n        return new ThrowableAssert(thrown)\n                .as(description);\n    }\n}\n##########################\npublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n    return ExceptionMatcherBuilder.assertThrown(thrown, description);\n}\n##########################", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\npublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n\t\treturn new ThrowableAssert( thrown )\n\t\t\t\t.as( description );\n\t}\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.util.impl.test;\n\nimport static org.junit.Assert.fail;\n\nimport java.util.concurrent.Callable;\n\nimport org.junit.Test;\n\nimport org.assertj.core.api.AbstractThrowableAssert;\nimport org.assertj.core.api.ThrowableAssert;\n\n/**\n * A util allowing to run blocks of code (\"sub-tests\"), expecting them to throw an exception.\n * <p>\n * Useful in particular when expecting an exception for each execution of a loop,\n * in which case {@link org.junit.rules.ExpectedException} or {@link Test#expected()} cannot be used.\n * <p>\n * By default any thrown exception will be accepted; if you want to run additional checks on the thrown exception,\n * use {@link #assertThrown()}.\n */\npublic class SubTest {\n\n\tpublic static SubTest expectException(Runnable runnable) {\n\t\treturn expectException( runnable.toString(), runnable );\n\t}\n\n\tpublic static SubTest expectException(String description, Runnable runnable) {\n\t\treturn expectException(\n\t\t\t\tdescription,\n\t\t\t\t() -> {\n\t\t\t\t\trunnable.run();\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t);\n\t}\n\n\tpublic static SubTest expectException(Callable<?> callable) {\n\t\treturn expectException( callable.toString(), callable );\n\t}\n\n\tpublic static SubTest expectException(String description, Callable<?> callable) {\n\t\ttry {\n\t\t\tcallable.call();\n\t\t\tfail( \"'\" + description + \"' should have thrown an exception\" );\n\t\t\tthrow new IllegalStateException( \"This should never happen\" );\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\treturn new SubTest( \"Exception thrown by '\" + description + \"'\", e );\n\t\t}\n\t}\n\n\tprivate final String description;\n\n\tprivate final Throwable thrown;\n\n\tprivate SubTest(String description, Throwable thrown) {\n\t\tthis.description = description;\n\t\tthis.thrown = thrown;\n\t}\n\n\tpublic AbstractThrowableAssert<?, Throwable> assertThrown() {\n\t\treturn new ThrowableAssert( thrown )\n\t\t\t\t.as( description );\n\t}\n\n}\n\nRefactoring Operation:\nMove Method\n\nProject Structure:\n['util/internal/test/src/main/java/org/hibernate/search/util/impl/test/ExceptionMatcherBuilder.java', 'util/internal/test/src/main/java/org/hibernate/search/util/impl/test/SubTest.java', 'util/internal/test/src/main/java/org/hibernate/search/util/impl/test/annotation/TestForIssue.java', 'util/internal/test/src/main/java/org/hibernate/search/util/impl/test/rule/ExpectedLog4jLog.java', 'util/internal/test/src/main/java/org/hibernate/search/util/impl/test/rule/StaticCounters.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply move method refactoring to the code to be refactored, output the target file path, moved class code, and refactored method code.\nNeed to move to an existing java file\nThe moved method code should be updated to the public static method.\nThe refactored method code should use the moved class to call the moved method.\nThe target file path should be the path of the existing class where the method is moved to.\n\n2. If refactoring is performed, output the target file path, moved class code, and refactored method code in the following format:\n##########################\ntarget_file_path\n##########################\nmoved_class_code\n##########################\nrefactored_method_code\n##########################\n\n\n\n"}, {"type": "Move And Inline Method", "description": "Move And Inline Method\tpublic end() : SearchSort moved from class org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext to class org.hibernate.search.integrationtest.backend.lucene.ExtensionIT & inlined to public sort_fromLuceneSortField_separateSort() : void", "diffLocations": [{"filePath": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "startLine": 184, "endLine": 230, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "startLine": 184, "endLine": 230, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "startLine": 17, "endLine": 24, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "import org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;", "filePathBefore": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "isPureRefactoring": true, "commitId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29", "packageNameBefore": "org.hibernate.search.engine.search.dsl.sort", "classNameBefore": "org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext", "methodNameBefore": "org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#end", "invokedMethod": "methodSignature: org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#toSort\n methodBody: SearchSort toSort();", "classSignatureBefore": "public interface SearchSortTerminalContext ", "methodNameBeforeSet": ["org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#end"], "classNameBeforeSet": ["org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext"], "classSignatureBeforeSet": ["public interface SearchSortTerminalContext "], "purityCheckResultList": [{"isPure": true, "purityComment": "Identical statements", "description": "There is no replacement! - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.end();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField, ExtensionIT::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n\tprivate static void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t}\n\n\tprivate static Integer fromNativeField(IndexableField field) {\n\t\treturn Integer.parseInt( field.stringValue() );\n\t}\n\n\tprivate static void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t}\n}\n", "filePathAfter": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).toPredicate();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).toPredicate();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).toPredicate();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).toPredicate();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.toSort();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.toSort();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.toSort();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField, ExtensionIT::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n\tprivate static void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t}\n\n\tprivate static Integer fromNativeField(IndexableField field) {\n\t\treturn Integer.parseInt( field.stringValue() );\n\t}\n\n\tprivate static void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t}\n}\n", "diffSourceCodeSet": [], "invokedMethodSet": ["methodSignature: org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#toSort\n methodBody: SearchSort toSort();"], "sourceCodeAfterRefactoring": "@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.toSort();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.toSort();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.toSort();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}", "diffSourceCode": "    17: import org.apache.lucene.document.LatLonPoint;\n    18: import org.apache.lucene.document.NumericDocValuesField;\n    19: import org.apache.lucene.document.StringField;\n    20: import org.apache.lucene.index.IndexableField;\n    21: import org.apache.lucene.index.Term;\n    22: import org.apache.lucene.search.Sort;\n    23: import org.apache.lucene.search.SortField;\n    24: import org.apache.lucene.search.SortField.Type;\n   184: \t@Test\n   185: \tpublic void sort_fromLuceneSortField_separateSort() {\n   186: \t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n   187: \n   188: \t\tSearchSort sort1 = searchTarget.sort().extension()\n   189: \t\t\t\t\t\t.ifSupported(\n   190: \t\t\t\t\t\t\t\tLuceneExtension.get(),\n   191: \t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n   192: \t\t\t\t\t\t)\n   193: \t\t\t\t\t\t.orElseFail()\n-  194: \t\t\t\t.end();\n+  194: \t\t\t\t.toSort();\n   195: \t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n   196: \t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n-  197: \t\t\t\t.end();\n+  197: \t\t\t\t.toSort();\n   198: \t\tSearchSort sort3 = searchTarget.sort().extension()\n   199: \t\t\t\t.ifSupported(\n   200: \t\t\t\t\t\tLuceneExtension.get(),\n   201: \t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n   202: \t\t\t\t)\n   203: \t\t\t\t.orElseFail()\n-  204: \t\t\t\t.end();\n+  204: \t\t\t\t.toSort();\n   205: \n   206: \t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n   207: \t\t\t\t.asReferences()\n   208: \t\t\t\t.predicate( root -> root.matchAll() )\n   209: \t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n   210: \t\t\t\t.build();\n   211: \t\tassertThat( query )\n   212: \t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n   213: \n   214: \t\tSearchSort sort = searchTarget.sort()\n   215: \t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n   216: \t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n   217: \t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n   218: \t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n   219: \t\t\t\t\t)\n   220: \t\t\t\t)\n-  221: \t\t\t\t.end();\n+  221: \t\t\t\t.toSort();\n   222: \n   223: \t\tquery = searchTarget.query( sessionContext )\n   224: \t\t\t\t.asReferences()\n   225: \t\t\t\t.predicate( root -> root.matchAll() )\n   226: \t\t\t\t.sort( c -> c.by( sort ) )\n   227: \t\t\t\t.build();\n   228: \t\tassertThat( query )\n   229: \t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n   230: \t}\n", "uniqueId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29_184_230__184_230_17_24", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "After analyzing the provided code, I identified that the methods `contributeNativeField`, `fromNativeField`, and `contributeNativeFieldInvalidFieldPath` can be moved and inlined into the `IndexAccessors` class. This will improve the readability and maintainability of the code by reducing the number of methods in the `ExtensionIT` class and keeping related functionality together.\n\nHere\u2019s the refactored code:\n\n```java\nintegrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java:\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.end();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, this::contributeNativeField, this::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, this::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, this::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\n\t\tprivate void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t\t}\n\n\t\tprivate Integer fromNativeField(IndexableField field) {\n\t\t\treturn Integer.parseInt( field.stringValue() );\n\t\t}\n\n\t\tprivate void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t\t}\n\t}\n}\n```\n\nIn this refactored code, the methods `contributeNativeField`, `fromNativeField`, and `contributeNativeFieldInvalidFieldPath` have been moved into the `IndexAccessors` class and are now instance methods. This change enhances the encapsulation of the `IndexAccessors` class and keeps related functionality together, improving the overall structure of the code.", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.end();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField, ExtensionIT::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n\tprivate static void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t}\n\n\tprivate static Integer fromNativeField(IndexableField field) {\n\t\treturn Integer.parseInt( field.stringValue() );\n\t}\n\n\tprivate static void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t}\n}\n\nRefactoring Operation:\nMove And Inline Method\n\nProject Structure:\n['integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/LuceneDocumentModelDslIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/analysis/LuceneAnalysisConfigurerIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/configuration/AnalysisCustomITAnalysisConfigurer.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/configuration/DefaultITAnalysisConfigurer.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/search/LuceneSearchMultiIndexIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/search/LuceneSearchSortIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/util/LuceneTckBackendFeatures.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/util/LuceneTckTestRunner.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply relevant refactoring operation to the code to be refactored, output the target file path.\n2. If refactoring is performed, output the refactored class code in the following format:\n$target_file_path$:\n$refactored_class_code$:\n\n\n"}, {"type": "Move And Inline Method", "description": "Move And Inline Method\tpublic end() : SearchSort moved from class org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext to class org.hibernate.search.integrationtest.backend.elasticsearch.ExtensionIT & inlined to public sort_fromJsonString_separateSort() : void", "diffLocations": [{"filePath": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "startLine": 198, "endLine": 246, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "startLine": 198, "endLine": 246, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "startLine": 17, "endLine": 24, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "import org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;", "filePathBefore": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "isPureRefactoring": true, "commitId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29", "packageNameBefore": "org.hibernate.search.engine.search.dsl.sort", "classNameBefore": "org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext", "methodNameBefore": "org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#end", "invokedMethod": "methodSignature: org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#toSort\n methodBody: SearchSort toSort();", "classSignatureBefore": "public interface SearchSortTerminalContext ", "methodNameBeforeSet": ["org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#end"], "classNameBeforeSet": ["org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext"], "classSignatureBeforeSet": ["public interface SearchSortTerminalContext "], "purityCheckResultList": [{"isPure": true, "purityComment": "Identical statements", "description": "There is no replacement! - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.elasticsearch;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myElasticsearchBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\tprivate static final String EMPTY_ID = \"empty\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\tb.should( c -> c.match().onField( \"yearDays\" ).matching( \"'2018:12'\" ) );\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\t\t.then().byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t\t\t.then().byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( ElasticsearchBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + ElasticsearchBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void backend_getClient() throws Exception {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\t\tRestClient restClient = elasticsearchBackend.getClient( RestClient.class );\n\n\t\t// Test that the client actually works\n\t\tResponse response = restClient.performRequest( \"GET\", \"/\" );\n\t\tAssertions.assertThat( response.getStatusLine().getStatusCode() ).isEqualTo( 200 );\n\t}\n\n\t@Test\n\tpublic void backend_getClient_error_invalidClass() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( HttpAsyncClient.class.getName() );\n\t\tthrown.expectMessage( \"the client can only be unwrapped to\" );\n\t\tthrown.expectMessage( RestClient.class.getName() );\n\n\t\telasticsearchBackend.getClient( HttpAsyncClient.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( ElasticsearchIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + ElasticsearchIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, \"2\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"'text 1'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 40.12, 'lon': -71.34}\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:012'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"a\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"'text 2'\" );\n\t\t\tindexAccessors.integer.write( document, \"1\" );\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 45.12, 'lon': -75.34}\" );\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:025'\" );\n\n\t\t\tindexAccessors.sort5.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( EMPTY_ID ), document -> { } );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<String> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<String> geoPoint;\n\t\tfinal IndexFieldAccessor<String> yearDays;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\t\tfinal IndexFieldAccessor<String> sort4;\n\t\tfinal IndexFieldAccessor<String> sort5;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'integer'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'geo_point'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tyearDays = root.field( \"yearDays\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'date', 'format': 'yyyy:DDD'}\" )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort4 = root.field( \"sort4\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort5 = root.field( \"sort5\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n}", "filePathAfter": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.elasticsearch;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myElasticsearchBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\tprivate static final String EMPTY_ID = \"empty\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\tb.should( c -> c.match().onField( \"yearDays\" ).matching( \"'2018:12'\" ) );\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).toPredicate();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).toPredicate();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.toPredicate();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).toPredicate();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).toPredicate();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\t\t.then().byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t\t\t.then().byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.toSort();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.toSort();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( ElasticsearchBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + ElasticsearchBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void backend_getClient() throws Exception {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\t\tRestClient restClient = elasticsearchBackend.getClient( RestClient.class );\n\n\t\t// Test that the client actually works\n\t\tResponse response = restClient.performRequest( \"GET\", \"/\" );\n\t\tAssertions.assertThat( response.getStatusLine().getStatusCode() ).isEqualTo( 200 );\n\t}\n\n\t@Test\n\tpublic void backend_getClient_error_invalidClass() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( HttpAsyncClient.class.getName() );\n\t\tthrown.expectMessage( \"the client can only be unwrapped to\" );\n\t\tthrown.expectMessage( RestClient.class.getName() );\n\n\t\telasticsearchBackend.getClient( HttpAsyncClient.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( ElasticsearchIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + ElasticsearchIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, \"2\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"'text 1'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 40.12, 'lon': -71.34}\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:012'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"a\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"'text 2'\" );\n\t\t\tindexAccessors.integer.write( document, \"1\" );\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 45.12, 'lon': -75.34}\" );\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:025'\" );\n\n\t\t\tindexAccessors.sort5.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( EMPTY_ID ), document -> { } );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<String> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<String> geoPoint;\n\t\tfinal IndexFieldAccessor<String> yearDays;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\t\tfinal IndexFieldAccessor<String> sort4;\n\t\tfinal IndexFieldAccessor<String> sort5;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'integer'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'geo_point'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tyearDays = root.field( \"yearDays\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'date', 'format': 'yyyy:DDD'}\" )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort4 = root.field( \"sort4\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort5 = root.field( \"sort5\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n}", "diffSourceCodeSet": [], "invokedMethodSet": ["methodSignature: org.hibernate.search.engine.search.dsl.sort.SearchSortTerminalContext#toSort\n methodBody: SearchSort toSort();"], "sourceCodeAfterRefactoring": "@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.toSort();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.toSort();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}", "diffSourceCode": "    17: import org.hibernate.search.engine.backend.document.IndexFieldAccessor;\n    18: import org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\n    19: import org.hibernate.search.engine.backend.index.IndexManager;\n    20: import org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\n    21: import org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\n    22: import org.hibernate.search.engine.common.spi.SearchIntegration;\n    23: import org.hibernate.search.engine.common.spi.SessionContext;\n    24: import org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\n   198: \t@Test\n   199: \tpublic void sort_fromJsonString_separateSort() {\n   200: \t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n   201: \n   202: \t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n   203: \t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n-  204: \t\t\t\t.end();\n+  204: \t\t\t\t.toSort();\n   205: \t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n   206: \t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n-  207: \t\t\t\t.end();\n+  207: \t\t\t\t.toSort();\n   208: \t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n   209: \t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n-  210: \t\t\t\t.end();\n+  210: \t\t\t\t.toSort();\n   211: \t\t// Also test using the standard DSL on a field defined with the extension\n   212: \t\tSearchSort sort4Asc = searchTarget.sort()\n   213: \t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n   214: \t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n-  215: \t\t\t\t.end();\n+  215: \t\t\t\t.toSort();\n   216: \n   217: \t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n   218: \t\t\t\t.asReferences()\n   219: \t\t\t\t.predicate( root -> root.matchAll() )\n   220: \t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n   221: \t\t\t\t.build();\n   222: \t\tassertThat( query )\n   223: \t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n   224: \n   225: \t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n   226: \t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n-  227: \t\t\t\t.end();\n+  227: \t\t\t\t.toSort();\n   228: \t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n   229: \t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n-  230: \t\t\t\t.end();\n+  230: \t\t\t\t.toSort();\n   231: \t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n   232: \t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n-  233: \t\t\t\t.end();\n+  233: \t\t\t\t.toSort();\n   234: \t\tSearchSort sort4Desc = searchTarget.sort()\n   235: \t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n   236: \t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n-  237: \t\t\t\t.end();\n+  237: \t\t\t\t.toSort();\n   238: \n   239: \t\tquery = searchTarget.query( sessionContext )\n   240: \t\t\t\t.asReferences()\n   241: \t\t\t\t.predicate( root -> root.matchAll() )\n   242: \t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n   243: \t\t\t\t.build();\n   244: \t\tassertThat( query )\n   245: \t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n   246: \t}\n", "uniqueId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29_198_246__198_246_17_24", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "After analyzing the provided code, I have identified that the `initData()` method can be refactored by moving its content into the `setup()` method. This will improve the readability and maintainability of the code by reducing the number of methods and making the setup process clearer.\n\nHere is the refactored class code:\n\n```java\nintegrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java:\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n    private static final String BACKEND_NAME = \"myElasticsearchBackend\";\n    private static final String INDEX_NAME = \"IndexName\";\n\n    private static final String FIRST_ID = \"1\";\n    private static final String SECOND_ID = \"2\";\n    private static final String THIRD_ID = \"3\";\n    private static final String FOURTH_ID = \"4\";\n    private static final String FIFTH_ID = \"5\";\n    private static final String EMPTY_ID = \"empty\";\n\n    @Rule\n    public SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n    @Rule\n    public ExpectedException thrown = ExpectedException.none();\n\n    private SearchIntegration integration;\n    private IndexAccessors indexAccessors;\n    private MappedIndexManager<?> indexManager;\n    private SessionContext sessionContext = new StubSessionContext();\n\n    @Before\n    public void setup() {\n        this.integration = setupHelper.withDefaultConfiguration(BACKEND_NAME)\n                .withIndex(\n                        \"MappedType\", INDEX_NAME,\n                        ctx -> this.indexAccessors = new IndexAccessors(ctx.getSchemaElement()),\n                        indexManager -> this.indexManager = indexManager\n                )\n                .setup();\n\n        // Initialize data directly in the setup method\n        IndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan(sessionContext);\n        workPlan.add(referenceProvider(SECOND_ID), document -> {\n            indexAccessors.integer.write(document, \"2\");\n            indexAccessors.sort1.write(document, \"z\");\n            indexAccessors.sort2.write(document, \"a\");\n            indexAccessors.sort3.write(document, \"z\");\n            indexAccessors.sort4.write(document, \"z\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(FIRST_ID), document -> {\n            indexAccessors.string.write(document, \"'text 1'\");\n            indexAccessors.sort1.write(document, \"a\");\n            indexAccessors.sort2.write(document, \"z\");\n            indexAccessors.sort3.write(document, \"z\");\n            indexAccessors.sort4.write(document, \"z\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(THIRD_ID), document -> {\n            indexAccessors.geoPoint.write(document, \"{'lat': 40.12, 'lon': -71.34}\");\n            indexAccessors.sort1.write(document, \"z\");\n            indexAccessors.sort2.write(document, \"z\");\n            indexAccessors.sort3.write(document, \"a\");\n            indexAccessors.sort4.write(document, \"z\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(FOURTH_ID), document -> {\n            indexAccessors.yearDays.write(document, \"'2018:012'\");\n            indexAccessors.sort1.write(document, \"z\");\n            indexAccessors.sort2.write(document, \"z\");\n            indexAccessors.sort3.write(document, \"z\");\n            indexAccessors.sort4.write(document, \"a\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(FIFTH_ID), document -> {\n            // This document should not match any query\n            indexAccessors.string.write(document, \"'text 2'\");\n            indexAccessors.integer.write(document, \"1\");\n            indexAccessors.geoPoint.write(document, \"{'lat': 45.12, 'lon': -75.34}\");\n            indexAccessors.yearDays.write(document, \"'2018:025'\");\n            indexAccessors.sort5.write(document, \"z\");\n        });\n        workPlan.add(referenceProvider(EMPTY_ID), document -> { });\n\n        workPlan.execute().join();\n\n        // Check that all documents are searchable\n        IndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n        SearchQuery<DocumentReference> query = searchTarget.query(sessionContext)\n                .asReferences()\n                .predicate(root -> root.matchAll())\n                .build();\n        assertThat(query).hasReferencesHitsAnyOrder(\n                INDEX_NAME,\n                FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n        );\n    }\n\n    // ... (rest of the class remains unchanged)\n\n    private static class IndexAccessors {\n        final IndexFieldAccessor<String> integer;\n        final IndexFieldAccessor<String> string;\n        final IndexFieldAccessor<String> geoPoint;\n        final IndexFieldAccessor<String> yearDays;\n\n        final IndexFieldAccessor<String> sort1;\n        final IndexFieldAccessor<String> sort2;\n        final IndexFieldAccessor<String> sort3;\n        final IndexFieldAccessor<String> sort4;\n        final IndexFieldAccessor<String> sort5;\n\n        IndexAccessors(IndexSchemaElement root) {\n            integer = root.field(\"integer\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'integer'}\")\n                    .createAccessor();\n            string = root.field(\"string\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword'}\")\n                    .createAccessor();\n            geoPoint = root.field(\"geoPoint\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'geo_point'}\")\n                    .createAccessor();\n            yearDays = root.field(\"yearDays\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'date', 'format': 'yyyy:DDD'}\")\n                    .createAccessor();\n\n            sort1 = root.field(\"sort1\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort2 = root.field(\"sort2\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort3 = root.field(\"sort3\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort4 = root.field(\"sort4\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort5 = root.field(\"sort5\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n        }\n    }\n}\n```\n\nIn this refactored code, the `initData()` method has been removed, and its content has been directly integrated into the `setup()` method. This change enhances the clarity of the setup process, making it easier to understand how the test data is initialized.", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.elasticsearch;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myElasticsearchBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\tprivate static final String EMPTY_ID = \"empty\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\tb.should( c -> c.match().onField( \"yearDays\" ).matching( \"'2018:12'\" ) );\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\t\t.then().byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t\t\t.then().byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( ElasticsearchBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + ElasticsearchBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void backend_getClient() throws Exception {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\t\tRestClient restClient = elasticsearchBackend.getClient( RestClient.class );\n\n\t\t// Test that the client actually works\n\t\tResponse response = restClient.performRequest( \"GET\", \"/\" );\n\t\tAssertions.assertThat( response.getStatusLine().getStatusCode() ).isEqualTo( 200 );\n\t}\n\n\t@Test\n\tpublic void backend_getClient_error_invalidClass() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( HttpAsyncClient.class.getName() );\n\t\tthrown.expectMessage( \"the client can only be unwrapped to\" );\n\t\tthrown.expectMessage( RestClient.class.getName() );\n\n\t\telasticsearchBackend.getClient( HttpAsyncClient.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( ElasticsearchIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + ElasticsearchIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, \"2\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"'text 1'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 40.12, 'lon': -71.34}\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:012'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"a\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"'text 2'\" );\n\t\t\tindexAccessors.integer.write( document, \"1\" );\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 45.12, 'lon': -75.34}\" );\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:025'\" );\n\n\t\t\tindexAccessors.sort5.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( EMPTY_ID ), document -> { } );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<String> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<String> geoPoint;\n\t\tfinal IndexFieldAccessor<String> yearDays;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\t\tfinal IndexFieldAccessor<String> sort4;\n\t\tfinal IndexFieldAccessor<String> sort5;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'integer'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'geo_point'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tyearDays = root.field( \"yearDays\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'date', 'format': 'yyyy:DDD'}\" )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort4 = root.field( \"sort4\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort5 = root.field( \"sort5\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n}\n\nRefactoring Operation:\nMove And Inline Method\n\nProject Structure:\n['integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/analysis/ElasticsearchAnalysisConfigurerIT.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/analysis/configuration/AnalysisCustomITAnalysisConfigurer.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/analysis/configuration/DefaultITAnalysisConfigurer.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/util/ElasticsearchTckBackendFeatures.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/util/ElasticsearchTckTestRunner.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply relevant refactoring operation to the code to be refactored, output the target file path.\n2. If refactoring is performed, output the refactored class code in the following format:\n$target_file_path$:\n$refactored_class_code$:\n\n\n"}, {"type": "Move And Inline Method", "description": "Move And Inline Method\tpublic end() : SearchPredicate moved from class org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext to class org.hibernate.search.integrationtest.backend.lucene.ExtensionIT & inlined to public predicate_fromLuceneQuery_separatePredicate() : void", "diffLocations": [{"filePath": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "startLine": 117, "endLine": 140, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "startLine": 117, "endLine": 140, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "startLine": 17, "endLine": 24, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "import org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;", "filePathBefore": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "isPureRefactoring": true, "commitId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29", "packageNameBefore": "org.hibernate.search.engine.search.dsl.predicate", "classNameBefore": "org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext", "methodNameBefore": "org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#end", "invokedMethod": "methodSignature: org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#toPredicate\n methodBody: SearchPredicate toPredicate();", "classSignatureBefore": "public interface SearchPredicateTerminalContext ", "methodNameBeforeSet": ["org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#end"], "classNameBeforeSet": ["org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext"], "classSignatureBeforeSet": ["public interface SearchPredicateTerminalContext "], "purityCheckResultList": [{"isPure": true, "purityComment": "Identical statements", "description": "There is no replacement! - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.end();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField, ExtensionIT::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n\tprivate static void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t}\n\n\tprivate static Integer fromNativeField(IndexableField field) {\n\t\treturn Integer.parseInt( field.stringValue() );\n\t}\n\n\tprivate static void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t}\n}\n", "filePathAfter": "integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).toPredicate();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).toPredicate();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).toPredicate();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).toPredicate();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.toSort();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.toSort();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.toSort();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField, ExtensionIT::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n\tprivate static void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t}\n\n\tprivate static Integer fromNativeField(IndexableField field) {\n\t\treturn Integer.parseInt( field.stringValue() );\n\t}\n\n\tprivate static void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t}\n}\n", "diffSourceCodeSet": [], "invokedMethodSet": ["methodSignature: org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#toPredicate\n methodBody: SearchPredicate toPredicate();"], "sourceCodeAfterRefactoring": "@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).toPredicate();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).toPredicate();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).toPredicate();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).toPredicate();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}", "diffSourceCode": "    17: import org.apache.lucene.document.LatLonPoint;\n    18: import org.apache.lucene.document.NumericDocValuesField;\n    19: import org.apache.lucene.document.StringField;\n    20: import org.apache.lucene.index.IndexableField;\n    21: import org.apache.lucene.index.Term;\n    22: import org.apache.lucene.search.Sort;\n    23: import org.apache.lucene.search.SortField;\n    24: import org.apache.lucene.search.SortField.Type;\n   117: \t@Test\n   118: \tpublic void predicate_fromLuceneQuery_separatePredicate() {\n   119: \t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n   120: \n   121: \t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n-  122: \t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n+  122: \t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).toPredicate();\n   123: \t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n-  124: \t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n+  124: \t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).toPredicate();\n   125: \t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n-  126: \t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n+  126: \t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).toPredicate();\n   127: \t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n   128: \t\t\tb.should( predicate1 );\n   129: \t\t\tb.should( predicate2 );\n   130: \t\t\tb.should( predicate3 );\n-  131: \t\t} ).end();\n+  131: \t\t} ).toPredicate();\n   132: \n   133: \t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n   134: \t\t\t\t.asReferences()\n   135: \t\t\t\t.predicate( booleanPredicate )\n   136: \t\t\t\t.build();\n   137: \t\tassertThat( query )\n   138: \t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n   139: \t\t\t\t.hasHitCount( 3 );\n   140: \t}\n", "uniqueId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29_117_140__117_140_17_24", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "After analyzing the provided code, I have identified that the methods `contributeNativeField`, `fromNativeField`, and `contributeNativeFieldInvalidFieldPath` can be moved and inlined into the `IndexAccessors` class. This will improve the readability and maintainability of the code by reducing the number of methods and keeping related logic together.\n\nHere is the refactored code:\n\n```java\nintegrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java:\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.end();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, (absoluteFieldPath, value, collector) -> {\n\t\t\t\t\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\t\t\t\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t\t\t\t\t}, field -> Integer.parseInt( field.stringValue() ) )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, (absoluteFieldPath, value, collector) -> {\n\t\t\t\t\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\t\t\t\t})\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, (absoluteFieldPath, value, collector) -> {\n\t\t\t\t\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t\t\t\t\t})\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n}\n```\n\nIn this refactored code, the methods `contributeNativeField`, `fromNativeField`, and `contributeNativeFieldInvalidFieldPath` have been inlined into the `IndexAccessors` constructor, which improves the encapsulation of the logic related to native fields.", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.lucene;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.IntPoint;\nimport org.apache.lucene.document.LatLonPoint;\nimport org.apache.lucene.document.NumericDocValuesField;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.search.SortField;\nimport org.apache.lucene.search.SortField.Type;\nimport org.apache.lucene.search.TermQuery;\nimport org.assertj.core.api.Assertions;\n\nimport org.hibernate.search.backend.lucene.LuceneBackend;\nimport org.hibernate.search.backend.lucene.index.LuceneIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.document.model.dsl.Sortable;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.backend.lucene.LuceneExtension;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.engine.logging.spi.EventContexts;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.engine.spatial.GeoPoint;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.FailureReportUtils;\nimport org.hibernate.search.util.impl.integrationtest.common.assertion.ProjectionsSearchResultAssert;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\nimport org.hibernate.search.util.impl.test.SubTest;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myLuceneBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) )\n\t\t\t\t\t);\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromLuceneQuery_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( new TermQuery( new Term( \"string\", \"text 1\" ) ) ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( IntPoint.newExactQuery( \"integer\", 2 ) ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneQuery( LatLonPoint.newDistanceQuery( \"geoPoint\", 40, -70, 200_000 ) ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID )\n\t\t\t\t.hasHitCount( 3 );\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t\t\t.then().extension( LuceneExtension.get() )\n\t\t\t\t\t\t\t\t.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension().ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSort( new Sort(\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tTHIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromLuceneSortField_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1 = searchTarget.sort().extension()\n\t\t\t\t\t\t.ifSupported(\n\t\t\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort1\", Type.STRING ) )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\t\tSearchSort sort2 = searchTarget.sort().extension( LuceneExtension.get() )\n\t\t\t\t.fromLuceneSortField( new SortField( \"sort2\", Type.STRING ) )\n\t\t\t\t.end();\n\t\tSearchSort sort3 = searchTarget.sort().extension()\n\t\t\t\t.ifSupported(\n\t\t\t\t\t\tLuceneExtension.get(),\n\t\t\t\t\t\tc2 -> c2.fromLuceneSortField( new SortField( \"sort3\", Type.STRING ) )\n\t\t\t\t)\n\t\t\t\t.orElseFail()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1 ).then().by( sort2 ).then().by( sort3 ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID );\n\n\t\tSearchSort sort = searchTarget.sort()\n\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneSort( new Sort(\n\t\t\t\t\t\tnew SortField( \"sort3\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort2\", Type.STRING ),\n\t\t\t\t\t\tnew SortField( \"sort1\", Type.STRING )\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, SECOND_ID, FIRST_ID, FOURTH_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"match() predicate on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t\t\t.match().onField( \"nativeField\" ).matching( \"37\" )\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining predicates with the DSL: use the Lucene extension and a native query.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void sort_nativeField_throwsException() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSubTest.expectException(\n\t\t\t\t\"sort on unsupported native field\",\n\t\t\t\t() -> searchTarget.query( sessionContext )\n\t\t\t\t\t\t.asReferences()\n\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t.sort( c -> c.byField( \"nativeField\" ) )\n\t\t\t\t\t\t.build()\n\t\t\t\t)\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Native fields do not support defining sorts with the DSL: use the Lucene extension and a native sort.\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeQuery() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<List<?>> query = searchTarget.query( sessionContext )\n\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField\", Integer.class ).toProjection() )\n\t\t\t\t.predicate( root -> root.match().onField( \"string\" ).matching( \"text 1\" ) )\n\t\t\t\t.build();\n\n\t\tProjectionsSearchResultAssert.assertThat( query ).hasProjectionsHitsAnyOrder( c -> {\n\t\t\tc.projection( 37 );\n\t\t} );\n\t}\n\n\t@Test\n\tpublic void projection_nativeField_unsupportedProjection() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\t// let's check that it's possible to query the field beforehand\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root\n\t\t\t\t\t\t.extension( LuceneExtension.get() ).fromLuceneQuery( new TermQuery( new Term( \"nativeField_unsupportedProjection\", \"37\" ) ) )\n\t\t\t\t)\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID );\n\n\t\t// now, let's check that projecting on the field throws an exception\n\t\tSubTest.expectException(\n\t\t\t\t\"projection on native field not supporting projections\",\n\t\t\t\t() -> {\n\t\t\t\t\t\tSearchQuery<List<?>> projectionQuery = searchTarget.query( sessionContext )\n\t\t\t\t\t\t\t\t.asProjections( searchTarget.projection().field( \"nativeField_unsupportedProjection\", Integer.class ).toProjection() )\n\t\t\t\t\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t\t\t\t\t.build();\n\t\t\t\t\t\tprojectionQuery.execute();\n\t\t\t\t} )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Projections are not enabled for field\" )\n\t\t\t\t.satisfies( FailureReportUtils.hasContext(\n\t\t\t\t\t\tEventContexts.fromIndexFieldAbsolutePath( \"nativeField_unsupportedProjection\" )\n\t\t\t\t) );\n\t}\n\n\t@Test\n\tpublic void predicate_nativeField_nativeSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.extension( LuceneExtension.get() ).fromLuceneSortField( new SortField( \"nativeField\", Type.LONG ) ) )\n\t\t\t\t.build();\n\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, THIRD_ID, FIRST_ID, FIFTH_ID, SECOND_ID, FOURTH_ID );\n\t}\n\n\t@Test\n\tpublic void nativeField_invalidFieldPath() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\n\t\tSubTest.expectException(\n\t\t\t\t\"native field contributing field with invalid field path\",\n\t\t\t\t() -> workPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\t\t\tindexAccessors.nativeField_invalidFieldPath.write( document, 45 );\n\t\t\t\t} ) )\n\t\t\t\t.assertThrown()\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Invalid field path; expected path 'nativeField_invalidFieldPath', got 'not the expected path'.\" );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( LuceneBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + LuceneBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( LuceneIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap a Lucene index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + LuceneIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"text 1\" );\n\n\t\t\tindexAccessors.nativeField.write( document, 37 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 37 );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, 2 );\n\n\t\t\tindexAccessors.nativeField.write( document, 78 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 78 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 40.12, -71.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 13 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 13 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.nativeField.write( document, 89 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 89 );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"text 2\" );\n\t\t\tindexAccessors.integer.write( document, 1 );\n\t\t\tindexAccessors.geoPoint.write( document, GeoPoint.of( 45.12, -75.34 ) );\n\n\t\t\tindexAccessors.nativeField.write( document, 53 );\n\t\t\tindexAccessors.nativeField_unsupportedProjection.write( document, 53 );\n\n\t\t\tindexAccessors.sort1.write( document, \"zz\" );\n\t\t\tindexAccessors.sort2.write( document, \"zz\" );\n\t\t\tindexAccessors.sort3.write( document, \"zz\" );\n\t\t} );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<Integer> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<GeoPoint> geoPoint;\n\t\tfinal IndexFieldAccessor<Integer> nativeField;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_unsupportedProjection;\n\t\tfinal IndexFieldAccessor<Integer> nativeField_invalidFieldPath;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.asInteger()\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.asGeoPoint()\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField = root.field( \"nativeField\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField, ExtensionIT::fromNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_unsupportedProjection = root.field( \"nativeField_unsupportedProjection\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeField )\n\t\t\t\t\t.createAccessor();\n\t\t\tnativeField_invalidFieldPath = root.field( \"nativeField_invalidFieldPath\" )\n\t\t\t\t\t.extension( LuceneExtension.get() )\n\t\t\t\t\t.asLuceneField( Integer.class, ExtensionIT::contributeNativeFieldInvalidFieldPath )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.asString()\n\t\t\t\t\t.sortable( Sortable.YES )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n\tprivate static void contributeNativeField(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( absoluteFieldPath, value.toString(), Store.YES ) );\n\t\tcollector.accept( new NumericDocValuesField( absoluteFieldPath, value.longValue() ) );\n\t}\n\n\tprivate static Integer fromNativeField(IndexableField field) {\n\t\treturn Integer.parseInt( field.stringValue() );\n\t}\n\n\tprivate static void contributeNativeFieldInvalidFieldPath(String absoluteFieldPath, Integer value, Consumer<IndexableField> collector) {\n\t\tcollector.accept( new StringField( \"not the expected path\", value.toString(), Store.YES ) );\n\t}\n}\n\nRefactoring Operation:\nMove And Inline Method\n\nProject Structure:\n['integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/ExtensionIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/LuceneDocumentModelDslIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/analysis/LuceneAnalysisConfigurerIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/configuration/AnalysisCustomITAnalysisConfigurer.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/configuration/DefaultITAnalysisConfigurer.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/search/LuceneSearchMultiIndexIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/search/LuceneSearchSortIT.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/util/LuceneTckBackendFeatures.java', 'integrationtest/backend/lucene/src/test/java/org/hibernate/search/integrationtest/backend/lucene/util/LuceneTckTestRunner.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply relevant refactoring operation to the code to be refactored, output the target file path.\n2. If refactoring is performed, output the refactored class code in the following format:\n$target_file_path$:\n$refactored_class_code$:\n\n\n"}, {"type": "Move And Inline Method", "description": "Move And Inline Method\tpublic end() : SearchPredicate moved from class org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext to class org.hibernate.search.integrationtest.backend.elasticsearch.ExtensionIT & inlined to public predicate_fromJsonString_separatePredicate() : void", "diffLocations": [{"filePath": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "startLine": 114, "endLine": 152, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "startLine": 114, "endLine": 152, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "startLine": 17, "endLine": 24, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "import org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;", "filePathBefore": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "isPureRefactoring": true, "commitId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29", "packageNameBefore": "org.hibernate.search.engine.search.dsl.predicate", "classNameBefore": "org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext", "methodNameBefore": "org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#end", "invokedMethod": "methodSignature: org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#toPredicate\n methodBody: SearchPredicate toPredicate();", "classSignatureBefore": "public interface SearchPredicateTerminalContext ", "methodNameBeforeSet": ["org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#end"], "classNameBeforeSet": ["org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext"], "classSignatureBeforeSet": ["public interface SearchPredicateTerminalContext "], "purityCheckResultList": [{"isPure": true, "purityComment": "Identical statements", "description": "There is no replacement! - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.elasticsearch;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myElasticsearchBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\tprivate static final String EMPTY_ID = \"empty\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\tb.should( c -> c.match().onField( \"yearDays\" ).matching( \"'2018:12'\" ) );\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\t\t.then().byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t\t\t.then().byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( ElasticsearchBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + ElasticsearchBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void backend_getClient() throws Exception {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\t\tRestClient restClient = elasticsearchBackend.getClient( RestClient.class );\n\n\t\t// Test that the client actually works\n\t\tResponse response = restClient.performRequest( \"GET\", \"/\" );\n\t\tAssertions.assertThat( response.getStatusLine().getStatusCode() ).isEqualTo( 200 );\n\t}\n\n\t@Test\n\tpublic void backend_getClient_error_invalidClass() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( HttpAsyncClient.class.getName() );\n\t\tthrown.expectMessage( \"the client can only be unwrapped to\" );\n\t\tthrown.expectMessage( RestClient.class.getName() );\n\n\t\telasticsearchBackend.getClient( HttpAsyncClient.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( ElasticsearchIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + ElasticsearchIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, \"2\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"'text 1'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 40.12, 'lon': -71.34}\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:012'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"a\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"'text 2'\" );\n\t\t\tindexAccessors.integer.write( document, \"1\" );\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 45.12, 'lon': -75.34}\" );\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:025'\" );\n\n\t\t\tindexAccessors.sort5.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( EMPTY_ID ), document -> { } );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<String> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<String> geoPoint;\n\t\tfinal IndexFieldAccessor<String> yearDays;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\t\tfinal IndexFieldAccessor<String> sort4;\n\t\tfinal IndexFieldAccessor<String> sort5;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'integer'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'geo_point'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tyearDays = root.field( \"yearDays\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'date', 'format': 'yyyy:DDD'}\" )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort4 = root.field( \"sort4\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort5 = root.field( \"sort5\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n}", "filePathAfter": "integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.elasticsearch;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myElasticsearchBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\tprivate static final String EMPTY_ID = \"empty\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\tb.should( c -> c.match().onField( \"yearDays\" ).matching( \"'2018:12'\" ) );\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).toPredicate();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).toPredicate();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.toPredicate();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).toPredicate();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).toPredicate();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\t\t.then().byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t\t\t.then().byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.toSort();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.toSort();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.toSort();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.toSort();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( ElasticsearchBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + ElasticsearchBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void backend_getClient() throws Exception {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\t\tRestClient restClient = elasticsearchBackend.getClient( RestClient.class );\n\n\t\t// Test that the client actually works\n\t\tResponse response = restClient.performRequest( \"GET\", \"/\" );\n\t\tAssertions.assertThat( response.getStatusLine().getStatusCode() ).isEqualTo( 200 );\n\t}\n\n\t@Test\n\tpublic void backend_getClient_error_invalidClass() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( HttpAsyncClient.class.getName() );\n\t\tthrown.expectMessage( \"the client can only be unwrapped to\" );\n\t\tthrown.expectMessage( RestClient.class.getName() );\n\n\t\telasticsearchBackend.getClient( HttpAsyncClient.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( ElasticsearchIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + ElasticsearchIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, \"2\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"'text 1'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 40.12, 'lon': -71.34}\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:012'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"a\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"'text 2'\" );\n\t\t\tindexAccessors.integer.write( document, \"1\" );\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 45.12, 'lon': -75.34}\" );\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:025'\" );\n\n\t\t\tindexAccessors.sort5.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( EMPTY_ID ), document -> { } );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<String> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<String> geoPoint;\n\t\tfinal IndexFieldAccessor<String> yearDays;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\t\tfinal IndexFieldAccessor<String> sort4;\n\t\tfinal IndexFieldAccessor<String> sort5;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'integer'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'geo_point'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tyearDays = root.field( \"yearDays\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'date', 'format': 'yyyy:DDD'}\" )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort4 = root.field( \"sort4\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort5 = root.field( \"sort5\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n}", "diffSourceCodeSet": [], "invokedMethodSet": ["methodSignature: org.hibernate.search.engine.search.dsl.predicate.SearchPredicateTerminalContext#toPredicate\n methodBody: SearchPredicate toPredicate();"], "sourceCodeAfterRefactoring": "@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).toPredicate();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).toPredicate();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.toPredicate();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).toPredicate();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).toPredicate();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}", "diffSourceCode": "    17: import org.hibernate.search.engine.backend.document.IndexFieldAccessor;\n    18: import org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\n    19: import org.hibernate.search.engine.backend.index.IndexManager;\n    20: import org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\n    21: import org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\n    22: import org.hibernate.search.engine.common.spi.SearchIntegration;\n    23: import org.hibernate.search.engine.common.spi.SessionContext;\n    24: import org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\n   114: \t@Test\n   115: \tpublic void predicate_fromJsonString_separatePredicate() {\n   116: \t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n   117: \n   118: \t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n-  119: \t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).end();\n+  119: \t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).toPredicate();\n   120: \t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n-  121: \t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).end();\n+  121: \t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).toPredicate();\n   122: \t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n   123: \t\t\t\t.fromJsonString(\n   124: \t\t\t\t\t\t\"{\"\n   125: \t\t\t\t\t\t\t+ \"'geo_distance': {\"\n   126: \t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n   127: \t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n   128: \t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n   129: \t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n   130: \t\t\t\t\t\t\t\t+ \"}\"\n   131: \t\t\t\t\t\t\t+ \"}\"\n   132: \t\t\t\t\t\t+ \"}\"\n   133: \t\t\t\t)\n-  134: \t\t\t\t.end();\n+  134: \t\t\t\t.toPredicate();\n   135: \t\t// Also test using the standard DSL on a field defined with the extension\n   136: \t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n-  137: \t\t\t\t.matching( \"'2018:12'\" ).end();\n+  137: \t\t\t\t.matching( \"'2018:12'\" ).toPredicate();\n   138: \t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n   139: \t\t\tb.should( predicate1 );\n   140: \t\t\tb.should( predicate2 );\n   141: \t\t\tb.should( predicate3 );\n   142: \t\t\tb.should( predicate4 );\n-  143: \t\t} ).end();\n+  143: \t\t} ).toPredicate();\n   144: \n   145: \t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n   146: \t\t\t\t.asReferences()\n   147: \t\t\t\t.predicate( booleanPredicate )\n   148: \t\t\t\t.build();\n   149: \t\tassertThat( query )\n   150: \t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n   151: \t\t\t\t.hasHitCount( 4 );\n   152: \t}\n", "uniqueId": "b67c74bdf7a5a1a8102fb0b0179bdc0774366c29_114_152__114_152_17_24", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "After analyzing the provided code, I have identified that the `initData()` method can be refactored by moving its content into the `setup()` method. This will improve the readability and maintainability of the code by reducing the number of methods and making the setup process clearer.\n\nHere is the refactored class code:\n\n```java\nintegrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java:\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n    private static final String BACKEND_NAME = \"myElasticsearchBackend\";\n    private static final String INDEX_NAME = \"IndexName\";\n\n    private static final String FIRST_ID = \"1\";\n    private static final String SECOND_ID = \"2\";\n    private static final String THIRD_ID = \"3\";\n    private static final String FOURTH_ID = \"4\";\n    private static final String FIFTH_ID = \"5\";\n    private static final String EMPTY_ID = \"empty\";\n\n    @Rule\n    public SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n    @Rule\n    public ExpectedException thrown = ExpectedException.none();\n\n    private SearchIntegration integration;\n    private IndexAccessors indexAccessors;\n    private MappedIndexManager<?> indexManager;\n    private SessionContext sessionContext = new StubSessionContext();\n\n    @Before\n    public void setup() {\n        this.integration = setupHelper.withDefaultConfiguration(BACKEND_NAME)\n                .withIndex(\n                        \"MappedType\", INDEX_NAME,\n                        ctx -> this.indexAccessors = new IndexAccessors(ctx.getSchemaElement()),\n                        indexManager -> this.indexManager = indexManager\n                )\n                .setup();\n\n        // Initialize data\n        IndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan(sessionContext);\n        workPlan.add(referenceProvider(SECOND_ID), document -> {\n            indexAccessors.integer.write(document, \"2\");\n            indexAccessors.sort1.write(document, \"z\");\n            indexAccessors.sort2.write(document, \"a\");\n            indexAccessors.sort3.write(document, \"z\");\n            indexAccessors.sort4.write(document, \"z\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(FIRST_ID), document -> {\n            indexAccessors.string.write(document, \"'text 1'\");\n            indexAccessors.sort1.write(document, \"a\");\n            indexAccessors.sort2.write(document, \"z\");\n            indexAccessors.sort3.write(document, \"z\");\n            indexAccessors.sort4.write(document, \"z\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(THIRD_ID), document -> {\n            indexAccessors.geoPoint.write(document, \"{'lat': 40.12, 'lon': -71.34}\");\n            indexAccessors.sort1.write(document, \"z\");\n            indexAccessors.sort2.write(document, \"z\");\n            indexAccessors.sort3.write(document, \"a\");\n            indexAccessors.sort4.write(document, \"z\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(FOURTH_ID), document -> {\n            indexAccessors.yearDays.write(document, \"'2018:012'\");\n            indexAccessors.sort1.write(document, \"z\");\n            indexAccessors.sort2.write(document, \"z\");\n            indexAccessors.sort3.write(document, \"z\");\n            indexAccessors.sort4.write(document, \"a\");\n            indexAccessors.sort5.write(document, \"a\");\n        });\n        workPlan.add(referenceProvider(FIFTH_ID), document -> {\n            // This document should not match any query\n            indexAccessors.string.write(document, \"'text 2'\");\n            indexAccessors.integer.write(document, \"1\");\n            indexAccessors.geoPoint.write(document, \"{'lat': 45.12, 'lon': -75.34}\");\n            indexAccessors.yearDays.write(document, \"'2018:025'\");\n            indexAccessors.sort5.write(document, \"z\");\n        });\n        workPlan.add(referenceProvider(EMPTY_ID), document -> { });\n\n        workPlan.execute().join();\n\n        // Check that all documents are searchable\n        IndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n        SearchQuery<DocumentReference> query = searchTarget.query(sessionContext)\n                .asReferences()\n                .predicate(root -> root.matchAll())\n                .build();\n        assertThat(query).hasReferencesHitsAnyOrder(\n                INDEX_NAME,\n                FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n        );\n    }\n\n    // ... (rest of the class remains unchanged)\n\n    private static class IndexAccessors {\n        final IndexFieldAccessor<String> integer;\n        final IndexFieldAccessor<String> string;\n        final IndexFieldAccessor<String> geoPoint;\n        final IndexFieldAccessor<String> yearDays;\n\n        final IndexFieldAccessor<String> sort1;\n        final IndexFieldAccessor<String> sort2;\n        final IndexFieldAccessor<String> sort3;\n        final IndexFieldAccessor<String> sort4;\n        final IndexFieldAccessor<String> sort5;\n\n        IndexAccessors(IndexSchemaElement root) {\n            integer = root.field(\"integer\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'integer'}\")\n                    .createAccessor();\n            string = root.field(\"string\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword'}\")\n                    .createAccessor();\n            geoPoint = root.field(\"geoPoint\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'geo_point'}\")\n                    .createAccessor();\n            yearDays = root.field(\"yearDays\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'date', 'format': 'yyyy:DDD'}\")\n                    .createAccessor();\n\n            sort1 = root.field(\"sort1\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort2 = root.field(\"sort2\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort3 = root.field(\"sort3\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort4 = root.field(\"sort4\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n            sort5 = root.field(\"sort5\")\n                    .extension(ElasticsearchExtension.get())\n                    .asJsonString(\"{'type': 'keyword', 'doc_values': true}\")\n                    .createAccessor();\n        }\n    }\n}\n```\n\nIn this refactored code, the `initData()` method has been inlined into the `setup()` method, which makes the setup process clearer and reduces the number of methods in the class. The rest of the class remains unchanged.", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.backend.elasticsearch;\n\nimport static org.hibernate.search.util.impl.integrationtest.common.assertion.DocumentReferencesSearchResultAssert.assertThat;\nimport static org.hibernate.search.util.impl.integrationtest.common.stub.mapper.StubMapperUtils.referenceProvider;\n\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchBackend;\nimport org.hibernate.search.backend.elasticsearch.ElasticsearchExtension;\nimport org.hibernate.search.backend.elasticsearch.index.ElasticsearchIndexManager;\nimport org.hibernate.search.engine.backend.Backend;\nimport org.hibernate.search.engine.backend.document.DocumentElement;\nimport org.hibernate.search.engine.backend.document.IndexFieldAccessor;\nimport org.hibernate.search.engine.backend.document.model.dsl.IndexSchemaElement;\nimport org.hibernate.search.engine.backend.index.IndexManager;\nimport org.hibernate.search.engine.backend.index.spi.IndexSearchTarget;\nimport org.hibernate.search.engine.backend.index.spi.IndexWorkPlan;\nimport org.hibernate.search.engine.common.spi.SearchIntegration;\nimport org.hibernate.search.engine.common.spi.SessionContext;\nimport org.hibernate.search.engine.mapper.mapping.spi.MappedIndexManager;\nimport org.hibernate.search.engine.search.DocumentReference;\nimport org.hibernate.search.engine.search.SearchPredicate;\nimport org.hibernate.search.engine.search.SearchQuery;\nimport org.hibernate.search.engine.search.SearchSort;\nimport org.hibernate.search.integrationtest.backend.tck.util.rule.SearchSetupHelper;\nimport org.hibernate.search.util.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.stub.StubSessionContext;\n\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\nimport org.apache.http.nio.client.HttpAsyncClient;\nimport org.assertj.core.api.Assertions;\nimport org.elasticsearch.client.Response;\nimport org.elasticsearch.client.RestClient;\n\npublic class ExtensionIT {\n\n\tprivate static final String BACKEND_NAME = \"myElasticsearchBackend\";\n\tprivate static final String INDEX_NAME = \"IndexName\";\n\n\tprivate static final String FIRST_ID = \"1\";\n\tprivate static final String SECOND_ID = \"2\";\n\tprivate static final String THIRD_ID = \"3\";\n\tprivate static final String FOURTH_ID = \"4\";\n\tprivate static final String FIFTH_ID = \"5\";\n\tprivate static final String EMPTY_ID = \"empty\";\n\n\t@Rule\n\tpublic SearchSetupHelper setupHelper = new SearchSetupHelper();\n\n\t@Rule\n\tpublic ExpectedException thrown = ExpectedException.none();\n\n\tprivate SearchIntegration integration;\n\tprivate IndexAccessors indexAccessors;\n\tprivate MappedIndexManager<?> indexManager;\n\tprivate SessionContext sessionContext = new StubSessionContext();\n\n\t@Before\n\tpublic void setup() {\n\t\tthis.integration = setupHelper.withDefaultConfiguration( BACKEND_NAME )\n\t\t\t\t.withIndex(\n\t\t\t\t\t\t\"MappedType\", INDEX_NAME,\n\t\t\t\t\t\tctx -> this.indexAccessors = new IndexAccessors( ctx.getSchemaElement() ),\n\t\t\t\t\t\tindexManager -> this.indexManager = indexManager\n\t\t\t\t)\n\t\t\t\t.setup();\n\n\t\tinitData();\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.bool( b -> {\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" )\n\t\t\t\t\t);\n\t\t\t\t\tb.should( c -> c.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\tb.should( c -> c.match().onField( \"yearDays\" ).matching( \"'2018:12'\" ) );\n\t\t\t\t} ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void predicate_fromJsonString_separatePredicate() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchPredicate predicate1 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'string': 'text 1'}}\" ).end();\n\t\tSearchPredicate predicate2 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'match': {'integer': 2}}\" ).end();\n\t\tSearchPredicate predicate3 = searchTarget.predicate().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString(\n\t\t\t\t\t\t\"{\"\n\t\t\t\t\t\t\t+ \"'geo_distance': {\"\n\t\t\t\t\t\t\t\t+ \"'distance': '200km',\"\n\t\t\t\t\t\t\t\t+ \"'geoPoint': {\"\n\t\t\t\t\t\t\t\t\t+ \"'lat': 40,\"\n\t\t\t\t\t\t\t\t\t+ \"'lon': -70\"\n\t\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t\t+ \"}\"\n\t\t\t\t\t\t+ \"}\"\n\t\t\t\t)\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchPredicate predicate4 = searchTarget.predicate().match().onField( \"yearDays\" )\n\t\t\t\t.matching( \"'2018:12'\" ).end();\n\t\tSearchPredicate booleanPredicate = searchTarget.predicate().bool( b -> {\n\t\t\tb.should( predicate1 );\n\t\t\tb.should( predicate2 );\n\t\t\tb.should( predicate3 );\n\t\t\tb.should( predicate4 );\n\t\t} ).end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( booleanPredicate )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsAnyOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID )\n\t\t\t\t.hasHitCount( 4 );\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t\t\t// Also test using the standard DSL on a field defined with the extension\n\t\t\t\t\t\t.then().byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c\n\t\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t\t\t.then().extension( ElasticsearchExtension.get() )\n\t\t\t\t\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t\t\t.then().byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t)\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsExactOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID\n\t\t);\n\t}\n\n\t@Test\n\tpublic void sort_fromJsonString_separateSort() {\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\n\t\tSearchSort sort1Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'asc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Asc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'asc'}\" )\n\t\t\t\t.end();\n\t\t// Also test using the standard DSL on a field defined with the extension\n\t\tSearchSort sort4Asc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).asc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Asc ).then().by( sort2Asc ).then().by( sort3Asc ).then().by( sort4Asc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, EMPTY_ID, FIFTH_ID );\n\n\t\tSearchSort sort1Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort1': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort2Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort2': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort3Desc = searchTarget.sort().extension( ElasticsearchExtension.get() )\n\t\t\t\t.fromJsonString( \"{'sort3': 'desc'}\" )\n\t\t\t\t.end();\n\t\tSearchSort sort4Desc = searchTarget.sort()\n\t\t\t\t.byField( \"sort4\" ).desc().onMissingValue().sortLast()\n\t\t\t\t.then().byField( \"sort5\" ).asc().onMissingValue().sortFirst()\n\t\t\t\t.end();\n\n\t\tquery = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.sort( c -> c.by( sort1Desc ).then().by( sort2Desc ).then().by( sort3Desc ).then().by( sort4Desc ) )\n\t\t\t\t.build();\n\t\tassertThat( query )\n\t\t\t\t.hasReferencesHitsExactOrder( INDEX_NAME, FOURTH_ID, THIRD_ID, SECOND_ID, FIRST_ID, EMPTY_ID, FIFTH_ID );\n\t}\n\n\t@Test\n\tpublic void backend_unwrap() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tAssertions.assertThat( backend.unwrap( ElasticsearchBackend.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void backend_unwrap_error_unknownType() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch backend to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this backend can only be unwrapped to '\" + ElasticsearchBackend.class.getName() + \"'\" );\n\n\t\tbackend.unwrap( String.class );\n\t}\n\n\t@Test\n\tpublic void backend_getClient() throws Exception {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\t\tRestClient restClient = elasticsearchBackend.getClient( RestClient.class );\n\n\t\t// Test that the client actually works\n\t\tResponse response = restClient.performRequest( \"GET\", \"/\" );\n\t\tAssertions.assertThat( response.getStatusLine().getStatusCode() ).isEqualTo( 200 );\n\t}\n\n\t@Test\n\tpublic void backend_getClient_error_invalidClass() {\n\t\tBackend backend = integration.getBackend( BACKEND_NAME );\n\t\tElasticsearchBackend elasticsearchBackend = backend.unwrap( ElasticsearchBackend.class );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( HttpAsyncClient.class.getName() );\n\t\tthrown.expectMessage( \"the client can only be unwrapped to\" );\n\t\tthrown.expectMessage( RestClient.class.getName() );\n\n\t\telasticsearchBackend.getClient( HttpAsyncClient.class );\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\t\tAssertions.assertThat( indexManager.unwrap( ElasticsearchIndexManager.class ) )\n\t\t\t\t.isNotNull();\n\t}\n\n\t@Test\n\tpublic void indexManager_unwrap_error_unknownType() {\n\t\tIndexManager indexManager = integration.getIndexManager( INDEX_NAME );\n\n\t\tthrown.expect( SearchException.class );\n\t\tthrown.expectMessage( \"Attempt to unwrap an Elasticsearch index manager to '\" + String.class.getName() + \"'\" );\n\t\tthrown.expectMessage( \"this index manager can only be unwrapped to '\" + ElasticsearchIndexManager.class.getName() + \"'\" );\n\n\t\tindexManager.unwrap( String.class );\n\t}\n\n\tprivate void initData() {\n\t\tIndexWorkPlan<? extends DocumentElement> workPlan = indexManager.createWorkPlan( sessionContext );\n\t\tworkPlan.add( referenceProvider( SECOND_ID ), document -> {\n\t\t\tindexAccessors.integer.write( document, \"2\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"a\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIRST_ID ), document -> {\n\t\t\tindexAccessors.string.write( document, \"'text 1'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"a\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( THIRD_ID ), document -> {\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 40.12, 'lon': -71.34}\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"a\" );\n\t\t\tindexAccessors.sort4.write( document, \"z\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FOURTH_ID ), document -> {\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:012'\" );\n\n\t\t\tindexAccessors.sort1.write( document, \"z\" );\n\t\t\tindexAccessors.sort2.write( document, \"z\" );\n\t\t\tindexAccessors.sort3.write( document, \"z\" );\n\t\t\tindexAccessors.sort4.write( document, \"a\" );\n\t\t\tindexAccessors.sort5.write( document, \"a\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( FIFTH_ID ), document -> {\n\t\t\t// This document should not match any query\n\t\t\tindexAccessors.string.write( document, \"'text 2'\" );\n\t\t\tindexAccessors.integer.write( document, \"1\" );\n\t\t\tindexAccessors.geoPoint.write( document, \"{'lat': 45.12, 'lon': -75.34}\" );\n\t\t\tindexAccessors.yearDays.write( document, \"'2018:025'\" );\n\n\t\t\tindexAccessors.sort5.write( document, \"z\" );\n\t\t} );\n\t\tworkPlan.add( referenceProvider( EMPTY_ID ), document -> { } );\n\n\t\tworkPlan.execute().join();\n\n\t\t// Check that all documents are searchable\n\t\tIndexSearchTarget searchTarget = indexManager.createSearchTarget().build();\n\t\tSearchQuery<DocumentReference> query = searchTarget.query( sessionContext )\n\t\t\t\t.asReferences()\n\t\t\t\t.predicate( root -> root.matchAll() )\n\t\t\t\t.build();\n\t\tassertThat( query ).hasReferencesHitsAnyOrder(\n\t\t\t\tINDEX_NAME,\n\t\t\t\tFIRST_ID, SECOND_ID, THIRD_ID, FOURTH_ID, FIFTH_ID, EMPTY_ID\n\t\t);\n\t}\n\n\tprivate static class IndexAccessors {\n\t\tfinal IndexFieldAccessor<String> integer;\n\t\tfinal IndexFieldAccessor<String> string;\n\t\tfinal IndexFieldAccessor<String> geoPoint;\n\t\tfinal IndexFieldAccessor<String> yearDays;\n\n\t\tfinal IndexFieldAccessor<String> sort1;\n\t\tfinal IndexFieldAccessor<String> sort2;\n\t\tfinal IndexFieldAccessor<String> sort3;\n\t\tfinal IndexFieldAccessor<String> sort4;\n\t\tfinal IndexFieldAccessor<String> sort5;\n\n\t\tIndexAccessors(IndexSchemaElement root) {\n\t\t\tinteger = root.field( \"integer\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'integer'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tstring = root.field( \"string\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tgeoPoint = root.field( \"geoPoint\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'geo_point'}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tyearDays = root.field( \"yearDays\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'date', 'format': 'yyyy:DDD'}\" )\n\t\t\t\t\t.createAccessor();\n\n\t\t\tsort1 = root.field( \"sort1\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort2 = root.field( \"sort2\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort3 = root.field( \"sort3\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort4 = root.field( \"sort4\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t\tsort5 = root.field( \"sort5\" )\n\t\t\t\t\t.extension( ElasticsearchExtension.get() )\n\t\t\t\t\t.asJsonString( \"{'type': 'keyword', 'doc_values': true}\" )\n\t\t\t\t\t.createAccessor();\n\t\t}\n\t}\n\n}\n\nRefactoring Operation:\nMove And Inline Method\n\nProject Structure:\n['integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/ExtensionIT.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/analysis/ElasticsearchAnalysisConfigurerIT.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/analysis/configuration/AnalysisCustomITAnalysisConfigurer.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/analysis/configuration/DefaultITAnalysisConfigurer.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/util/ElasticsearchTckBackendFeatures.java', 'integrationtest/backend/elasticsearch/src/test/java/org/hibernate/search/integrationtest/backend/elasticsearch/util/ElasticsearchTckTestRunner.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply relevant refactoring operation to the code to be refactored, output the target file path.\n2. If refactoring is performed, output the refactored class code in the following format:\n$target_file_path$:\n$refactored_class_code$:\n\n\n"}, {"type": "Move And Rename Method", "description": "Move And Rename Method\tpublic tearDownAfterClass() : void from class org.hibernate.search.jsr352.massindexing.MassIndexingJobWithCompositeIdTest to public shutDown() : void from class org.hibernate.search.jsr352.massindexing.impl.steps.lucene.EntityReaderTest", "diffLocations": [{"filePath": "jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/MassIndexingJobWithCompositeIdTest.java", "startLine": 48, "endLine": 51, "startColumn": 0, "endColumn": 0}, {"filePath": "jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/EntityReaderTest.java", "startLine": 103, "endLine": 108, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "@AfterClass\n\tpublic static void tearDownAfterClass() throws Exception {\n\t\temf.close();\n\t}", "filePathBefore": "jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/MassIndexingJobWithCompositeIdTest.java", "isPureRefactoring": true, "commitId": "ea4e402fd1d991e8c01ae3918047796dd2f3ab8b", "packageNameBefore": "org.hibernate.search.jsr352.massindexing", "classNameBefore": "org.hibernate.search.jsr352.massindexing.MassIndexingJobWithCompositeIdTest", "methodNameBefore": "org.hibernate.search.jsr352.massindexing.MassIndexingJobWithCompositeIdTest#tearDownAfterClass", "classSignatureBefore": "public class MassIndexingJobWithCompositeIdTest ", "methodNameBeforeSet": ["org.hibernate.search.jsr352.massindexing.MassIndexingJobWithCompositeIdTest#tearDownAfterClass"], "classNameBeforeSet": ["org.hibernate.search.jsr352.massindexing.MassIndexingJobWithCompositeIdTest"], "classSignatureBeforeSet": ["public class MassIndexingJobWithCompositeIdTest "], "purityCheckResultList": [{"isPure": true, "purityComment": "", "description": "Extra print lines - with non-mapped leaves", "mappingState": 5}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.jsr352.massindexing;\n\nimport static org.fest.assertions.Assertions.assertThat;\n\nimport java.time.LocalDate;\nimport java.time.temporal.ChronoUnit;\nimport java.util.Properties;\n\nimport javax.persistence.EntityManagerFactory;\nimport javax.persistence.Persistence;\n\nimport org.hibernate.criterion.Restrictions;\nimport org.hibernate.search.jpa.FullTextEntityManager;\nimport org.hibernate.search.jpa.Search;\nimport org.hibernate.search.jsr352.massindexing.test.entity.EntityWithEmbeddedId;\nimport org.hibernate.search.jsr352.massindexing.test.entity.EntityWithIdClass;\nimport org.hibernate.search.jsr352.test.util.JobTestUtil;\nimport org.hibernate.search.testsupport.TestForIssue;\nimport org.junit.After;\nimport org.junit.AfterClass;\nimport org.junit.Before;\nimport org.junit.Test;\n\n/**\n * Tests that mass indexing job can handle entity having\n * {@link javax.persistence.EmbeddedId} annotation, or\n * {@link javax.persistence.IdClass} annotation.\n *\n * @author Mincong Huang\n */\n@TestForIssue(jiraKey = \"HSEARCH-2615\")\npublic class MassIndexingJobWithCompositeIdTest {\n\n\tprivate static final LocalDate START = LocalDate.of( 2017, 6, 1 );\n\n\tprivate static final LocalDate END = LocalDate.of( 2017, 8, 1 );\n\n\tprivate static final EntityManagerFactory emf = Persistence.createEntityManagerFactory( \"h2\" );\n\n\tprivate FullTextEntityManager ftem;\n\n\t@AfterClass\n\tpublic static void tearDownAfterClass() throws Exception {\n\t\temf.close();\n\t}\n\n\t@Before\n\tpublic void setUp() throws Exception {\n\t\tftem = Search.getFullTextEntityManager( emf.createEntityManager() );\n\t\tftem.getTransaction().begin();\n\t\tfor ( LocalDate d = START; d.isBefore( END ); d = d.plusDays( 1 ) ) {\n\t\t\tftem.persist( new EntityWithIdClass( d ) );\n\t\t\tftem.persist( new EntityWithEmbeddedId( d ) );\n\t\t}\n\t\tftem.getTransaction().commit();\n\n\t\tassertThat( JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class ) ).isEqualTo( 0 );\n\t\tassertThat( JobTestUtil.nbDocumentsInIndex( emf, EntityWithEmbeddedId.class ) ).isEqualTo( 0 );\n\t}\n\n\t@After\n\tpublic void tearDown() throws Exception {\n\t\tftem.getTransaction().begin();\n\n\t\tftem.createQuery( \"delete from \" + EntityWithIdClass.class.getSimpleName() ).executeUpdate();\n\t\tftem.createQuery( \"delete from \" + EntityWithEmbeddedId.class.getSimpleName() ).executeUpdate();\n\n\t\tftem.purgeAll( EntityWithIdClass.class );\n\t\tftem.purgeAll( EntityWithEmbeddedId.class );\n\t\tftem.flushToIndexes();\n\n\t\tftem.getTransaction().commit();\n\t\tftem.close();\n\t}\n\n\t@Test\n\tpublic void canHandleIdClass_strategyFull() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithIdClass.class )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( START, END );\n\t\tassertThat( JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class ) ).isEqualTo( expectedDays );\n\t}\n\n\t@Test\n\tpublic void canHandleIdClass_strategyCriteria() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithIdClass.class )\n\t\t\t\t.restrictedBy( Restrictions.gt( \"month\", 6 ) )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( LocalDate.of( 2017, 7, 1 ), END );\n\t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class );\n\t\tassertThat( actualDays ).isEqualTo( expectedDays );\n\t}\n\n\t@Test\n\tpublic void canHandleEmbeddedId_strategyFull() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithEmbeddedId.class )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( START, END );\n\t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithEmbeddedId.class );\n\t\tassertThat( actualDays ).isEqualTo( expectedDays );\n\t}\n\n\t@Test\n\tpublic void canHandleEmbeddedId_strategyCriteria() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithEmbeddedId.class )\n\t\t\t\t.restrictedBy( Restrictions.gt( \"embeddableDateId.month\", 6 ) )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( LocalDate.of( 2017, 7, 1 ), END );\n\t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithEmbeddedId.class );\n\t\tassertThat( actualDays ).isEqualTo( expectedDays );\n\t}\n\n}\n", "filePathAfter": "jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/EntityReaderTest.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.jsr352.massindexing.impl.steps.lucene;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNull;\n\nimport java.util.Arrays;\nimport java.util.HashSet;\n\nimport javax.batch.runtime.context.JobContext;\nimport javax.batch.runtime.context.StepContext;\nimport javax.persistence.EntityManager;\nimport javax.persistence.EntityManagerFactory;\nimport javax.persistence.Persistence;\n\nimport org.hibernate.CacheMode;\nimport org.hibernate.search.jsr352.logging.impl.Log;\nimport org.hibernate.search.jsr352.massindexing.impl.JobContextData;\nimport org.hibernate.search.jsr352.massindexing.test.entity.Company;\nimport org.hibernate.search.jsr352.test.util.JobTestUtil;\nimport org.hibernate.search.util.logging.impl.LoggerFactory;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\nimport org.mockito.InjectMocks;\nimport org.mockito.Mock;\nimport org.mockito.Mockito;\nimport org.mockito.MockitoAnnotations;\n\n/**\n * Unit test for item reader validation.\n *\n * @author Mincong Huang\n */\npublic class EntityReaderTest {\n\n\tprivate static final Log log = LoggerFactory.make( Log.class );\n\n\tprivate static final String PERSISTENCE_UNIT_NAME = \"primary_pu\";\n\tprivate static final Company[] COMPANIES = new Company[]{\n\t\t\tnew Company( \"Red Hat\" ),\n\t\t\tnew Company( \"Google\" ),\n\t\t\tnew Company( \"Microsoft\" ) };\n\tprivate EntityManagerFactory emf;\n\n\t@Mock\n\tprivate JobContext mockedJobContext;\n\n\t@Mock\n\tprivate StepContext mockedStepContext;\n\n\t@InjectMocks\n\tprivate EntityReader entityReader;\n\n\t@Before\n\tpublic void setUp() {\n\t\tEntityManager em = null;\n\t\ttry {\n\t\t\temf = Persistence.createEntityManagerFactory( PERSISTENCE_UNIT_NAME );\n\t\t\tem = emf.createEntityManager();\n\t\t\tem.getTransaction().begin();\n\t\t\tfor ( Company c : COMPANIES ) {\n\t\t\t\tem.persist( c );\n\t\t\t}\n\t\t\tem.getTransaction().commit();\n\t\t}\n\t\tfinally {\n\t\t\ttry {\n\t\t\t\tem.close();\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tlog.error( e );\n\t\t\t}\n\t\t}\n\n\t\tfinal String cacheMode = CacheMode.IGNORE.name();\n\t\tfinal String entityName = Company.class.getName();\n\t\tfinal String entityFetchSize = String.valueOf( 1000 );\n\t\tfinal String checkpointInterval = String.valueOf( 1000 );\n\t\tfinal String hql = null;\n\t\tfinal String maxResults = String.valueOf( Integer.MAX_VALUE );\n\t\tfinal String partitionId = String.valueOf( 0 );\n\t\tentityReader = new EntityReader( cacheMode,\n\t\t\t\tentityName,\n\t\t\t\tentityFetchSize,\n\t\t\t\tcheckpointInterval,\n\t\t\t\thql,\n\t\t\t\tmaxResults,\n\t\t\t\tpartitionId,\n\t\t\t\tnull,\n\t\t\t\tnull,\n\t\t\t\tIndexScope.FULL_ENTITY.name() );\n\n\t\tMockitoAnnotations.initMocks( this );\n\t}\n\n\t@After\n\tpublic void shutDown() {\n\t\tif ( emf.isOpen() ) {\n\t\t\temf.close();\n\t\t}\n\t}\n\n\t@Test\n\tpublic void testReadItem_withoutBoundary() throws Exception {\n\t\t// mock job context\n\t\tJobContextData jobData = new JobContextData();\n\t\tjobData.setEntityManagerFactory( emf );\n\t\tjobData.setCustomQueryCriteria( new HashSet<>() );\n\t\tjobData.setEntityTypeDescriptors( Arrays.asList( JobTestUtil.createSimpleEntityTypeDescriptor( emf, Company.class ) ) );\n\t\tMockito.when( mockedJobContext.getTransientUserData() ).thenReturn( jobData );\n\n\t\t// mock step context\n\t\tMockito.doNothing().when( mockedStepContext ).setTransientUserData( Mockito.any() );\n\n\t\ttry {\n\t\t\tentityReader.open( null );\n\t\t\tfor ( int i = 0; i < COMPANIES.length; i++ ) {\n\t\t\t\tCompany c = (Company) entityReader.readItem();\n\t\t\t\tassertEquals( COMPANIES[i].getName(), c.getName() );\n\t\t\t}\n\t\t\t// no more item\n\t\t\tassertNull( entityReader.readItem() );\n\t\t}\n\t\tfinally {\n\t\t\tentityReader.close();\n\t\t}\n\t}\n}\n", "diffSourceCodeSet": [], "invokedMethodSet": [], "sourceCodeAfterRefactoring": "@After\n\tpublic void shutDown() {\n\t\tif ( emf.isOpen() ) {\n\t\t\temf.close();\n\t\t}\n\t}", "diffSourceCode": "-   48: \t@AfterClass\n-   49: \tpublic static void tearDownAfterClass() throws Exception {\n-   50: \t\temf.close();\n-   51: \t}\n-  103: \t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n-  104: \n-  105: \t\tint expectedDays = (int) ChronoUnit.DAYS.between( LocalDate.of( 2017, 7, 1 ), END );\n-  106: \t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class );\n-  107: \t\tassertThat( actualDays ).isEqualTo( expectedDays );\n+   48: \t\t\tnew Company( \"Google\" ),\n+   49: \t\t\tnew Company( \"Microsoft\" ) };\n+   50: \tprivate EntityManagerFactory emf;\n+   51: \n+  103: \t@After\n+  104: \tpublic void shutDown() {\n+  105: \t\tif ( emf.isOpen() ) {\n+  106: \t\t\temf.close();\n+  107: \t\t}\n   108: \t}\n", "uniqueId": "ea4e402fd1d991e8c01ae3918047796dd2f3ab8b_48_51__103_108", "moveFileExist": true, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "To refactor the provided code by moving the `tearDownAfterClass` method to an existing class, we will move it to the `JobContextUtil` class, which seems appropriate for utility methods related to job context management. \n\nHere\u2019s how the refactoring will be performed:\n\n1. **Target File Path**: We will move the method to `jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/JobContextUtil.java`.\n\n2. **Moved Class Code**: The `JobContextUtil` class will be updated to include the `tearDownAfterClass` method.\n\n3. **Refactored Method Code**: The `MassIndexingJobWithCompositeIdTest` class will be updated to call the moved method from `JobContextUtil`.\n\n### Refactoring Details\n\n**Target File Path**:\n```\njsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/JobContextUtil.java\n```\n\n**Moved Class Code**:\n```java\npackage org.hibernate.search.jsr352.massindexing.impl.util;\n\nimport javax.persistence.EntityManagerFactory;\n\npublic class JobContextUtil {\n\n    public static void tearDownAfterClass(EntityManagerFactory emf) throws Exception {\n        if (emf != null) {\n            emf.close();\n        }\n    }\n}\n```\n\n**Refactored Method Code**:\n```java\n@AfterClass\npublic static void tearDownAfterClass() throws Exception {\n    JobContextUtil.tearDownAfterClass(emf);\n}\n```\n\n### Final Output\n\nHere is the complete output in the required format:\n\n##########################\njsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/JobContextUtil.java\n##########################\n```java\npackage org.hibernate.search.jsr352.massindexing.impl.util;\n\nimport javax.persistence.EntityManagerFactory;\n\npublic class JobContextUtil {\n\n    public static void tearDownAfterClass(EntityManagerFactory emf) throws Exception {\n        if (emf != null) {\n            emf.close();\n        }\n    }\n}\n```\n##########################\n```java\n@AfterClass\npublic static void tearDownAfterClass() throws Exception {\n    JobContextUtil.tearDownAfterClass(emf);\n}\n```\n##########################", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\n@AfterClass\n\tpublic static void tearDownAfterClass() throws Exception {\n\t\temf.close();\n\t}\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.jsr352.massindexing;\n\nimport static org.fest.assertions.Assertions.assertThat;\n\nimport java.time.LocalDate;\nimport java.time.temporal.ChronoUnit;\nimport java.util.Properties;\n\nimport javax.persistence.EntityManagerFactory;\nimport javax.persistence.Persistence;\n\nimport org.hibernate.criterion.Restrictions;\nimport org.hibernate.search.jpa.FullTextEntityManager;\nimport org.hibernate.search.jpa.Search;\nimport org.hibernate.search.jsr352.massindexing.test.entity.EntityWithEmbeddedId;\nimport org.hibernate.search.jsr352.massindexing.test.entity.EntityWithIdClass;\nimport org.hibernate.search.jsr352.test.util.JobTestUtil;\nimport org.hibernate.search.testsupport.TestForIssue;\nimport org.junit.After;\nimport org.junit.AfterClass;\nimport org.junit.Before;\nimport org.junit.Test;\n\n/**\n * Tests that mass indexing job can handle entity having\n * {@link javax.persistence.EmbeddedId} annotation, or\n * {@link javax.persistence.IdClass} annotation.\n *\n * @author Mincong Huang\n */\n@TestForIssue(jiraKey = \"HSEARCH-2615\")\npublic class MassIndexingJobWithCompositeIdTest {\n\n\tprivate static final LocalDate START = LocalDate.of( 2017, 6, 1 );\n\n\tprivate static final LocalDate END = LocalDate.of( 2017, 8, 1 );\n\n\tprivate static final EntityManagerFactory emf = Persistence.createEntityManagerFactory( \"h2\" );\n\n\tprivate FullTextEntityManager ftem;\n\n\t@AfterClass\n\tpublic static void tearDownAfterClass() throws Exception {\n\t\temf.close();\n\t}\n\n\t@Before\n\tpublic void setUp() throws Exception {\n\t\tftem = Search.getFullTextEntityManager( emf.createEntityManager() );\n\t\tftem.getTransaction().begin();\n\t\tfor ( LocalDate d = START; d.isBefore( END ); d = d.plusDays( 1 ) ) {\n\t\t\tftem.persist( new EntityWithIdClass( d ) );\n\t\t\tftem.persist( new EntityWithEmbeddedId( d ) );\n\t\t}\n\t\tftem.getTransaction().commit();\n\n\t\tassertThat( JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class ) ).isEqualTo( 0 );\n\t\tassertThat( JobTestUtil.nbDocumentsInIndex( emf, EntityWithEmbeddedId.class ) ).isEqualTo( 0 );\n\t}\n\n\t@After\n\tpublic void tearDown() throws Exception {\n\t\tftem.getTransaction().begin();\n\n\t\tftem.createQuery( \"delete from \" + EntityWithIdClass.class.getSimpleName() ).executeUpdate();\n\t\tftem.createQuery( \"delete from \" + EntityWithEmbeddedId.class.getSimpleName() ).executeUpdate();\n\n\t\tftem.purgeAll( EntityWithIdClass.class );\n\t\tftem.purgeAll( EntityWithEmbeddedId.class );\n\t\tftem.flushToIndexes();\n\n\t\tftem.getTransaction().commit();\n\t\tftem.close();\n\t}\n\n\t@Test\n\tpublic void canHandleIdClass_strategyFull() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithIdClass.class )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( START, END );\n\t\tassertThat( JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class ) ).isEqualTo( expectedDays );\n\t}\n\n\t@Test\n\tpublic void canHandleIdClass_strategyCriteria() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithIdClass.class )\n\t\t\t\t.restrictedBy( Restrictions.gt( \"month\", 6 ) )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( LocalDate.of( 2017, 7, 1 ), END );\n\t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithIdClass.class );\n\t\tassertThat( actualDays ).isEqualTo( expectedDays );\n\t}\n\n\t@Test\n\tpublic void canHandleEmbeddedId_strategyFull() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithEmbeddedId.class )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( START, END );\n\t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithEmbeddedId.class );\n\t\tassertThat( actualDays ).isEqualTo( expectedDays );\n\t}\n\n\t@Test\n\tpublic void canHandleEmbeddedId_strategyCriteria() throws Exception {\n\t\tProperties props = MassIndexingJob.parameters()\n\t\t\t\t.forEntities( EntityWithEmbeddedId.class )\n\t\t\t\t.restrictedBy( Restrictions.gt( \"embeddableDateId.month\", 6 ) )\n\t\t\t\t.rowsPerPartition( 13 ) // Ensure there're more than 1 partition, so that a WHERE clause is applied.\n\t\t\t\t.checkpointInterval( 4 )\n\t\t\t\t.build();\n\t\tJobTestUtil.startJobAndWait( MassIndexingJob.NAME, props );\n\n\t\tint expectedDays = (int) ChronoUnit.DAYS.between( LocalDate.of( 2017, 7, 1 ), END );\n\t\tint actualDays = JobTestUtil.nbDocumentsInIndex( emf, EntityWithEmbeddedId.class );\n\t\tassertThat( actualDays ).isEqualTo( expectedDays );\n\t}\n\n}\n\nRefactoring Operation:\nMove And Rename Method\n\nProject Structure:\n['jsr352/core/src/main/java/org/hibernate/search/jsr352/context/jpa/EntityManagerFactoryRegistry.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/context/jpa/impl/ActiveSessionFactoryRegistry.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/context/jpa/impl/ActiveSessionFactoryRegistryUpdater.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/context/jpa/impl/MutableSessionFactoryRegistry.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/inject/scope/HibernateSearchJobScoped.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/inject/scope/HibernateSearchPartitionScoped.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/logging/impl/Log.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/MassIndexingJob.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/MassIndexingJobParameters.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/JobContextData.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/JobContextSetupListener.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/afterchunk/AfterChunkBatchlet.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/beforechunk/BeforeChunkBatchlet.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/EntityReader.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/IndexScope.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/LuceneDocProducer.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/LuceneDocWriter.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/PartitionContextData.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/PartitionMapper.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/PartitionProgress.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/ProgressAggregator.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/ProgressCollector.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/StepProgress.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/StepProgressSetupListener.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/CompositeIdOrder.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/EntityTypeDescriptor.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/IdOrder.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/JobContextUtil.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/MassIndexingPartitionProperties.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/PartitionBound.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/PersistenceUtil.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/SerializationUtil.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/SingularIdOrder.java', 'jsr352/core/src/main/java/org/hibernate/search/jsr352/massindexing/impl/util/ValidationUtil.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/BatchIndexingJobIT.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/MassIndexingJobParametersBuilderTest.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/MassIndexingJobWithCompositeIdTest.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/MassIndexingJobWithMultiTenancyIT.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/RestartChunkIT.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/EntityReaderTest.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/impl/steps/lucene/PartitionMapperTest.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/impl/util/SerializationUtilTest.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/impl/util/ValidationUtilTest.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/bridge/DateIdBridge.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/entity/Company.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/entity/CompanyGroup.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/entity/EntityWithEmbeddedId.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/entity/EntityWithIdClass.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/entity/Person.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/entity/WhoAmI.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/id/DatePK.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/massindexing/test/id/EmbeddableDateId.java', 'jsr352/core/src/test/java/org/hibernate/search/jsr352/test/util/JobTestUtil.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply move and rename method operation to the code to be refactored, output the target file path, moved class code, and refactored method code.\nNeed to move to an existing java file\nThe moved method code should be updated to the public static method.\nThe refactored method code should use the moved class to call the moved method.\nThe target file path should be the path of the existing class where the method is moved to.\n\n2. If refactoring is performed, output the target file path, moved class code, and refactored method code in the following format:\n\n##########################\ntarget_file_path\n##########################\nmoved_class_code\n##########################\nrefactored_method_code\n##########################\n\n\n\n"}, {"type": "Extract Method", "description": "Extract Method\tprivate composeExplicitlyIncludedPaths(relativePrefix String, nullSafeIncludePaths Set<String>, currentRemainingDepth Integer, nestedRemainingDepth Integer) : Set<String> extracted from public composeWithNested(parentTypeModel MappableTypeModel, relativePrefix String, maxDepth Integer, includePaths Set<String>) : IndexSchemaFilter in class org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter", "diffLocations": [{"filePath": "engine/src/main/java/org/hibernate/search/engine/mapper/mapping/building/impl/IndexSchemaFilter.java", "startLine": 145, "endLine": 223, "startColumn": 0, "endColumn": 0}, {"filePath": "engine/src/main/java/org/hibernate/search/engine/mapper/mapping/building/impl/IndexSchemaFilter.java", "startLine": 145, "endLine": 194, "startColumn": 0, "endColumn": 0}, {"filePath": "engine/src/main/java/org/hibernate/search/engine/mapper/mapping/building/impl/IndexSchemaFilter.java", "startLine": 196, "endLine": 231, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "public IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger maxDepth, Set<String> includePaths) {\n\t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\tif ( cyclicRecursionPath != null ) {\n\t\t\tcyclicRecursionPath += relativePrefix;\n\t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n\t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n\t\t}\n\n\t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n\n\t\t// The remaining composition depth according to \"this\" only\n\t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n\n\t\t// The remaining composition depth according to the nested IndexedEmbedded only\n\t\tInteger nestedRemainingDepth = maxDepth;\n\t\tif ( maxDepth == null ) {\n\t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n\t\t\t\t/*\n\t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n\t\t\t\t * the remaining composition depth is implicitly set to 0,\n\t\t\t\t * meaning no composition is allowed and paths are excluded unless\n\t\t\t\t * explicitly listed in \"includePaths\".\n\t\t\t\t */\n\t\t\t\tnestedRemainingDepth = 0;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n\t\t * (or null if the remaining composition depth was not set in the parent)...\n\t\t */\n\t\tInteger composedRemainingDepth = currentRemainingDepth;\n\t\tif ( composedRemainingDepth == null\n\t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n\t\t\t/*\n\t\t\t * ... but the nested filter can override it.\n\t\t\t */\n\t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n\t\t}\n\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn new IndexSchemaFilter(\n\t\t\t\tthis, parentTypeModel, relativePrefix,\n\t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n\t\t);\n\t}", "filePathBefore": "engine/src/main/java/org/hibernate/search/engine/mapper/mapping/building/impl/IndexSchemaFilter.java", "isPureRefactoring": true, "commitId": "35593714e0e5ffec22e4e9e93e12eaf3ab24d1a5", "packageNameBefore": "org.hibernate.search.engine.mapper.mapping.building.impl", "classNameBefore": "org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter", "methodNameBefore": "org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter#composeWithNested", "invokedMethod": "methodSignature: org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter#isPathIncluded\n methodBody: private static boolean isPathIncluded(Integer remainingDepth, Set<String> explicitlyIncludedPaths, String relativePath) {\nreturn isEveryPathIncludedByDefault(remainingDepth) || explicitlyIncludedPaths.contains(relativePath);\n}\nmethodSignature: org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter#getPathFromSameIndexedEmbeddedSinceNoCompositionLimits\n methodBody: private String getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(MappableTypeModel parentTypeModel, String relativePrefix) {\nif(hasCompositionLimits()){return null;\n}if(parent != null){if(this.relativePrefix.equals(relativePrefix) && this.parentTypeModel.isSubTypeOf(parentTypeModel)){return this.relativePrefix;\n}{String path=parent.getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(parentTypeModel,relativePrefix);\nreturn path == null ? null : path + this.relativePrefix;\n}}{return null;\n}}", "classSignatureBefore": "class IndexSchemaFilter ", "methodNameBeforeSet": ["org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter#composeWithNested"], "classNameBeforeSet": ["org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter"], "classSignatureBeforeSet": ["class IndexSchemaFilter "], "purityCheckResultList": [{"isPure": true, "purityComment": "Changes are within the Extract Method refactoring mechanics Severe changes", "description": "Return expression has been added within the Extract Method mechanics - with non-mapped leaves", "mappingState": 2}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.engine.mapper.mapping.building.impl;\n\nimport java.util.Collections;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.hibernate.search.engine.mapper.model.spi.MappableTypeModel;\nimport org.hibernate.search.util.SearchException;\n\n/**\n * A schema filter, responsible for deciding which parts of a mapping will actually make it to the index schema.\n * <p>\n * A schema filter is created at the root of a Pojo mapping (it accepts everything),\n * and also each time index embedding ({@code @IndexedEmbedded}) is used.\n *\n * <h3 id=\"filter-usage\">Filter usage</h3>\n * <p>\n * A schema filter is asked to provide advice about whether or not to trim down the schema in two cases:\n * <ul>\n *     <li>When a field is added by a bridge, the filter decides whether to include this field or not\n *     through its {@link #isPathIncluded(String)} method</li>\n *     <li>When a nested {@code @IndexedEmbedded} is requested, a new filter is created through the\n *     {@link #composeWithNested(MappableTypeModel, String, Integer, Set)} method, which may return a filter\n *     that {@link #isEveryPathExcluded() excludes every path}, meaning the {@code @IndexedEmbedded} will\n *     be ignored</li>\n * </ul>\n *\n * <h3 id=\"filter-properties\">Filter properties</h3>\n * <p>\n * A filter decides whether to include a path or not according to its two main properties:\n * <ul>\n *     <li>the {@link #remainingCompositionDepth remaining composition depth}</li>\n *     <li>the {@link #explicitlyIncludedPaths explicitly included paths}</li>\n * </ul>\n * <p>\n * The explicitly included paths, as their name suggests, define which paths\n * should be accepted by this filter no matter what.\n * <p>\n * The composition depth defines\n * {@link #isEveryPathIncludedByDefault(Integer) how paths that do not appear in the explicitly included paths should be treated}:\n * <ul>\n *     <li>if {@code <= 0}, paths are excluded by default</li>\n *     <li>if {@code null} or {@code > 0}, paths are included by default</li>\n * </ul>\n *\n * <h3 id=\"filter-composition\">Filter composition</h3>\n * <p>\n * Composed filters are created whenever a nested {@code @IndexedEmbedded} is encountered.\n * A composed filter will always enforce the restrictions of its parent filter,\n * plus some added restrictions depending on the properties of the nested {@code IndexedEmbedded}.\n * <p>\n * For more information about how filters are composed, see\n * {@link #composeWithNested(MappableTypeModel, String, Integer, Set)}.\n *\n * @author Yoann Rodiere\n */\nclass IndexSchemaFilter {\n\n\tprivate static final IndexSchemaFilter ROOT = new IndexSchemaFilter(\n\t\t\tnull, null, null, null, Collections.emptySet()\n\t);\n\n\tpublic static IndexSchemaFilter root() {\n\t\treturn ROOT;\n\t}\n\n\tprivate final IndexSchemaFilter parent;\n\tprivate final MappableTypeModel parentTypeModel;\n\tprivate final String relativePrefix;\n\n\t/**\n\t * Defines how deep indexed embedded are allowed to be composed.\n\t *\n\t * Note that composition depth only relates to IndexedEmbedded composition;\n\t * bridge-declared fields are only affected by path filtering,\n\t * whose default behavior (include or exclude) is determined by {@link #isEveryPathIncludedByDefault(Integer)}.\n\t */\n\tprivate final Integer remainingCompositionDepth;\n\n\t/**\n\t * Defines paths to be included even when the default behavior is to exclude paths.\n\t */\n\tprivate final Set<String> explicitlyIncludedPaths;\n\n\tprivate IndexSchemaFilter(IndexSchemaFilter parent, MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger remainingCompositionDepth, Set<String> explicitlyIncludedPaths) {\n\t\tthis.parent = parent;\n\t\tthis.parentTypeModel = parentTypeModel;\n\t\tthis.relativePrefix = relativePrefix;\n\t\tthis.remainingCompositionDepth = remainingCompositionDepth;\n\t\tthis.explicitlyIncludedPaths = explicitlyIncludedPaths;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn new StringBuilder( getClass().getSimpleName() )\n\t\t\t\t.append( \"[\" )\n\t\t\t\t.append( \"parentTypeModel=\" ).append( parentTypeModel )\n\t\t\t\t.append( \",relativePrefix=\" ).append( relativePrefix )\n\t\t\t\t.append( \",remainingCompositionDepth=\" ).append( remainingCompositionDepth )\n\t\t\t\t.append( \",explicitlyIncludedPaths=\" ).append( explicitlyIncludedPaths )\n\t\t\t\t.append( \"]\" )\n\t\t\t\t.toString();\n\t}\n\n\tpublic boolean isPathIncluded(String relativePath) {\n\t\treturn isPathIncluded( remainingCompositionDepth, explicitlyIncludedPaths, relativePath );\n\t}\n\n\tpublic boolean isEveryPathExcluded() {\n\t\treturn !isEveryPathIncludedByDefault( remainingCompositionDepth ) && !isAnyPathExplicitlyIncluded();\n\t}\n\n\tprivate String getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(MappableTypeModel parentTypeModel, String relativePrefix) {\n\t\tif ( hasCompositionLimits() ) {\n\t\t\treturn null;\n\t\t}\n\t\telse if ( parent != null ) {\n\t\t\tif ( this.relativePrefix.equals( relativePrefix )\n\t\t\t\t\t&& this.parentTypeModel.isSubTypeOf( parentTypeModel ) ) {\n\t\t\t\t// Same IndexedEmbedded as the one passed as a parameter\n\t\t\t\treturn this.relativePrefix;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tString path = parent.getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\t\t\treturn path == null ? null : path + this.relativePrefix;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t/*\n\t\t\t * No recursion limits, no parent: this is the root.\n\t\t\t * I we reach this point, it means there was no recursion limit at all,\n\t\t\t * but we did not encounter the IndexedEmbedded we were looking for.\n\t\t\t */\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tpublic IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger maxDepth, Set<String> includePaths) {\n\t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\tif ( cyclicRecursionPath != null ) {\n\t\t\tcyclicRecursionPath += relativePrefix;\n\t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n\t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n\t\t}\n\n\t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n\n\t\t// The remaining composition depth according to \"this\" only\n\t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n\n\t\t// The remaining composition depth according to the nested IndexedEmbedded only\n\t\tInteger nestedRemainingDepth = maxDepth;\n\t\tif ( maxDepth == null ) {\n\t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n\t\t\t\t/*\n\t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n\t\t\t\t * the remaining composition depth is implicitly set to 0,\n\t\t\t\t * meaning no composition is allowed and paths are excluded unless\n\t\t\t\t * explicitly listed in \"includePaths\".\n\t\t\t\t */\n\t\t\t\tnestedRemainingDepth = 0;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n\t\t * (or null if the remaining composition depth was not set in the parent)...\n\t\t */\n\t\tInteger composedRemainingDepth = currentRemainingDepth;\n\t\tif ( composedRemainingDepth == null\n\t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n\t\t\t/*\n\t\t\t * ... but the nested filter can override it.\n\t\t\t */\n\t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n\t\t}\n\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn new IndexSchemaFilter(\n\t\t\t\tthis, parentTypeModel, relativePrefix,\n\t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n\t\t);\n\t}\n\n\tprivate static boolean isPathIncluded(Integer remainingDepth, Set<String> explicitlyIncludedPaths, String relativePath) {\n\t\treturn isEveryPathIncludedByDefault( remainingDepth )\n\t\t\t\t|| explicitlyIncludedPaths.contains( relativePath );\n\t}\n\n\tprivate static boolean isEveryPathIncludedByDefault(Integer remainingDepth) {\n\t\t/*\n\t\t * A remaining composition depth of 0 or below means\n\t\t * paths should be excluded when filtering unless mentioned in explicitlyIncludedPaths.\n\t\t */\n\t\treturn remainingDepth == null || remainingDepth > 0;\n\t}\n\n\tprivate boolean isAnyPathExplicitlyIncluded() {\n\t\treturn !explicitlyIncludedPaths.isEmpty();\n\t}\n\n\tprivate boolean hasCompositionLimits() {\n\t\treturn remainingCompositionDepth != null || !explicitlyIncludedPaths.isEmpty();\n\t}\n}", "filePathAfter": "engine/src/main/java/org/hibernate/search/engine/mapper/mapping/building/impl/IndexSchemaFilter.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.engine.mapper.mapping.building.impl;\n\nimport java.util.Collections;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.hibernate.search.engine.mapper.model.spi.MappableTypeModel;\nimport org.hibernate.search.util.SearchException;\n\n/**\n * A schema filter, responsible for deciding which parts of a mapping will actually make it to the index schema.\n * <p>\n * A schema filter is created at the root of a Pojo mapping (it accepts everything),\n * and also each time index embedding ({@code @IndexedEmbedded}) is used.\n *\n * <h3 id=\"filter-usage\">Filter usage</h3>\n * <p>\n * A schema filter is asked to provide advice about whether or not to trim down the schema in two cases:\n * <ul>\n *     <li>When a field is added by a bridge, the filter decides whether to include this field or not\n *     through its {@link #isPathIncluded(String)} method</li>\n *     <li>When a nested {@code @IndexedEmbedded} is requested, a new filter is created through the\n *     {@link #composeWithNested(MappableTypeModel, String, Integer, Set)} method, which may return a filter\n *     that {@link #isEveryPathExcluded() excludes every path}, meaning the {@code @IndexedEmbedded} will\n *     be ignored</li>\n * </ul>\n *\n * <h3 id=\"filter-properties\">Filter properties</h3>\n * <p>\n * A filter decides whether to include a path or not according to its two main properties:\n * <ul>\n *     <li>the {@link #remainingCompositionDepth remaining composition depth}</li>\n *     <li>the {@link #explicitlyIncludedPaths explicitly included paths}</li>\n * </ul>\n * <p>\n * The explicitly included paths, as their name suggests, define which paths\n * should be accepted by this filter no matter what.\n * <p>\n * The composition depth defines\n * {@link #isEveryPathIncludedByDefault(Integer) how paths that do not appear in the explicitly included paths should be treated}:\n * <ul>\n *     <li>if {@code <= 0}, paths are excluded by default</li>\n *     <li>if {@code null} or {@code > 0}, paths are included by default</li>\n * </ul>\n *\n * <h3 id=\"filter-composition\">Filter composition</h3>\n * <p>\n * Composed filters are created whenever a nested {@code @IndexedEmbedded} is encountered.\n * A composed filter will always enforce the restrictions of its parent filter,\n * plus some added restrictions depending on the properties of the nested {@code IndexedEmbedded}.\n * <p>\n * For more information about how filters are composed, see\n * {@link #composeWithNested(MappableTypeModel, String, Integer, Set)}.\n *\n * @author Yoann Rodiere\n */\nclass IndexSchemaFilter {\n\n\tprivate static final IndexSchemaFilter ROOT = new IndexSchemaFilter(\n\t\t\tnull, null, null, null, Collections.emptySet()\n\t);\n\n\tpublic static IndexSchemaFilter root() {\n\t\treturn ROOT;\n\t}\n\n\tprivate final IndexSchemaFilter parent;\n\tprivate final MappableTypeModel parentTypeModel;\n\tprivate final String relativePrefix;\n\n\t/**\n\t * Defines how deep indexed embedded are allowed to be composed.\n\t *\n\t * Note that composition depth only relates to IndexedEmbedded composition;\n\t * bridge-declared fields are only affected by path filtering,\n\t * whose default behavior (include or exclude) is determined by {@link #isEveryPathIncludedByDefault(Integer)}.\n\t */\n\tprivate final Integer remainingCompositionDepth;\n\n\t/**\n\t * Defines paths to be included even when the default behavior is to exclude paths.\n\t */\n\tprivate final Set<String> explicitlyIncludedPaths;\n\n\tprivate IndexSchemaFilter(IndexSchemaFilter parent, MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger remainingCompositionDepth, Set<String> explicitlyIncludedPaths) {\n\t\tthis.parent = parent;\n\t\tthis.parentTypeModel = parentTypeModel;\n\t\tthis.relativePrefix = relativePrefix;\n\t\tthis.remainingCompositionDepth = remainingCompositionDepth;\n\t\tthis.explicitlyIncludedPaths = explicitlyIncludedPaths;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn new StringBuilder( getClass().getSimpleName() )\n\t\t\t\t.append( \"[\" )\n\t\t\t\t.append( \"parentTypeModel=\" ).append( parentTypeModel )\n\t\t\t\t.append( \",relativePrefix=\" ).append( relativePrefix )\n\t\t\t\t.append( \",remainingCompositionDepth=\" ).append( remainingCompositionDepth )\n\t\t\t\t.append( \",explicitlyIncludedPaths=\" ).append( explicitlyIncludedPaths )\n\t\t\t\t.append( \"]\" )\n\t\t\t\t.toString();\n\t}\n\n\tpublic boolean isPathIncluded(String relativePath) {\n\t\treturn isPathIncluded( remainingCompositionDepth, explicitlyIncludedPaths, relativePath );\n\t}\n\n\tpublic boolean isEveryPathExcluded() {\n\t\treturn !isEveryPathIncludedByDefault( remainingCompositionDepth ) && !isAnyPathExplicitlyIncluded();\n\t}\n\n\tprivate String getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(MappableTypeModel parentTypeModel, String relativePrefix) {\n\t\tif ( hasCompositionLimits() ) {\n\t\t\treturn null;\n\t\t}\n\t\telse if ( parent != null ) {\n\t\t\tif ( this.relativePrefix.equals( relativePrefix )\n\t\t\t\t\t&& this.parentTypeModel.isSubTypeOf( parentTypeModel ) ) {\n\t\t\t\t// Same IndexedEmbedded as the one passed as a parameter\n\t\t\t\treturn this.relativePrefix;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tString path = parent.getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\t\t\treturn path == null ? null : path + this.relativePrefix;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t/*\n\t\t\t * No recursion limits, no parent: this is the root.\n\t\t\t * I we reach this point, it means there was no recursion limit at all,\n\t\t\t * but we did not encounter the IndexedEmbedded we were looking for.\n\t\t\t */\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tpublic IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger maxDepth, Set<String> includePaths) {\n\t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\tif ( cyclicRecursionPath != null ) {\n\t\t\tcyclicRecursionPath += relativePrefix;\n\t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n\t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n\t\t}\n\n\t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n\n\t\t// The remaining composition depth according to \"this\" only\n\t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n\n\t\t// The remaining composition depth according to the nested IndexedEmbedded only\n\t\tInteger nestedRemainingDepth = maxDepth;\n\t\tif ( maxDepth == null ) {\n\t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n\t\t\t\t/*\n\t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n\t\t\t\t * the remaining composition depth is implicitly set to 0,\n\t\t\t\t * meaning no composition is allowed and paths are excluded unless\n\t\t\t\t * explicitly listed in \"includePaths\".\n\t\t\t\t */\n\t\t\t\tnestedRemainingDepth = 0;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n\t\t * (or null if the remaining composition depth was not set in the parent)...\n\t\t */\n\t\tInteger composedRemainingDepth = currentRemainingDepth;\n\t\tif ( composedRemainingDepth == null\n\t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n\t\t\t/*\n\t\t\t * ... but the nested filter can override it.\n\t\t\t */\n\t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n\t\t}\n\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = composeExplicitlyIncludedPaths(\n\t\t\t\trelativePrefix, nullSafeIncludePaths, currentRemainingDepth, nestedRemainingDepth\n\t\t);\n\n\t\treturn new IndexSchemaFilter(\n\t\t\t\tthis, parentTypeModel, relativePrefix,\n\t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n\t\t);\n\t}\n\n\tprivate Set<String> composeExplicitlyIncludedPaths(String relativePrefix, Set<String> nullSafeIncludePaths,\n\t\t\tInteger currentRemainingDepth, Integer nestedRemainingDepth) {\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn composedFilterExplicitlyIncludedPaths;\n\t}\n\n\tprivate static boolean isPathIncluded(Integer remainingDepth, Set<String> explicitlyIncludedPaths, String relativePath) {\n\t\treturn isEveryPathIncludedByDefault( remainingDepth )\n\t\t\t\t|| explicitlyIncludedPaths.contains( relativePath );\n\t}\n\n\tprivate static boolean isEveryPathIncludedByDefault(Integer remainingDepth) {\n\t\t/*\n\t\t * A remaining composition depth of 0 or below means\n\t\t * paths should be excluded when filtering unless mentioned in explicitlyIncludedPaths.\n\t\t */\n\t\treturn remainingDepth == null || remainingDepth > 0;\n\t}\n\n\tprivate boolean isAnyPathExplicitlyIncluded() {\n\t\treturn !explicitlyIncludedPaths.isEmpty();\n\t}\n\n\tprivate boolean hasCompositionLimits() {\n\t\treturn remainingCompositionDepth != null || !explicitlyIncludedPaths.isEmpty();\n\t}\n}", "diffSourceCodeSet": ["private Set<String> composeExplicitlyIncludedPaths(String relativePrefix, Set<String> nullSafeIncludePaths,\n\t\t\tInteger currentRemainingDepth, Integer nestedRemainingDepth) {\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn composedFilterExplicitlyIncludedPaths;\n\t}"], "invokedMethodSet": ["methodSignature: org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter#isPathIncluded\n methodBody: private static boolean isPathIncluded(Integer remainingDepth, Set<String> explicitlyIncludedPaths, String relativePath) {\nreturn isEveryPathIncludedByDefault(remainingDepth) || explicitlyIncludedPaths.contains(relativePath);\n}", "methodSignature: org.hibernate.search.engine.mapper.mapping.building.impl.IndexSchemaFilter#getPathFromSameIndexedEmbeddedSinceNoCompositionLimits\n methodBody: private String getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(MappableTypeModel parentTypeModel, String relativePrefix) {\nif(hasCompositionLimits()){return null;\n}if(parent != null){if(this.relativePrefix.equals(relativePrefix) && this.parentTypeModel.isSubTypeOf(parentTypeModel)){return this.relativePrefix;\n}{String path=parent.getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(parentTypeModel,relativePrefix);\nreturn path == null ? null : path + this.relativePrefix;\n}}{return null;\n}}"], "sourceCodeAfterRefactoring": "public IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger maxDepth, Set<String> includePaths) {\n\t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\tif ( cyclicRecursionPath != null ) {\n\t\t\tcyclicRecursionPath += relativePrefix;\n\t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n\t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n\t\t}\n\n\t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n\n\t\t// The remaining composition depth according to \"this\" only\n\t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n\n\t\t// The remaining composition depth according to the nested IndexedEmbedded only\n\t\tInteger nestedRemainingDepth = maxDepth;\n\t\tif ( maxDepth == null ) {\n\t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n\t\t\t\t/*\n\t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n\t\t\t\t * the remaining composition depth is implicitly set to 0,\n\t\t\t\t * meaning no composition is allowed and paths are excluded unless\n\t\t\t\t * explicitly listed in \"includePaths\".\n\t\t\t\t */\n\t\t\t\tnestedRemainingDepth = 0;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n\t\t * (or null if the remaining composition depth was not set in the parent)...\n\t\t */\n\t\tInteger composedRemainingDepth = currentRemainingDepth;\n\t\tif ( composedRemainingDepth == null\n\t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n\t\t\t/*\n\t\t\t * ... but the nested filter can override it.\n\t\t\t */\n\t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n\t\t}\n\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = composeExplicitlyIncludedPaths(\n\t\t\t\trelativePrefix, nullSafeIncludePaths, currentRemainingDepth, nestedRemainingDepth\n\t\t);\n\n\t\treturn new IndexSchemaFilter(\n\t\t\t\tthis, parentTypeModel, relativePrefix,\n\t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n\t\t);\n\t}\nprivate Set<String> composeExplicitlyIncludedPaths(String relativePrefix, Set<String> nullSafeIncludePaths,\n\t\t\tInteger currentRemainingDepth, Integer nestedRemainingDepth) {\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn composedFilterExplicitlyIncludedPaths;\n\t}", "diffSourceCode": "   145: \tpublic IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n   146: \t\t\tInteger maxDepth, Set<String> includePaths) {\n   147: \t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n   148: \t\tif ( cyclicRecursionPath != null ) {\n   149: \t\t\tcyclicRecursionPath += relativePrefix;\n   150: \t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n   151: \t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n   152: \t\t}\n   153: \n   154: \t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n   155: \n   156: \t\t// The remaining composition depth according to \"this\" only\n   157: \t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n   158: \n   159: \t\t// The remaining composition depth according to the nested IndexedEmbedded only\n   160: \t\tInteger nestedRemainingDepth = maxDepth;\n   161: \t\tif ( maxDepth == null ) {\n   162: \t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n   163: \t\t\t\t/*\n   164: \t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n   165: \t\t\t\t * the remaining composition depth is implicitly set to 0,\n   166: \t\t\t\t * meaning no composition is allowed and paths are excluded unless\n   167: \t\t\t\t * explicitly listed in \"includePaths\".\n   168: \t\t\t\t */\n   169: \t\t\t\tnestedRemainingDepth = 0;\n   170: \t\t\t}\n   171: \t\t}\n   172: \n   173: \t\t/*\n   174: \t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n   175: \t\t * (or null if the remaining composition depth was not set in the parent)...\n   176: \t\t */\n   177: \t\tInteger composedRemainingDepth = currentRemainingDepth;\n   178: \t\tif ( composedRemainingDepth == null\n   179: \t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n   180: \t\t\t/*\n   181: \t\t\t * ... but the nested filter can override it.\n   182: \t\t\t */\n   183: \t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n   184: \t\t}\n   185: \n-  186: \t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n-  187: \t\t/*\n-  188: \t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n-  189: \t\t * provided they are not filtered out by the current filter.\n-  190: \t\t */\n-  191: \t\tfor ( String path : nullSafeIncludePaths ) {\n-  192: \t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n-  193: \t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n-  194: \t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n-  195: \t\t\t\tint afterPreviousDotIndex = 0;\n-  196: \t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n-  197: \t\t\t\twhile ( nextDotIndex >= 0 ) {\n-  198: \t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n-  199: \t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n-  200: \t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n-  201: \t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n-  202: \t\t\t\t}\n-  203: \t\t\t}\n-  204: \t\t}\n-  205: \t\t/*\n-  206: \t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n-  207: \t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n-  208: \t\t */\n-  209: \t\tint relativePrefixLength = relativePrefix.length();\n-  210: \t\tfor ( String path : explicitlyIncludedPaths ) {\n-  211: \t\t\tif ( path.startsWith( relativePrefix ) ) {\n-  212: \t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n-  213: \t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n-  214: \t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n-  215: \t\t\t\t}\n-  216: \t\t\t}\n-  217: \t\t}\n-  218: \n-  219: \t\treturn new IndexSchemaFilter(\n-  220: \t\t\t\tthis, parentTypeModel, relativePrefix,\n-  221: \t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n-  222: \t\t);\n-  223: \t}\n-  224: \n-  225: \tprivate static boolean isPathIncluded(Integer remainingDepth, Set<String> explicitlyIncludedPaths, String relativePath) {\n-  226: \t\treturn isEveryPathIncludedByDefault( remainingDepth )\n-  227: \t\t\t\t|| explicitlyIncludedPaths.contains( relativePath );\n-  228: \t}\n-  229: \n-  230: \tprivate static boolean isEveryPathIncludedByDefault(Integer remainingDepth) {\n-  231: \t\t/*\n+  186: \t\tSet<String> composedFilterExplicitlyIncludedPaths = composeExplicitlyIncludedPaths(\n+  187: \t\t\t\trelativePrefix, nullSafeIncludePaths, currentRemainingDepth, nestedRemainingDepth\n+  188: \t\t);\n+  189: \n+  190: \t\treturn new IndexSchemaFilter(\n+  191: \t\t\t\tthis, parentTypeModel, relativePrefix,\n+  192: \t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n+  193: \t\t);\n+  194: \t}\n+  195: \n+  196: \tprivate Set<String> composeExplicitlyIncludedPaths(String relativePrefix, Set<String> nullSafeIncludePaths,\n+  197: \t\t\tInteger currentRemainingDepth, Integer nestedRemainingDepth) {\n+  198: \t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n+  199: \t\t/*\n+  200: \t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n+  201: \t\t * provided they are not filtered out by the current filter.\n+  202: \t\t */\n+  203: \t\tfor ( String path : nullSafeIncludePaths ) {\n+  204: \t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n+  205: \t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n+  206: \t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n+  207: \t\t\t\tint afterPreviousDotIndex = 0;\n+  208: \t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n+  209: \t\t\t\twhile ( nextDotIndex >= 0 ) {\n+  210: \t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n+  211: \t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n+  212: \t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n+  213: \t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n+  214: \t\t\t\t}\n+  215: \t\t\t}\n+  216: \t\t}\n+  217: \t\t/*\n+  218: \t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n+  219: \t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n+  220: \t\t */\n+  221: \t\tint relativePrefixLength = relativePrefix.length();\n+  222: \t\tfor ( String path : explicitlyIncludedPaths ) {\n+  223: \t\t\tif ( path.startsWith( relativePrefix ) ) {\n+  224: \t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n+  225: \t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n+  226: \t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n+  227: \t\t\t\t}\n+  228: \t\t\t}\n+  229: \t\t}\n+  230: \t\treturn composedFilterExplicitlyIncludedPaths;\n+  231: \t}\n", "uniqueId": "35593714e0e5ffec22e4e9e93e12eaf3ab24d1a5_145_223_196_231_145_194", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 1.8, "testResult": true, "coverageInfo": {"INSTRUCTION": {"missed": 0, "covered": 91}, "BRANCH": {"missed": 0, "covered": 16}, "LINE": {"missed": 0, "covered": 16}, "COMPLEXITY": {"missed": 0, "covered": 9}, "METHOD": {"missed": 0, "covered": 1}}, "refactoringMinerResult": true, "compileAndTestResult": false, "refactoredCode": "To improve the readability and maintainability of the `composeWithNested` method, we can extract several smaller methods that encapsulate specific functionalities. This will help in breaking down the complex logic into more manageable pieces.\n\nHere\u2019s the refactored code with the extracted methods:\n\n```java\npublic IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n        Integer maxDepth, Set<String> includePaths) {\n    String cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(parentTypeModel, relativePrefix);\n    if (cyclicRecursionPath != null) {\n        cyclicRecursionPath += relativePrefix;\n        throw new SearchException(\"Found an infinite IndexedEmbedded recursion involving path '\"\n                + cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\");\n    }\n\n    Set<String> nullSafeIncludePaths = getNullSafeIncludePaths(includePaths);\n    Integer currentRemainingDepth = getCurrentRemainingDepth();\n    Integer nestedRemainingDepth = getNestedRemainingDepth(maxDepth, nullSafeIncludePaths);\n\n    Integer composedRemainingDepth = calculateComposedRemainingDepth(currentRemainingDepth, nestedRemainingDepth);\n\n    Set<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n    addNestedFilterPaths(nullSafeIncludePaths, currentRemainingDepth, relativePrefix, composedFilterExplicitlyIncludedPaths);\n    addCurrentFilterPaths(relativePrefix, composedFilterExplicitlyIncludedPaths, nestedRemainingDepth);\n\n    return new IndexSchemaFilter(\n            this, parentTypeModel, relativePrefix,\n            composedRemainingDepth, composedFilterExplicitlyIncludedPaths\n    );\n}\n\nprivate Set<String> getNullSafeIncludePaths(Set<String> includePaths) {\n    return includePaths == null ? Collections.emptySet() : includePaths;\n}\n\nprivate Integer getCurrentRemainingDepth() {\n    return remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n}\n\nprivate Integer getNestedRemainingDepth(Integer maxDepth, Set<String> nullSafeIncludePaths) {\n    if (maxDepth == null && !nullSafeIncludePaths.isEmpty()) {\n        return 0; // No composition allowed\n    }\n    return maxDepth;\n}\n\nprivate Integer calculateComposedRemainingDepth(Integer currentRemainingDepth, Integer nestedRemainingDepth) {\n    Integer composedRemainingDepth = currentRemainingDepth;\n    if (composedRemainingDepth == null || (nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth)) {\n        composedRemainingDepth = nestedRemainingDepth;\n    }\n    return composedRemainingDepth;\n}\n\nprivate void addNestedFilterPaths(Set<String> nullSafeIncludePaths, Integer currentRemainingDepth, String relativePrefix,\n        Set<String> composedFilterExplicitlyIncludedPaths) {\n    for (String path : nullSafeIncludePaths) {\n        if (isPathIncluded(currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path)) {\n            composedFilterExplicitlyIncludedPaths.add(path);\n            addSubPaths(path, composedFilterExplicitlyIncludedPaths);\n        }\n    }\n}\n\nprivate void addSubPaths(String path, Set<String> composedFilterExplicitlyIncludedPaths) {\n    int afterPreviousDotIndex = 0;\n    int nextDotIndex = path.indexOf('.', afterPreviousDotIndex);\n    while (nextDotIndex >= 0) {\n        String subPath = path.substring(0, nextDotIndex);\n        composedFilterExplicitlyIncludedPaths.add(subPath);\n        afterPreviousDotIndex = nextDotIndex + 1;\n        nextDotIndex = path.indexOf('.', afterPreviousDotIndex);\n    }\n}\n\nprivate void addCurrentFilterPaths(String relativePrefix, Set<String> composedFilterExplicitlyIncludedPaths,\n        Integer nestedRemainingDepth) {\n    int relativePrefixLength = relativePrefix.length();\n    for (String path : explicitlyIncludedPaths) {\n        if (path.startsWith(relativePrefix)) {\n            String pathRelativeToNestedFilter = path.substring(relativePrefixLength);\n            if (isPathIncluded(nestedRemainingDepth, getNullSafeIncludePaths(null), pathRelativeToNestedFilter)) {\n                composedFilterExplicitlyIncludedPaths.add(pathRelativeToNestedFilter);\n            }\n        }\n    }\n}\n```\n\n### Explanation of Changes:\n1. **Extracted Methods**: \n   - `getNullSafeIncludePaths`: Handles null checks for `includePaths`.\n   - `getCurrentRemainingDepth`: Calculates the current remaining depth.\n   - `getNestedRemainingDepth`: Determines the nested remaining depth based on `maxDepth`.\n   - `calculateComposedRemainingDepth`: Computes the composed remaining depth.\n   - `addNestedFilterPaths`: Adds paths from the nested filter to the composed filter.\n   - `addSubPaths`: Adds sub-paths leading to the specified path.\n   - `addCurrentFilterPaths`: Adds paths from the current filter to the composed filter.\n\n2. **Improved Readability**: The main method `composeWithNested` is now cleaner and easier to understand, as it delegates specific tasks to well-named helper methods.\n\nThis refactoring enhances the modularity of the code, making it easier to maintain and test individual components.", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\npublic IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger maxDepth, Set<String> includePaths) {\n\t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\tif ( cyclicRecursionPath != null ) {\n\t\t\tcyclicRecursionPath += relativePrefix;\n\t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n\t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n\t\t}\n\n\t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n\n\t\t// The remaining composition depth according to \"this\" only\n\t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n\n\t\t// The remaining composition depth according to the nested IndexedEmbedded only\n\t\tInteger nestedRemainingDepth = maxDepth;\n\t\tif ( maxDepth == null ) {\n\t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n\t\t\t\t/*\n\t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n\t\t\t\t * the remaining composition depth is implicitly set to 0,\n\t\t\t\t * meaning no composition is allowed and paths are excluded unless\n\t\t\t\t * explicitly listed in \"includePaths\".\n\t\t\t\t */\n\t\t\t\tnestedRemainingDepth = 0;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n\t\t * (or null if the remaining composition depth was not set in the parent)...\n\t\t */\n\t\tInteger composedRemainingDepth = currentRemainingDepth;\n\t\tif ( composedRemainingDepth == null\n\t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n\t\t\t/*\n\t\t\t * ... but the nested filter can override it.\n\t\t\t */\n\t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n\t\t}\n\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn new IndexSchemaFilter(\n\t\t\t\tthis, parentTypeModel, relativePrefix,\n\t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n\t\t);\n\t}\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.engine.mapper.mapping.building.impl;\n\nimport java.util.Collections;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.hibernate.search.engine.mapper.model.spi.MappableTypeModel;\nimport org.hibernate.search.util.SearchException;\n\n/**\n * A schema filter, responsible for deciding which parts of a mapping will actually make it to the index schema.\n * <p>\n * A schema filter is created at the root of a Pojo mapping (it accepts everything),\n * and also each time index embedding ({@code @IndexedEmbedded}) is used.\n *\n * <h3 id=\"filter-usage\">Filter usage</h3>\n * <p>\n * A schema filter is asked to provide advice about whether or not to trim down the schema in two cases:\n * <ul>\n *     <li>When a field is added by a bridge, the filter decides whether to include this field or not\n *     through its {@link #isPathIncluded(String)} method</li>\n *     <li>When a nested {@code @IndexedEmbedded} is requested, a new filter is created through the\n *     {@link #composeWithNested(MappableTypeModel, String, Integer, Set)} method, which may return a filter\n *     that {@link #isEveryPathExcluded() excludes every path}, meaning the {@code @IndexedEmbedded} will\n *     be ignored</li>\n * </ul>\n *\n * <h3 id=\"filter-properties\">Filter properties</h3>\n * <p>\n * A filter decides whether to include a path or not according to its two main properties:\n * <ul>\n *     <li>the {@link #remainingCompositionDepth remaining composition depth}</li>\n *     <li>the {@link #explicitlyIncludedPaths explicitly included paths}</li>\n * </ul>\n * <p>\n * The explicitly included paths, as their name suggests, define which paths\n * should be accepted by this filter no matter what.\n * <p>\n * The composition depth defines\n * {@link #isEveryPathIncludedByDefault(Integer) how paths that do not appear in the explicitly included paths should be treated}:\n * <ul>\n *     <li>if {@code <= 0}, paths are excluded by default</li>\n *     <li>if {@code null} or {@code > 0}, paths are included by default</li>\n * </ul>\n *\n * <h3 id=\"filter-composition\">Filter composition</h3>\n * <p>\n * Composed filters are created whenever a nested {@code @IndexedEmbedded} is encountered.\n * A composed filter will always enforce the restrictions of its parent filter,\n * plus some added restrictions depending on the properties of the nested {@code IndexedEmbedded}.\n * <p>\n * For more information about how filters are composed, see\n * {@link #composeWithNested(MappableTypeModel, String, Integer, Set)}.\n *\n * @author Yoann Rodiere\n */\nclass IndexSchemaFilter {\n\n\tprivate static final IndexSchemaFilter ROOT = new IndexSchemaFilter(\n\t\t\tnull, null, null, null, Collections.emptySet()\n\t);\n\n\tpublic static IndexSchemaFilter root() {\n\t\treturn ROOT;\n\t}\n\n\tprivate final IndexSchemaFilter parent;\n\tprivate final MappableTypeModel parentTypeModel;\n\tprivate final String relativePrefix;\n\n\t/**\n\t * Defines how deep indexed embedded are allowed to be composed.\n\t *\n\t * Note that composition depth only relates to IndexedEmbedded composition;\n\t * bridge-declared fields are only affected by path filtering,\n\t * whose default behavior (include or exclude) is determined by {@link #isEveryPathIncludedByDefault(Integer)}.\n\t */\n\tprivate final Integer remainingCompositionDepth;\n\n\t/**\n\t * Defines paths to be included even when the default behavior is to exclude paths.\n\t */\n\tprivate final Set<String> explicitlyIncludedPaths;\n\n\tprivate IndexSchemaFilter(IndexSchemaFilter parent, MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger remainingCompositionDepth, Set<String> explicitlyIncludedPaths) {\n\t\tthis.parent = parent;\n\t\tthis.parentTypeModel = parentTypeModel;\n\t\tthis.relativePrefix = relativePrefix;\n\t\tthis.remainingCompositionDepth = remainingCompositionDepth;\n\t\tthis.explicitlyIncludedPaths = explicitlyIncludedPaths;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn new StringBuilder( getClass().getSimpleName() )\n\t\t\t\t.append( \"[\" )\n\t\t\t\t.append( \"parentTypeModel=\" ).append( parentTypeModel )\n\t\t\t\t.append( \",relativePrefix=\" ).append( relativePrefix )\n\t\t\t\t.append( \",remainingCompositionDepth=\" ).append( remainingCompositionDepth )\n\t\t\t\t.append( \",explicitlyIncludedPaths=\" ).append( explicitlyIncludedPaths )\n\t\t\t\t.append( \"]\" )\n\t\t\t\t.toString();\n\t}\n\n\tpublic boolean isPathIncluded(String relativePath) {\n\t\treturn isPathIncluded( remainingCompositionDepth, explicitlyIncludedPaths, relativePath );\n\t}\n\n\tpublic boolean isEveryPathExcluded() {\n\t\treturn !isEveryPathIncludedByDefault( remainingCompositionDepth ) && !isAnyPathExplicitlyIncluded();\n\t}\n\n\tprivate String getPathFromSameIndexedEmbeddedSinceNoCompositionLimits(MappableTypeModel parentTypeModel, String relativePrefix) {\n\t\tif ( hasCompositionLimits() ) {\n\t\t\treturn null;\n\t\t}\n\t\telse if ( parent != null ) {\n\t\t\tif ( this.relativePrefix.equals( relativePrefix )\n\t\t\t\t\t&& this.parentTypeModel.isSubTypeOf( parentTypeModel ) ) {\n\t\t\t\t// Same IndexedEmbedded as the one passed as a parameter\n\t\t\t\treturn this.relativePrefix;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tString path = parent.getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\t\t\treturn path == null ? null : path + this.relativePrefix;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t/*\n\t\t\t * No recursion limits, no parent: this is the root.\n\t\t\t * I we reach this point, it means there was no recursion limit at all,\n\t\t\t * but we did not encounter the IndexedEmbedded we were looking for.\n\t\t\t */\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tpublic IndexSchemaFilter composeWithNested(MappableTypeModel parentTypeModel, String relativePrefix,\n\t\t\tInteger maxDepth, Set<String> includePaths) {\n\t\tString cyclicRecursionPath = getPathFromSameIndexedEmbeddedSinceNoCompositionLimits( parentTypeModel, relativePrefix );\n\t\tif ( cyclicRecursionPath != null ) {\n\t\t\tcyclicRecursionPath += relativePrefix;\n\t\t\tthrow new SearchException( \"Found an infinite IndexedEmbedded recursion involving path '\"\n\t\t\t\t\t+ cyclicRecursionPath + \"' on type '\" + parentTypeModel + \"'\" );\n\t\t}\n\n\t\tSet<String> nullSafeIncludePaths = includePaths == null ? Collections.emptySet() : includePaths;\n\n\t\t// The remaining composition depth according to \"this\" only\n\t\tInteger currentRemainingDepth = remainingCompositionDepth == null ? null : remainingCompositionDepth - 1;\n\n\t\t// The remaining composition depth according to the nested IndexedEmbedded only\n\t\tInteger nestedRemainingDepth = maxDepth;\n\t\tif ( maxDepth == null ) {\n\t\t\tif ( !nullSafeIncludePaths.isEmpty() ) {\n\t\t\t\t/*\n\t\t\t\t * If no max depth was provided and \"includePaths\" was provided,\n\t\t\t\t * the remaining composition depth is implicitly set to 0,\n\t\t\t\t * meaning no composition is allowed and paths are excluded unless\n\t\t\t\t * explicitly listed in \"includePaths\".\n\t\t\t\t */\n\t\t\t\tnestedRemainingDepth = 0;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * By default, a composed filters' remaining composition depth is its parent's minus one\n\t\t * (or null if the remaining composition depth was not set in the parent)...\n\t\t */\n\t\tInteger composedRemainingDepth = currentRemainingDepth;\n\t\tif ( composedRemainingDepth == null\n\t\t\t\t|| nestedRemainingDepth != null && composedRemainingDepth > nestedRemainingDepth ) {\n\t\t\t/*\n\t\t\t * ... but the nested filter can override it.\n\t\t\t */\n\t\t\tcomposedRemainingDepth = nestedRemainingDepth;\n\t\t}\n\n\t\tSet<String> composedFilterExplicitlyIncludedPaths = new HashSet<>();\n\t\t/*\n\t\t * Add the nested filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they are not filtered out by the current filter.\n\t\t */\n\t\tfor ( String path : nullSafeIncludePaths ) {\n\t\t\tif ( isPathIncluded( currentRemainingDepth, explicitlyIncludedPaths, relativePrefix + path ) ) {\n\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( path );\n\t\t\t\t// Also add paths leading to this path (so that object nodes are not excluded)\n\t\t\t\tint afterPreviousDotIndex = 0;\n\t\t\t\tint nextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\twhile ( nextDotIndex >= 0 ) {\n\t\t\t\t\tString subPath = path.substring( 0, nextDotIndex );\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( subPath );\n\t\t\t\t\tafterPreviousDotIndex = nextDotIndex + 1;\n\t\t\t\t\tnextDotIndex = path.indexOf( '.', afterPreviousDotIndex );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/*\n\t\t * Add the current filter's explicitly included paths to the composed filter's \"explicitlyIncludedPaths\",\n\t\t * provided they start with the nested filter's prefix and are not filtered out by the nested filter.\n\t\t */\n\t\tint relativePrefixLength = relativePrefix.length();\n\t\tfor ( String path : explicitlyIncludedPaths ) {\n\t\t\tif ( path.startsWith( relativePrefix ) ) {\n\t\t\t\tString pathRelativeToNestedFilter = path.substring( relativePrefixLength );\n\t\t\t\tif ( isPathIncluded( nestedRemainingDepth, nullSafeIncludePaths, pathRelativeToNestedFilter ) ) {\n\t\t\t\t\tcomposedFilterExplicitlyIncludedPaths.add( pathRelativeToNestedFilter );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn new IndexSchemaFilter(\n\t\t\t\tthis, parentTypeModel, relativePrefix,\n\t\t\t\tcomposedRemainingDepth, composedFilterExplicitlyIncludedPaths\n\t\t);\n\t}\n\n\tprivate static boolean isPathIncluded(Integer remainingDepth, Set<String> explicitlyIncludedPaths, String relativePath) {\n\t\treturn isEveryPathIncludedByDefault( remainingDepth )\n\t\t\t\t|| explicitlyIncludedPaths.contains( relativePath );\n\t}\n\n\tprivate static boolean isEveryPathIncludedByDefault(Integer remainingDepth) {\n\t\t/*\n\t\t * A remaining composition depth of 0 or below means\n\t\t * paths should be excluded when filtering unless mentioned in explicitlyIncludedPaths.\n\t\t */\n\t\treturn remainingDepth == null || remainingDepth > 0;\n\t}\n\n\tprivate boolean isAnyPathExplicitlyIncluded() {\n\t\treturn !explicitlyIncludedPaths.isEmpty();\n\t}\n\n\tprivate boolean hasCompositionLimits() {\n\t\treturn remainingCompositionDepth != null || !explicitlyIncludedPaths.isEmpty();\n\t}\n}\n\nRefactoring Operation:\nExtract Method\n\nInstructions:\n1. Analyze the provided code and class content, apply relevant refactoring operation to the code to be refactored.\n2. If refactoring is performed, output the refactored_method_code in the following format:\n##########################\nrefactored_method_code\n##########################\n\n\n\n"}, {"type": "Extract Method", "description": "Extract Method\tprivate assertEventUUIDVersion(session Session, expectedVersion int) : void extracted from public validMappingWithCustomUuidGenerator() : void in class org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT", "diffLocations": [{"filePath": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "startLine": 270, "endLine": 315, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "startLine": 268, "endLine": 310, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "startLine": 373, "endLine": 380, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}", "filePathBefore": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "isPureRefactoring": true, "commitId": "fe9d94f5875ba28017d584653e397cffe57d7555", "packageNameBefore": "org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing", "classNameBefore": "org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT", "methodNameBefore": "org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#validMappingWithCustomUuidGenerator", "invokedMethod": "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#getId\n methodBody: public Integer getId() {\nreturn id;\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setIndexedField\n methodBody: public void setIndexedField(String indexedField) {\nthis.indexedField=indexedField;\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.KeysStatementInspector#countByKey\n methodBody: public int countByKey(String key) {\nreturn sqlByKey.get(key).size();\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setId\n methodBody: public void setId(Integer id) {\nthis.id=id;\n}", "classSignatureBefore": "public class OutboxPollingCustomEntityMappingIT ", "methodNameBeforeSet": ["org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#validMappingWithCustomUuidGenerator"], "classNameBeforeSet": ["org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT"], "classSignatureBeforeSet": ["public class OutboxPollingCustomEntityMappingIT "], "purityCheckResultList": [{"isPure": true, "purityComment": "Changes are within the Extract Method refactoring mechanics", "description": "All replacements have been justified - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.assertThatThrownBy;\nimport static org.awaitility.Awaitility.await;\nimport static org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmUtils.with;\nimport static org.junit.Assume.assumeTrue;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport javax.persistence.Basic;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\n\nimport org.hibernate.SessionFactory;\nimport org.hibernate.boot.MappingException;\nimport org.hibernate.dialect.Dialect;\nimport org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;\nimport org.hibernate.engine.spi.SessionFactoryImplementor;\nimport org.hibernate.resource.jdbc.spi.StatementInspector;\nimport org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.FilteringOutboxEventFinder;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cfg.HibernateOrmMapperOutboxPollingSettings;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.OutboxPollingAgentAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxEvent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxPollingOutboxEventAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.GenericField;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.Indexed;\nimport org.hibernate.search.util.common.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.rule.BackendMock;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.CoordinationStrategyExpectations;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmSetupHelper;\n\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class OutboxPollingCustomEntityMappingIT {\n\n\tprivate static final String CUSTOM_SCHEMA = \"CUSTOM_SCHEMA\";\n\tprivate static final String ORIGINAL_OUTBOX_EVENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_OUTBOX_EVENT_TABLE;\n\tprivate static final String CUSTOM_OUTBOX_EVENT_TABLE_NAME = \"CUSTOM_OUTBOX_EVENT\";\n\n\tprivate static final String ORIGINAL_AGENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_AGENT_TABLE;\n\tprivate static final String CUSTOM_AGENT_TABLE_NAME = \"CUSTOM_AGENT\";\n\tprivate static final String VALID_OUTBOX_EVENT_MAPPING;\n\tprivate static final String VALID_AGENT_EVENT_MAPPING;\n\n\tprivate static final String[] SQL_KEYS;\n\n\tstatic {\n\t\tVALID_OUTBOX_EVENT_MAPPING = OutboxPollingOutboxEventAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME );\n\n\t\tVALID_AGENT_EVENT_MAPPING = OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME );\n\n\t\tSQL_KEYS = new String[] {\n\t\t\t\tORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME,\n\t\t\t\tORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME,\n\t\t\t\tCUSTOM_SCHEMA,\n\t\t};\n\t}\n\n\t@Rule\n\tpublic BackendMock backendMock = new BackendMock();\n\n\t@Rule\n\tpublic OrmSetupHelper ormSetupHelper = OrmSetupHelper.withBackendMock( backendMock )\n\t\t\t.coordinationStrategy( CoordinationStrategyExpectations.outboxPolling() );\n\n\tprivate SessionFactory sessionFactory;\n\n\tprivate final FilteringOutboxEventFinder outboxEventFinder = new FilteringOutboxEventFinder();\n\n\t@Test\n\tpublic void wrongOutboxEventMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void wrongAgentMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void validOutboxEventMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isZero();\n\t}\n\n\t@Test\n\tpublic void validAgentMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void conflictingAgentMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox polling agent configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void conflictingOutboxeventMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox event configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNames() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidDataType() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomFailingUuidGenerator() {\n\t\tassertThatThrownBy(\n\t\t\t\t() -> ormSetupHelper.start()\n\t\t\t\t\t\t.withProperty(\n\t\t\t\t\t\t\t\t\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\",\n\t\t\t\t\t\t\t\t\"something-incompatible\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.setup( IndexedEntity.class )\n\t\t).isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContainingAll(\n\t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n\t\t\t\t\t\t\"something-incompatible\",\n\t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n\t\t\t\t);\n\t}\n\n\tprivate Dialect getDialect() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getDialect();\n\t}\n\n\tprivate NameQualifierSupport getNameQualifierSupport() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getNameQualifierSupport();\n\t}\n\n\t@Entity(name = IndexedEntity.INDEX)\n\t@Indexed(index = IndexedEntity.INDEX)\n\tpublic static class IndexedEntity {\n\t\tstatic final String INDEX = \"IndexedEntity\";\n\n\t\t@Id\n\t\tprivate Integer id;\n\n\t\t@Basic\n\t\t@GenericField\n\t\tprivate String indexedField;\n\n\t\tpublic IndexedEntity() {\n\t\t}\n\n\t\tpublic IndexedEntity(Integer id, String indexedField) {\n\t\t\tthis.id = id;\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\n\t\tpublic Integer getId() {\n\t\t\treturn id;\n\t\t}\n\n\t\tpublic void setId(Integer id) {\n\t\t\tthis.id = id;\n\t\t}\n\n\t\tpublic String getIndexedField() {\n\t\t\treturn indexedField;\n\t\t}\n\n\t\tpublic void setIndexedField(String indexedField) {\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\t}\n\n\tpublic static class KeysStatementInspector implements StatementInspector {\n\n\t\tprivate Map<String, List<String>> sqlByKey = new HashMap<>();\n\n\t\tpublic KeysStatementInspector() {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tsqlByKey.put( key, new ArrayList<>() );\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic String inspect(String sql) {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tif ( Arrays.stream( sql.split( \"[^A-Za-z0-9_-]\" ) ).anyMatch( token -> key.equals( token ) ) ) {\n\t\t\t\t\tsqlByKey.get( key ).add( sql );\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sql;\n\t\t}\n\n\t\tpublic int countByKey(String key) {\n\t\t\treturn sqlByKey.get( key ).size();\n\t\t}\n\t}\n}\n", "filePathAfter": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.assertThatThrownBy;\nimport static org.awaitility.Awaitility.await;\nimport static org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmUtils.with;\nimport static org.junit.Assume.assumeTrue;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport javax.persistence.Basic;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\n\nimport org.hibernate.Session;\nimport org.hibernate.SessionFactory;\nimport org.hibernate.boot.MappingException;\nimport org.hibernate.dialect.Dialect;\nimport org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;\nimport org.hibernate.engine.spi.SessionFactoryImplementor;\nimport org.hibernate.resource.jdbc.spi.StatementInspector;\nimport org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.FilteringOutboxEventFinder;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cfg.HibernateOrmMapperOutboxPollingSettings;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.Agent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.OutboxPollingAgentAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxEvent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxPollingOutboxEventAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.GenericField;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.Indexed;\nimport org.hibernate.search.util.common.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.rule.BackendMock;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.CoordinationStrategyExpectations;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmSetupHelper;\n\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class OutboxPollingCustomEntityMappingIT {\n\n\tprivate static final String CUSTOM_SCHEMA = \"CUSTOM_SCHEMA\";\n\tprivate static final String ORIGINAL_OUTBOX_EVENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_OUTBOX_EVENT_TABLE;\n\tprivate static final String CUSTOM_OUTBOX_EVENT_TABLE_NAME = \"CUSTOM_OUTBOX_EVENT\";\n\n\tprivate static final String ORIGINAL_AGENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_AGENT_TABLE;\n\tprivate static final String CUSTOM_AGENT_TABLE_NAME = \"CUSTOM_AGENT\";\n\tprivate static final String VALID_OUTBOX_EVENT_MAPPING;\n\tprivate static final String VALID_AGENT_EVENT_MAPPING;\n\n\tprivate static final String[] SQL_KEYS;\n\n\tstatic {\n\t\tVALID_OUTBOX_EVENT_MAPPING = OutboxPollingOutboxEventAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME );\n\n\t\tVALID_AGENT_EVENT_MAPPING = OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME );\n\n\t\tSQL_KEYS = new String[] {\n\t\t\t\tORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME,\n\t\t\t\tORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME,\n\t\t\t\tCUSTOM_SCHEMA,\n\t\t};\n\t}\n\n\t@Rule\n\tpublic BackendMock backendMock = new BackendMock();\n\n\t@Rule\n\tpublic OrmSetupHelper ormSetupHelper = OrmSetupHelper.withBackendMock( backendMock )\n\t\t\t.coordinationStrategy( CoordinationStrategyExpectations.outboxPolling() );\n\n\tprivate SessionFactory sessionFactory;\n\n\tprivate final FilteringOutboxEventFinder outboxEventFinder = new FilteringOutboxEventFinder();\n\n\t@Test\n\tpublic void wrongOutboxEventMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void wrongAgentMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void validOutboxEventMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isZero();\n\t}\n\n\t@Test\n\tpublic void validAgentMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void conflictingAgentMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox polling agent configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void conflictingOutboxeventMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox event configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNames() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 4 );\n\t\t\t\tassertAgentUUIDVersion( session, 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 1 );\n\t\t\t\tassertAgentUUIDVersion( session, 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidDataType() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 4 );\n\t\t\t\tassertAgentUUIDVersion( session, 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomFailingUuidGenerator() {\n\t\tassertThatThrownBy(\n\t\t\t\t() -> ormSetupHelper.start()\n\t\t\t\t\t\t.withProperty(\n\t\t\t\t\t\t\t\t\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\",\n\t\t\t\t\t\t\t\t\"something-incompatible\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.setup( IndexedEntity.class )\n\t\t).isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContainingAll(\n\t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n\t\t\t\t\t\t\"something-incompatible\",\n\t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n\t\t\t\t);\n\t}\n\n\tprivate void assertEventUUIDVersion(Session session, int expectedVersion) {\n\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\tassertThat( events )\n\t\t\t\t.hasSize( 1 )\n\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}\n\n\tprivate void assertAgentUUIDVersion(Session session, int expectedVersion) {\n\t\tassertThat(\n\t\t\t\tsession.createQuery(\n\t\t\t\t\t\t\t\t\"select a from \" + OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_NAME + \" a \",\n\t\t\t\t\t\t\t\tAgent.class\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.getResultList()\n\t\t).hasSizeGreaterThan( 0 )\n\t\t\t\t.extracting( Agent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}\n\n\tprivate Dialect getDialect() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getDialect();\n\t}\n\n\tprivate NameQualifierSupport getNameQualifierSupport() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getNameQualifierSupport();\n\t}\n\n\t@Entity(name = IndexedEntity.INDEX)\n\t@Indexed(index = IndexedEntity.INDEX)\n\tpublic static class IndexedEntity {\n\t\tstatic final String INDEX = \"IndexedEntity\";\n\n\t\t@Id\n\t\tprivate Integer id;\n\n\t\t@Basic\n\t\t@GenericField\n\t\tprivate String indexedField;\n\n\t\tpublic IndexedEntity() {\n\t\t}\n\n\t\tpublic IndexedEntity(Integer id, String indexedField) {\n\t\t\tthis.id = id;\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\n\t\tpublic Integer getId() {\n\t\t\treturn id;\n\t\t}\n\n\t\tpublic void setId(Integer id) {\n\t\t\tthis.id = id;\n\t\t}\n\n\t\tpublic String getIndexedField() {\n\t\t\treturn indexedField;\n\t\t}\n\n\t\tpublic void setIndexedField(String indexedField) {\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\t}\n\n\tpublic static class KeysStatementInspector implements StatementInspector {\n\n\t\tprivate Map<String, List<String>> sqlByKey = new HashMap<>();\n\n\t\tpublic KeysStatementInspector() {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tsqlByKey.put( key, new ArrayList<>() );\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic String inspect(String sql) {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tif ( Arrays.stream( sql.split( \"[^A-Za-z0-9_-]\" ) ).anyMatch( token -> key.equals( token ) ) ) {\n\t\t\t\t\tsqlByKey.get( key ).add( sql );\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sql;\n\t\t}\n\n\t\tpublic int countByKey(String key) {\n\t\t\treturn sqlByKey.get( key ).size();\n\t\t}\n\t}\n}\n", "diffSourceCodeSet": ["private void assertEventUUIDVersion(Session session, int expectedVersion) {\n\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\tassertThat( events )\n\t\t\t\t.hasSize( 1 )\n\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}"], "invokedMethodSet": ["methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#getId\n methodBody: public Integer getId() {\nreturn id;\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setIndexedField\n methodBody: public void setIndexedField(String indexedField) {\nthis.indexedField=indexedField;\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.KeysStatementInspector#countByKey\n methodBody: public int countByKey(String key) {\nreturn sqlByKey.get(key).size();\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setId\n methodBody: public void setId(Integer id) {\nthis.id=id;\n}"], "sourceCodeAfterRefactoring": "@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 1 );\n\t\t\t\tassertAgentUUIDVersion( session, 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\nprivate void assertEventUUIDVersion(Session session, int expectedVersion) {\n\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\tassertThat( events )\n\t\t\t\t.hasSize( 1 )\n\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}", "diffSourceCode": "-  268: \t}\n-  269: \n-  270: \t@Test\n-  271: \tpublic void validMappingWithCustomUuidGenerator() {\n-  272: \t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n-  273: \n-  274: \t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n-  275: \t\tsessionFactory = ormSetupHelper.start()\n-  276: \t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n-  277: \t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n-  278: \t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n-  279: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n-  280: \t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n-  281: \t\t\t\t.setup( IndexedEntity.class );\n-  282: \t\tbackendMock.verifyExpectationsMet();\n-  283: \n-  284: \t\tint id = 1;\n-  285: \t\twith( sessionFactory ).runInTransaction( session -> {\n-  286: \t\t\tIndexedEntity entity = new IndexedEntity();\n-  287: \t\t\tentity.setId( id );\n-  288: \t\t\tentity.setIndexedField( \"value for the field\" );\n-  289: \t\t\tsession.persist( entity );\n-  290: \n-  291: \t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n-  292: \t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n-  293: \t\t} );\n-  294: \n-  295: \t\tawait().untilAsserted( () -> {\n-  296: \t\t\twith( sessionFactory ).runInTransaction( session -> {\n-  297: \t\t\t\t// check that correct UUIDs are generated by asserting the version:\n-  298: \t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n-  299: \t\t\t\tassertThat( events )\n-  300: \t\t\t\t\t\t.hasSize( 1 )\n-  301: \t\t\t\t\t\t.extracting( OutboxEvent::getId )\n-  302: \t\t\t\t\t\t.extracting( UUID::version )\n-  303: \t\t\t\t\t\t.contains( 1 );\n-  304: \t\t\t} );\n-  305: \t\t} );\n-  306: \t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n-  307: \t\t// Make them visible to Hibernate Search now.\n-  308: \t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n-  309: \t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n-  310: \n-  311: \t\tbackendMock.verifyExpectationsMet();\n-  312: \n-  313: \t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n-  314: \t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n-  315: \t}\n-  373: \t\t).isInstanceOf( SearchException.class )\n-  374: \t\t\t\t.hasMessageContainingAll(\n-  375: \t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n-  376: \t\t\t\t\t\t\"something-incompatible\",\n-  377: \t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n-  378: \t\t\t\t);\n-  379: \t}\n-  380: \n+  268: \t@Test\n+  269: \tpublic void validMappingWithCustomUuidGenerator() {\n+  270: \t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n+  271: \n+  272: \t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n+  273: \t\tsessionFactory = ormSetupHelper.start()\n+  274: \t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n+  275: \t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n+  276: \t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n+  277: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.uuid_gen_strategy\", \"time\" )\n+  278: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n+  279: \t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n+  280: \t\t\t\t.setup( IndexedEntity.class );\n+  281: \t\tbackendMock.verifyExpectationsMet();\n+  282: \n+  283: \t\tint id = 1;\n+  284: \t\twith( sessionFactory ).runInTransaction( session -> {\n+  285: \t\t\tIndexedEntity entity = new IndexedEntity();\n+  286: \t\t\tentity.setId( id );\n+  287: \t\t\tentity.setIndexedField( \"value for the field\" );\n+  288: \t\t\tsession.persist( entity );\n+  289: \n+  290: \t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n+  291: \t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n+  292: \t\t} );\n+  293: \n+  294: \t\tawait().untilAsserted( () -> {\n+  295: \t\t\twith( sessionFactory ).runInTransaction( session -> {\n+  296: \t\t\t\t// check that correct UUIDs are generated by asserting the version:\n+  297: \t\t\t\tassertEventUUIDVersion( session, 1 );\n+  298: \t\t\t\tassertAgentUUIDVersion( session, 1 );\n+  299: \t\t\t} );\n+  300: \t\t} );\n+  301: \t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n+  302: \t\t// Make them visible to Hibernate Search now.\n+  303: \t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n+  304: \t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n+  305: \n+  306: \t\tbackendMock.verifyExpectationsMet();\n+  307: \n+  308: \t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n+  309: \t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n+  310: \t}\n+  311: \n+  312: \t@Test\n+  313: \tpublic void validMappingWithCustomUuidDataType() {\n+  314: \t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n+  315: \n+  373: \tprivate void assertEventUUIDVersion(Session session, int expectedVersion) {\n+  374: \t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n+  375: \t\tassertThat( events )\n+  376: \t\t\t\t.hasSize( 1 )\n+  377: \t\t\t\t.extracting( OutboxEvent::getId )\n+  378: \t\t\t\t.extracting( UUID::version )\n+  379: \t\t\t\t.containsOnly( expectedVersion );\n+  380: \t}\n", "uniqueId": "fe9d94f5875ba28017d584653e397cffe57d7555_270_315_373_380_268_310", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 17, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": true, "compileAndTestResult": false, "refactoredCode": "To improve the readability and maintainability of the `validMappingWithCustomUuidGenerator` method, we can extract the repeated logic into separate methods. This will help to reduce the complexity of the test method and make it easier to understand.\n\nHere\u2019s the refactored code with the extracted methods:\n\n```java\n@Test\npublic void validMappingWithCustomUuidGenerator() {\n    KeysStatementInspector statementInspector = new KeysStatementInspector();\n\n    setupSessionFactoryWithCustomUuidGenerator(statementInspector);\n\n    int id = 1;\n    persistIndexedEntity(id, \"value for the field\");\n\n    await().untilAsserted(() -> {\n        verifyGeneratedUuidVersion(1);\n    });\n\n    makeEventsVisible();\n\n    backendMock.verifyExpectationsMet();\n\n    assertThat(statementInspector.countByKey(ORIGINAL_OUTBOX_EVENT_TABLE_NAME)).isPositive();\n    assertThat(statementInspector.countByKey(ORIGINAL_AGENT_TABLE_NAME)).isPositive();\n}\n\nprivate void setupSessionFactoryWithCustomUuidGenerator(KeysStatementInspector statementInspector) {\n    backendMock.expectAnySchema(IndexedEntity.INDEX);\n    sessionFactory = ormSetupHelper.start()\n            .withProperty(\"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider())\n            .withProperty(\"javax.persistence.create-database-schemas\", true)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\")\n            .withProperty(\"hibernate.session_factory.statement_inspector\", statementInspector)\n            .setup(IndexedEntity.class);\n    backendMock.verifyExpectationsMet();\n}\n\nprivate void persistIndexedEntity(int id, String indexedFieldValue) {\n    with(sessionFactory).runInTransaction(session -> {\n        IndexedEntity entity = new IndexedEntity();\n        entity.setId(id);\n        entity.setIndexedField(indexedFieldValue);\n        session.persist(entity);\n\n        backendMock.expectWorks(IndexedEntity.INDEX)\n                .add(\"1\", f -> f.field(\"indexedField\", indexedFieldValue));\n    });\n}\n\nprivate void verifyGeneratedUuidVersion(int expectedVersion) {\n    with(sessionFactory).runInTransaction(session -> {\n        List<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter(session);\n        assertThat(events)\n                .hasSize(1)\n                .extracting(OutboxEvent::getId)\n                .extracting(UUID::version)\n                .contains(expectedVersion);\n    });\n}\n\nprivate void makeEventsVisible() {\n    outboxEventFinder.showAllEventsUpToNow(sessionFactory);\n    outboxEventFinder.awaitUntilNoMoreVisibleEvents(sessionFactory);\n}\n```\n\nThis refactoring extracts the setup of the session factory, the persistence of the indexed entity, the verification of the generated UUID version, and the visibility of events into separate methods. This makes the `validMappingWithCustomUuidGenerator` method cleaner and easier to read, while also promoting code reuse. \n\nHere\u2019s the output in the requested format:\n\n##########################\n```java\n@Test\npublic void validMappingWithCustomUuidGenerator() {\n    KeysStatementInspector statementInspector = new KeysStatementInspector();\n\n    setupSessionFactoryWithCustomUuidGenerator(statementInspector);\n\n    int id = 1;\n    persistIndexedEntity(id, \"value for the field\");\n\n    await().untilAsserted(() -> {\n        verifyGeneratedUuidVersion(1);\n    });\n\n    makeEventsVisible();\n\n    backendMock.verifyExpectationsMet();\n\n    assertThat(statementInspector.countByKey(ORIGINAL_OUTBOX_EVENT_TABLE_NAME)).isPositive();\n    assertThat(statementInspector.countByKey(ORIGINAL_AGENT_TABLE_NAME)).isPositive();\n}\n\nprivate void setupSessionFactoryWithCustomUuidGenerator(KeysStatementInspector statementInspector) {\n    backendMock.expectAnySchema(IndexedEntity.INDEX);\n    sessionFactory = ormSetupHelper.start()\n            .withProperty(\"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider())\n            .withProperty(\"javax.persistence.create-database-schemas\", true)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\")\n            .withProperty(\"hibernate.session_factory.statement_inspector\", statementInspector)\n            .setup(IndexedEntity.class);\n    backendMock.verifyExpectationsMet();\n}\n\nprivate void persistIndexedEntity(int id, String indexedFieldValue) {\n    with(sessionFactory).runInTransaction(session -> {\n        IndexedEntity entity = new IndexedEntity();\n        entity.setId(id);\n        entity.setIndexedField(indexedFieldValue);\n        session.persist(entity);\n\n        backendMock.expectWorks(IndexedEntity.INDEX)\n                .add(\"1\", f -> f.field(\"indexedField\", indexedFieldValue));\n    });\n}\n\nprivate void verifyGeneratedUuidVersion(int expectedVersion) {\n    with(sessionFactory).runInTransaction(session -> {\n        List<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter(session);\n        assertThat(events)\n                .hasSize(1)\n                .extracting(OutboxEvent::getId)\n                .extracting(UUID::version)\n                .contains(expectedVersion);\n    });\n}\n\nprivate void makeEventsVisible() {\n    outboxEventFinder.showAllEventsUpToNow(sessionFactory);\n    outboxEventFinder.awaitUntilNoMoreVisibleEvents(sessionFactory);\n}\n```\n##########################", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\n@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.assertThatThrownBy;\nimport static org.awaitility.Awaitility.await;\nimport static org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmUtils.with;\nimport static org.junit.Assume.assumeTrue;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport javax.persistence.Basic;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\n\nimport org.hibernate.SessionFactory;\nimport org.hibernate.boot.MappingException;\nimport org.hibernate.dialect.Dialect;\nimport org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;\nimport org.hibernate.engine.spi.SessionFactoryImplementor;\nimport org.hibernate.resource.jdbc.spi.StatementInspector;\nimport org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.FilteringOutboxEventFinder;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cfg.HibernateOrmMapperOutboxPollingSettings;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.OutboxPollingAgentAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxEvent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxPollingOutboxEventAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.GenericField;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.Indexed;\nimport org.hibernate.search.util.common.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.rule.BackendMock;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.CoordinationStrategyExpectations;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmSetupHelper;\n\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class OutboxPollingCustomEntityMappingIT {\n\n\tprivate static final String CUSTOM_SCHEMA = \"CUSTOM_SCHEMA\";\n\tprivate static final String ORIGINAL_OUTBOX_EVENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_OUTBOX_EVENT_TABLE;\n\tprivate static final String CUSTOM_OUTBOX_EVENT_TABLE_NAME = \"CUSTOM_OUTBOX_EVENT\";\n\n\tprivate static final String ORIGINAL_AGENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_AGENT_TABLE;\n\tprivate static final String CUSTOM_AGENT_TABLE_NAME = \"CUSTOM_AGENT\";\n\tprivate static final String VALID_OUTBOX_EVENT_MAPPING;\n\tprivate static final String VALID_AGENT_EVENT_MAPPING;\n\n\tprivate static final String[] SQL_KEYS;\n\n\tstatic {\n\t\tVALID_OUTBOX_EVENT_MAPPING = OutboxPollingOutboxEventAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME );\n\n\t\tVALID_AGENT_EVENT_MAPPING = OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME );\n\n\t\tSQL_KEYS = new String[] {\n\t\t\t\tORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME,\n\t\t\t\tORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME,\n\t\t\t\tCUSTOM_SCHEMA,\n\t\t};\n\t}\n\n\t@Rule\n\tpublic BackendMock backendMock = new BackendMock();\n\n\t@Rule\n\tpublic OrmSetupHelper ormSetupHelper = OrmSetupHelper.withBackendMock( backendMock )\n\t\t\t.coordinationStrategy( CoordinationStrategyExpectations.outboxPolling() );\n\n\tprivate SessionFactory sessionFactory;\n\n\tprivate final FilteringOutboxEventFinder outboxEventFinder = new FilteringOutboxEventFinder();\n\n\t@Test\n\tpublic void wrongOutboxEventMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void wrongAgentMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void validOutboxEventMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isZero();\n\t}\n\n\t@Test\n\tpublic void validAgentMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void conflictingAgentMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox polling agent configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void conflictingOutboxeventMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox event configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNames() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidDataType() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomFailingUuidGenerator() {\n\t\tassertThatThrownBy(\n\t\t\t\t() -> ormSetupHelper.start()\n\t\t\t\t\t\t.withProperty(\n\t\t\t\t\t\t\t\t\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\",\n\t\t\t\t\t\t\t\t\"something-incompatible\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.setup( IndexedEntity.class )\n\t\t).isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContainingAll(\n\t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n\t\t\t\t\t\t\"something-incompatible\",\n\t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n\t\t\t\t);\n\t}\n\n\tprivate Dialect getDialect() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getDialect();\n\t}\n\n\tprivate NameQualifierSupport getNameQualifierSupport() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getNameQualifierSupport();\n\t}\n\n\t@Entity(name = IndexedEntity.INDEX)\n\t@Indexed(index = IndexedEntity.INDEX)\n\tpublic static class IndexedEntity {\n\t\tstatic final String INDEX = \"IndexedEntity\";\n\n\t\t@Id\n\t\tprivate Integer id;\n\n\t\t@Basic\n\t\t@GenericField\n\t\tprivate String indexedField;\n\n\t\tpublic IndexedEntity() {\n\t\t}\n\n\t\tpublic IndexedEntity(Integer id, String indexedField) {\n\t\t\tthis.id = id;\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\n\t\tpublic Integer getId() {\n\t\t\treturn id;\n\t\t}\n\n\t\tpublic void setId(Integer id) {\n\t\t\tthis.id = id;\n\t\t}\n\n\t\tpublic String getIndexedField() {\n\t\t\treturn indexedField;\n\t\t}\n\n\t\tpublic void setIndexedField(String indexedField) {\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\t}\n\n\tpublic static class KeysStatementInspector implements StatementInspector {\n\n\t\tprivate Map<String, List<String>> sqlByKey = new HashMap<>();\n\n\t\tpublic KeysStatementInspector() {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tsqlByKey.put( key, new ArrayList<>() );\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic String inspect(String sql) {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tif ( Arrays.stream( sql.split( \"[^A-Za-z0-9_-]\" ) ).anyMatch( token -> key.equals( token ) ) ) {\n\t\t\t\t\tsqlByKey.get( key ).add( sql );\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sql;\n\t\t}\n\n\t\tpublic int countByKey(String key) {\n\t\t\treturn sqlByKey.get( key ).size();\n\t\t}\n\t}\n}\n\nRefactoring Operation:\nExtract Method\n\nInstructions:\n1. Analyze the provided code and class content, apply relevant refactoring operation to the code to be refactored.\n2. If refactoring is performed, output the refactored_method_code in the following format:\n##########################\nrefactored_method_code\n##########################\n\n\n\n"}, {"type": "Extract Method", "description": "Extract Method\tprivate assertEventUUIDVersion(session Session, expectedVersion int) : void extracted from public validMappingWithCustomNamesAndSchema() : void in class org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT", "diffLocations": [{"filePath": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "startLine": 212, "endLine": 268, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "startLine": 214, "endLine": 266, "startColumn": 0, "endColumn": 0}, {"filePath": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "startLine": 373, "endLine": 380, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}", "filePathBefore": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "isPureRefactoring": true, "commitId": "fe9d94f5875ba28017d584653e397cffe57d7555", "packageNameBefore": "org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing", "classNameBefore": "org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT", "methodNameBefore": "org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#validMappingWithCustomNamesAndSchema", "invokedMethod": "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#getId\n methodBody: public Integer getId() {\nreturn id;\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#getDialect\n methodBody: private Dialect getDialect() {\nreturn sessionFactory.unwrap(SessionFactoryImplementor.class).getJdbcServices().getJdbcEnvironment().getDialect();\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setIndexedField\n methodBody: public void setIndexedField(String indexedField) {\nthis.indexedField=indexedField;\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.KeysStatementInspector#countByKey\n methodBody: public int countByKey(String key) {\nreturn sqlByKey.get(key).size();\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setId\n methodBody: public void setId(Integer id) {\nthis.id=id;\n}\nmethodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#getNameQualifierSupport\n methodBody: private NameQualifierSupport getNameQualifierSupport() {\nreturn sessionFactory.unwrap(SessionFactoryImplementor.class).getJdbcServices().getJdbcEnvironment().getNameQualifierSupport();\n}", "classSignatureBefore": "public class OutboxPollingCustomEntityMappingIT ", "methodNameBeforeSet": ["org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#validMappingWithCustomNamesAndSchema"], "classNameBeforeSet": ["org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT"], "classSignatureBeforeSet": ["public class OutboxPollingCustomEntityMappingIT "], "purityCheckResultList": [{"isPure": true, "purityComment": "Changes are within the Extract Method refactoring mechanics", "description": "All replacements have been justified - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.assertThatThrownBy;\nimport static org.awaitility.Awaitility.await;\nimport static org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmUtils.with;\nimport static org.junit.Assume.assumeTrue;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport javax.persistence.Basic;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\n\nimport org.hibernate.SessionFactory;\nimport org.hibernate.boot.MappingException;\nimport org.hibernate.dialect.Dialect;\nimport org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;\nimport org.hibernate.engine.spi.SessionFactoryImplementor;\nimport org.hibernate.resource.jdbc.spi.StatementInspector;\nimport org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.FilteringOutboxEventFinder;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cfg.HibernateOrmMapperOutboxPollingSettings;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.OutboxPollingAgentAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxEvent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxPollingOutboxEventAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.GenericField;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.Indexed;\nimport org.hibernate.search.util.common.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.rule.BackendMock;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.CoordinationStrategyExpectations;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmSetupHelper;\n\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class OutboxPollingCustomEntityMappingIT {\n\n\tprivate static final String CUSTOM_SCHEMA = \"CUSTOM_SCHEMA\";\n\tprivate static final String ORIGINAL_OUTBOX_EVENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_OUTBOX_EVENT_TABLE;\n\tprivate static final String CUSTOM_OUTBOX_EVENT_TABLE_NAME = \"CUSTOM_OUTBOX_EVENT\";\n\n\tprivate static final String ORIGINAL_AGENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_AGENT_TABLE;\n\tprivate static final String CUSTOM_AGENT_TABLE_NAME = \"CUSTOM_AGENT\";\n\tprivate static final String VALID_OUTBOX_EVENT_MAPPING;\n\tprivate static final String VALID_AGENT_EVENT_MAPPING;\n\n\tprivate static final String[] SQL_KEYS;\n\n\tstatic {\n\t\tVALID_OUTBOX_EVENT_MAPPING = OutboxPollingOutboxEventAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME );\n\n\t\tVALID_AGENT_EVENT_MAPPING = OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME );\n\n\t\tSQL_KEYS = new String[] {\n\t\t\t\tORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME,\n\t\t\t\tORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME,\n\t\t\t\tCUSTOM_SCHEMA,\n\t\t};\n\t}\n\n\t@Rule\n\tpublic BackendMock backendMock = new BackendMock();\n\n\t@Rule\n\tpublic OrmSetupHelper ormSetupHelper = OrmSetupHelper.withBackendMock( backendMock )\n\t\t\t.coordinationStrategy( CoordinationStrategyExpectations.outboxPolling() );\n\n\tprivate SessionFactory sessionFactory;\n\n\tprivate final FilteringOutboxEventFinder outboxEventFinder = new FilteringOutboxEventFinder();\n\n\t@Test\n\tpublic void wrongOutboxEventMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void wrongAgentMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void validOutboxEventMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isZero();\n\t}\n\n\t@Test\n\tpublic void validAgentMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void conflictingAgentMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox polling agent configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void conflictingOutboxeventMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox event configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNames() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidDataType() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomFailingUuidGenerator() {\n\t\tassertThatThrownBy(\n\t\t\t\t() -> ormSetupHelper.start()\n\t\t\t\t\t\t.withProperty(\n\t\t\t\t\t\t\t\t\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\",\n\t\t\t\t\t\t\t\t\"something-incompatible\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.setup( IndexedEntity.class )\n\t\t).isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContainingAll(\n\t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n\t\t\t\t\t\t\"something-incompatible\",\n\t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n\t\t\t\t);\n\t}\n\n\tprivate Dialect getDialect() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getDialect();\n\t}\n\n\tprivate NameQualifierSupport getNameQualifierSupport() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getNameQualifierSupport();\n\t}\n\n\t@Entity(name = IndexedEntity.INDEX)\n\t@Indexed(index = IndexedEntity.INDEX)\n\tpublic static class IndexedEntity {\n\t\tstatic final String INDEX = \"IndexedEntity\";\n\n\t\t@Id\n\t\tprivate Integer id;\n\n\t\t@Basic\n\t\t@GenericField\n\t\tprivate String indexedField;\n\n\t\tpublic IndexedEntity() {\n\t\t}\n\n\t\tpublic IndexedEntity(Integer id, String indexedField) {\n\t\t\tthis.id = id;\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\n\t\tpublic Integer getId() {\n\t\t\treturn id;\n\t\t}\n\n\t\tpublic void setId(Integer id) {\n\t\t\tthis.id = id;\n\t\t}\n\n\t\tpublic String getIndexedField() {\n\t\t\treturn indexedField;\n\t\t}\n\n\t\tpublic void setIndexedField(String indexedField) {\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\t}\n\n\tpublic static class KeysStatementInspector implements StatementInspector {\n\n\t\tprivate Map<String, List<String>> sqlByKey = new HashMap<>();\n\n\t\tpublic KeysStatementInspector() {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tsqlByKey.put( key, new ArrayList<>() );\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic String inspect(String sql) {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tif ( Arrays.stream( sql.split( \"[^A-Za-z0-9_-]\" ) ).anyMatch( token -> key.equals( token ) ) ) {\n\t\t\t\t\tsqlByKey.get( key ).add( sql );\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sql;\n\t\t}\n\n\t\tpublic int countByKey(String key) {\n\t\t\treturn sqlByKey.get( key ).size();\n\t\t}\n\t}\n}\n", "filePathAfter": "integrationtest/mapper/orm-coordination-outbox-polling/src/test/java/org/hibernate/search/integrationtest/mapper/orm/coordination/outboxpolling/automaticindexing/OutboxPollingCustomEntityMappingIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.assertThatThrownBy;\nimport static org.awaitility.Awaitility.await;\nimport static org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmUtils.with;\nimport static org.junit.Assume.assumeTrue;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport javax.persistence.Basic;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\n\nimport org.hibernate.Session;\nimport org.hibernate.SessionFactory;\nimport org.hibernate.boot.MappingException;\nimport org.hibernate.dialect.Dialect;\nimport org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;\nimport org.hibernate.engine.spi.SessionFactoryImplementor;\nimport org.hibernate.resource.jdbc.spi.StatementInspector;\nimport org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.FilteringOutboxEventFinder;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cfg.HibernateOrmMapperOutboxPollingSettings;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.Agent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.OutboxPollingAgentAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxEvent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxPollingOutboxEventAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.GenericField;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.Indexed;\nimport org.hibernate.search.util.common.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.rule.BackendMock;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.CoordinationStrategyExpectations;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmSetupHelper;\n\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class OutboxPollingCustomEntityMappingIT {\n\n\tprivate static final String CUSTOM_SCHEMA = \"CUSTOM_SCHEMA\";\n\tprivate static final String ORIGINAL_OUTBOX_EVENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_OUTBOX_EVENT_TABLE;\n\tprivate static final String CUSTOM_OUTBOX_EVENT_TABLE_NAME = \"CUSTOM_OUTBOX_EVENT\";\n\n\tprivate static final String ORIGINAL_AGENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_AGENT_TABLE;\n\tprivate static final String CUSTOM_AGENT_TABLE_NAME = \"CUSTOM_AGENT\";\n\tprivate static final String VALID_OUTBOX_EVENT_MAPPING;\n\tprivate static final String VALID_AGENT_EVENT_MAPPING;\n\n\tprivate static final String[] SQL_KEYS;\n\n\tstatic {\n\t\tVALID_OUTBOX_EVENT_MAPPING = OutboxPollingOutboxEventAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME );\n\n\t\tVALID_AGENT_EVENT_MAPPING = OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME );\n\n\t\tSQL_KEYS = new String[] {\n\t\t\t\tORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME,\n\t\t\t\tORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME,\n\t\t\t\tCUSTOM_SCHEMA,\n\t\t};\n\t}\n\n\t@Rule\n\tpublic BackendMock backendMock = new BackendMock();\n\n\t@Rule\n\tpublic OrmSetupHelper ormSetupHelper = OrmSetupHelper.withBackendMock( backendMock )\n\t\t\t.coordinationStrategy( CoordinationStrategyExpectations.outboxPolling() );\n\n\tprivate SessionFactory sessionFactory;\n\n\tprivate final FilteringOutboxEventFinder outboxEventFinder = new FilteringOutboxEventFinder();\n\n\t@Test\n\tpublic void wrongOutboxEventMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void wrongAgentMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void validOutboxEventMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isZero();\n\t}\n\n\t@Test\n\tpublic void validAgentMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void conflictingAgentMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox polling agent configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void conflictingOutboxeventMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox event configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNames() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 4 );\n\t\t\t\tassertAgentUUIDVersion( session, 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 1 );\n\t\t\t\tassertAgentUUIDVersion( session, 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidDataType() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 4 );\n\t\t\t\tassertAgentUUIDVersion( session, 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomFailingUuidGenerator() {\n\t\tassertThatThrownBy(\n\t\t\t\t() -> ormSetupHelper.start()\n\t\t\t\t\t\t.withProperty(\n\t\t\t\t\t\t\t\t\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\",\n\t\t\t\t\t\t\t\t\"something-incompatible\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.setup( IndexedEntity.class )\n\t\t).isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContainingAll(\n\t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n\t\t\t\t\t\t\"something-incompatible\",\n\t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n\t\t\t\t);\n\t}\n\n\tprivate void assertEventUUIDVersion(Session session, int expectedVersion) {\n\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\tassertThat( events )\n\t\t\t\t.hasSize( 1 )\n\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}\n\n\tprivate void assertAgentUUIDVersion(Session session, int expectedVersion) {\n\t\tassertThat(\n\t\t\t\tsession.createQuery(\n\t\t\t\t\t\t\t\t\"select a from \" + OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_NAME + \" a \",\n\t\t\t\t\t\t\t\tAgent.class\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.getResultList()\n\t\t).hasSizeGreaterThan( 0 )\n\t\t\t\t.extracting( Agent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}\n\n\tprivate Dialect getDialect() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getDialect();\n\t}\n\n\tprivate NameQualifierSupport getNameQualifierSupport() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getNameQualifierSupport();\n\t}\n\n\t@Entity(name = IndexedEntity.INDEX)\n\t@Indexed(index = IndexedEntity.INDEX)\n\tpublic static class IndexedEntity {\n\t\tstatic final String INDEX = \"IndexedEntity\";\n\n\t\t@Id\n\t\tprivate Integer id;\n\n\t\t@Basic\n\t\t@GenericField\n\t\tprivate String indexedField;\n\n\t\tpublic IndexedEntity() {\n\t\t}\n\n\t\tpublic IndexedEntity(Integer id, String indexedField) {\n\t\t\tthis.id = id;\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\n\t\tpublic Integer getId() {\n\t\t\treturn id;\n\t\t}\n\n\t\tpublic void setId(Integer id) {\n\t\t\tthis.id = id;\n\t\t}\n\n\t\tpublic String getIndexedField() {\n\t\t\treturn indexedField;\n\t\t}\n\n\t\tpublic void setIndexedField(String indexedField) {\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\t}\n\n\tpublic static class KeysStatementInspector implements StatementInspector {\n\n\t\tprivate Map<String, List<String>> sqlByKey = new HashMap<>();\n\n\t\tpublic KeysStatementInspector() {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tsqlByKey.put( key, new ArrayList<>() );\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic String inspect(String sql) {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tif ( Arrays.stream( sql.split( \"[^A-Za-z0-9_-]\" ) ).anyMatch( token -> key.equals( token ) ) ) {\n\t\t\t\t\tsqlByKey.get( key ).add( sql );\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sql;\n\t\t}\n\n\t\tpublic int countByKey(String key) {\n\t\t\treturn sqlByKey.get( key ).size();\n\t\t}\n\t}\n}\n", "diffSourceCodeSet": ["private void assertEventUUIDVersion(Session session, int expectedVersion) {\n\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\tassertThat( events )\n\t\t\t\t.hasSize( 1 )\n\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}"], "invokedMethodSet": ["methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#getId\n methodBody: public Integer getId() {\nreturn id;\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#getDialect\n methodBody: private Dialect getDialect() {\nreturn sessionFactory.unwrap(SessionFactoryImplementor.class).getJdbcServices().getJdbcEnvironment().getDialect();\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setIndexedField\n methodBody: public void setIndexedField(String indexedField) {\nthis.indexedField=indexedField;\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.KeysStatementInspector#countByKey\n methodBody: public int countByKey(String key) {\nreturn sqlByKey.get(key).size();\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT.IndexedEntity#setId\n methodBody: public void setId(Integer id) {\nthis.id=id;\n}", "methodSignature: org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing.OutboxPollingCustomEntityMappingIT#getNameQualifierSupport\n methodBody: private NameQualifierSupport getNameQualifierSupport() {\nreturn sessionFactory.unwrap(SessionFactoryImplementor.class).getJdbcServices().getJdbcEnvironment().getNameQualifierSupport();\n}"], "sourceCodeAfterRefactoring": "@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tassertEventUUIDVersion( session, 4 );\n\t\t\t\tassertAgentUUIDVersion( session, 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\nprivate void assertEventUUIDVersion(Session session, int expectedVersion) {\n\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\tassertThat( events )\n\t\t\t\t.hasSize( 1 )\n\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t.extracting( UUID::version )\n\t\t\t\t.containsOnly( expectedVersion );\n\t}", "diffSourceCode": "-  212: \t@Test\n-  213: \tpublic void validMappingWithCustomNamesAndSchema() {\n-  214: \t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n-  215: \n-  216: \t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n-  217: \t\tsessionFactory = ormSetupHelper.start()\n-  218: \t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n-  219: \t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n-  220: \t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n-  221: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n-  222: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n-  223: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n-  224: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n-  225: \t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n-  226: \t\t\t\t.setup( IndexedEntity.class );\n-  227: \t\tbackendMock.verifyExpectationsMet();\n-  228: \n-  229: \t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n-  230: \t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n-  231: \t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n-  232: \t\t\t\tgetDialect().canCreateSchema() );\n-  233: \n-  234: \t\tint id = 1;\n-  235: \t\twith( sessionFactory ).runInTransaction( session -> {\n-  236: \t\t\tIndexedEntity entity = new IndexedEntity();\n-  237: \t\t\tentity.setId( id );\n-  238: \t\t\tentity.setIndexedField( \"value for the field\" );\n-  239: \t\t\tsession.persist( entity );\n-  240: \n-  241: \t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n-  242: \t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n-  243: \t\t} );\n-  244: \t\tawait().untilAsserted( () -> {\n-  245: \t\t\twith( sessionFactory ).runInTransaction( session -> {\n-  246: \t\t\t\t// check that correct UUIDs are generated by asserting the version:\n-  247: \t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n-  248: \t\t\t\tassertThat( events )\n-  249: \t\t\t\t\t\t.hasSize( 1 )\n-  250: \t\t\t\t\t\t.extracting( OutboxEvent::getId )\n-  251: \t\t\t\t\t\t.extracting( UUID::version )\n-  252: \t\t\t\t\t\t.contains( 4 );\n-  253: \t\t\t} );\n-  254: \t\t} );\n-  255: \t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n-  256: \t\t// Make them visible to Hibernate Search now.\n-  257: \t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n-  258: \t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n+  212: \t}\n+  213: \n+  214: \t@Test\n+  215: \tpublic void validMappingWithCustomNamesAndSchema() {\n+  216: \t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n+  217: \n+  218: \t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n+  219: \t\tsessionFactory = ormSetupHelper.start()\n+  220: \t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n+  221: \t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n+  222: \t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n+  223: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n+  224: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n+  225: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n+  226: \t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n+  227: \t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n+  228: \t\t\t\t.setup( IndexedEntity.class );\n+  229: \t\tbackendMock.verifyExpectationsMet();\n+  230: \n+  231: \t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n+  232: \t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n+  233: \t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n+  234: \t\t\t\tgetDialect().canCreateSchema() );\n+  235: \n+  236: \t\tint id = 1;\n+  237: \t\twith( sessionFactory ).runInTransaction( session -> {\n+  238: \t\t\tIndexedEntity entity = new IndexedEntity();\n+  239: \t\t\tentity.setId( id );\n+  240: \t\t\tentity.setIndexedField( \"value for the field\" );\n+  241: \t\t\tsession.persist( entity );\n+  242: \n+  243: \t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n+  244: \t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n+  245: \t\t} );\n+  246: \t\tawait().untilAsserted( () -> {\n+  247: \t\t\twith( sessionFactory ).runInTransaction( session -> {\n+  248: \t\t\t\t// check that correct UUIDs are generated by asserting the version:\n+  249: \t\t\t\tassertEventUUIDVersion( session, 4 );\n+  250: \t\t\t\tassertAgentUUIDVersion( session, 4 );\n+  251: \t\t\t} );\n+  252: \t\t} );\n+  253: \t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n+  254: \t\t// Make them visible to Hibernate Search now.\n+  255: \t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n+  256: \t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n+  257: \n+  258: \t\tbackendMock.verifyExpectationsMet();\n   259: \n-  260: \t\tbackendMock.verifyExpectationsMet();\n-  261: \n-  262: \t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n-  263: \t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n-  264: \t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n-  265: \t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n-  266: \n-  267: \t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n-  268: \t}\n-  373: \t\t).isInstanceOf( SearchException.class )\n-  374: \t\t\t\t.hasMessageContainingAll(\n-  375: \t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n-  376: \t\t\t\t\t\t\"something-incompatible\",\n-  377: \t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n-  378: \t\t\t\t);\n-  379: \t}\n-  380: \n+  260: \t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n+  261: \t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n+  262: \t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n+  263: \t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n+  264: \n+  265: \t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n+  266: \t}\n+  267: \n+  268: \t@Test\n+  373: \tprivate void assertEventUUIDVersion(Session session, int expectedVersion) {\n+  374: \t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n+  375: \t\tassertThat( events )\n+  376: \t\t\t\t.hasSize( 1 )\n+  377: \t\t\t\t.extracting( OutboxEvent::getId )\n+  378: \t\t\t\t.extracting( UUID::version )\n+  379: \t\t\t\t.containsOnly( expectedVersion );\n+  380: \t}\n", "uniqueId": "fe9d94f5875ba28017d584653e397cffe57d7555_212_268_373_380_214_266", "moveFileExist": true, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 17, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "To improve the readability and maintainability of the `validMappingWithCustomNamesAndSchema` method, we can extract the repeated setup logic into a separate method. This will help reduce duplication and make the test method more concise.\n\nHere's the refactored code:\n\n```java\n@Test\npublic void validMappingWithCustomNamesAndSchema() {\n    KeysStatementInspector statementInspector = new KeysStatementInspector();\n\n    setupSessionFactoryWithCustomNamesAndSchema(statementInspector);\n\n    assumeTrue(\"This test only makes sense if the database supports schemas\",\n            getNameQualifierSupport().supportsSchemas());\n    assumeTrue(\"This test only makes sense if the dialect supports creating schemas\",\n            getDialect().canCreateSchema());\n\n    int id = 1;\n    with(sessionFactory).runInTransaction(session -> {\n        IndexedEntity entity = new IndexedEntity();\n        entity.setId(id);\n        entity.setIndexedField(\"value for the field\");\n        session.persist(entity);\n\n        backendMock.expectWorks(IndexedEntity.INDEX)\n                .add(\"1\", f -> f.field(\"indexedField\", \"value for the field\"));\n    });\n    await().untilAsserted(() -> {\n        with(sessionFactory).runInTransaction(session -> {\n            // check that correct UUIDs are generated by asserting the version:\n            List<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter(session);\n            assertThat(events)\n                    .hasSize(1)\n                    .extracting(OutboxEvent::getId)\n                    .extracting(UUID::version)\n                    .contains(4);\n        });\n    });\n    // The events were hidden until now, to ensure they were not processed in separate batches.\n    // Make them visible to Hibernate Search now.\n    outboxEventFinder.showAllEventsUpToNow(sessionFactory);\n    outboxEventFinder.awaitUntilNoMoreVisibleEvents(sessionFactory);\n\n    backendMock.verifyExpectationsMet();\n\n    assertThat(statementInspector.countByKey(ORIGINAL_OUTBOX_EVENT_TABLE_NAME)).isZero();\n    assertThat(statementInspector.countByKey(CUSTOM_OUTBOX_EVENT_TABLE_NAME)).isPositive();\n    assertThat(statementInspector.countByKey(ORIGINAL_AGENT_TABLE_NAME)).isZero();\n    assertThat(statementInspector.countByKey(CUSTOM_AGENT_TABLE_NAME)).isPositive();\n\n    assertThat(statementInspector.countByKey(CUSTOM_SCHEMA)).isPositive();\n}\n\nprivate void setupSessionFactoryWithCustomNamesAndSchema(KeysStatementInspector statementInspector) {\n    backendMock.expectAnySchema(IndexedEntity.INDEX);\n    sessionFactory = ormSetupHelper.start()\n            .withProperty(\"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider())\n            // Allow ORM to create schema as we want to use non-default for this testcase:\n            .withProperty(\"javax.persistence.create-database-schemas\", true)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME)\n            .withProperty(\"hibernate.session_factory.statement_inspector\", statementInspector)\n            .setup(IndexedEntity.class);\n    backendMock.verifyExpectationsMet();\n}\n```\n\nThe extracted method `setupSessionFactoryWithCustomNamesAndSchema` encapsulates the logic for setting up the session factory with the custom names and schema properties. This makes the `validMappingWithCustomNamesAndSchema` method cleaner and easier to read.\n\nHere is the output in the requested format:\n\n##########################\n```java\nprivate void setupSessionFactoryWithCustomNamesAndSchema(KeysStatementInspector statementInspector) {\n    backendMock.expectAnySchema(IndexedEntity.INDEX);\n    sessionFactory = ormSetupHelper.start()\n            .withProperty(\"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider())\n            // Allow ORM to create schema as we want to use non-default for this testcase:\n            .withProperty(\"javax.persistence.create-database-schemas\", true)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA)\n            .withProperty(\"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME)\n            .withProperty(\"hibernate.session_factory.statement_inspector\", statementInspector)\n            .setup(IndexedEntity.class);\n    backendMock.verifyExpectationsMet();\n}\n```\n##########################", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\n@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.automaticindexing;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.assertThatThrownBy;\nimport static org.awaitility.Awaitility.await;\nimport static org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmUtils.with;\nimport static org.junit.Assume.assumeTrue;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport javax.persistence.Basic;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\n\nimport org.hibernate.SessionFactory;\nimport org.hibernate.boot.MappingException;\nimport org.hibernate.dialect.Dialect;\nimport org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;\nimport org.hibernate.engine.spi.SessionFactoryImplementor;\nimport org.hibernate.resource.jdbc.spi.StatementInspector;\nimport org.hibernate.search.integrationtest.mapper.orm.coordination.outboxpolling.FilteringOutboxEventFinder;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cfg.HibernateOrmMapperOutboxPollingSettings;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.cluster.impl.OutboxPollingAgentAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxEvent;\nimport org.hibernate.search.mapper.orm.coordination.outboxpolling.event.impl.OutboxPollingOutboxEventAdditionalJaxbMappingProducer;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.GenericField;\nimport org.hibernate.search.mapper.pojo.mapping.definition.annotation.Indexed;\nimport org.hibernate.search.util.common.SearchException;\nimport org.hibernate.search.util.impl.integrationtest.common.rule.BackendMock;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.CoordinationStrategyExpectations;\nimport org.hibernate.search.util.impl.integrationtest.mapper.orm.OrmSetupHelper;\n\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class OutboxPollingCustomEntityMappingIT {\n\n\tprivate static final String CUSTOM_SCHEMA = \"CUSTOM_SCHEMA\";\n\tprivate static final String ORIGINAL_OUTBOX_EVENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_OUTBOX_EVENT_TABLE;\n\tprivate static final String CUSTOM_OUTBOX_EVENT_TABLE_NAME = \"CUSTOM_OUTBOX_EVENT\";\n\n\tprivate static final String ORIGINAL_AGENT_TABLE_NAME = HibernateOrmMapperOutboxPollingSettings.Defaults.COORDINATION_ENTITY_MAPPING_AGENT_TABLE;\n\tprivate static final String CUSTOM_AGENT_TABLE_NAME = \"CUSTOM_AGENT\";\n\tprivate static final String VALID_OUTBOX_EVENT_MAPPING;\n\tprivate static final String VALID_AGENT_EVENT_MAPPING;\n\n\tprivate static final String[] SQL_KEYS;\n\n\tstatic {\n\t\tVALID_OUTBOX_EVENT_MAPPING = OutboxPollingOutboxEventAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME );\n\n\t\tVALID_AGENT_EVENT_MAPPING = OutboxPollingAgentAdditionalJaxbMappingProducer.ENTITY_DEFINITION\n\t\t\t\t.replace( ORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME );\n\n\t\tSQL_KEYS = new String[] {\n\t\t\t\tORIGINAL_OUTBOX_EVENT_TABLE_NAME, CUSTOM_OUTBOX_EVENT_TABLE_NAME,\n\t\t\t\tORIGINAL_AGENT_TABLE_NAME, CUSTOM_AGENT_TABLE_NAME,\n\t\t\t\tCUSTOM_SCHEMA,\n\t\t};\n\t}\n\n\t@Rule\n\tpublic BackendMock backendMock = new BackendMock();\n\n\t@Rule\n\tpublic OrmSetupHelper ormSetupHelper = OrmSetupHelper.withBackendMock( backendMock )\n\t\t\t.coordinationStrategy( CoordinationStrategyExpectations.outboxPolling() );\n\n\tprivate SessionFactory sessionFactory;\n\n\tprivate final FilteringOutboxEventFinder outboxEventFinder = new FilteringOutboxEventFinder();\n\n\t@Test\n\tpublic void wrongOutboxEventMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void wrongAgentMapping() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", \"<entity-mappings><ciao></ciao></entity-mappings>\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( MappingException.class )\n\t\t\t\t.hasMessageContainingAll( \"Unable to perform unmarshalling\", \"unexpected element\" );\n\t}\n\n\t@Test\n\tpublic void validOutboxEventMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isZero();\n\t}\n\n\t@Test\n\tpublic void validAgentMapping() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void conflictingAgentMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.agent.entity.mapping\", VALID_AGENT_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox polling agent configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void conflictingOutboxeventMappingConfiguration() {\n\t\tassertThatThrownBy( () -> ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outboxevent.entity.mapping\", VALID_OUTBOX_EVENT_MAPPING )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", \"break_it_all\" )\n\t\t\t\t.setup( IndexedEntity.class ) )\n\t\t\t\t.isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContaining( \"Outbox event configuration property conflict.\" );\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNames() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomNamesAndSchema() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.agent.table\", CUSTOM_AGENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.schema\", CUSTOM_SCHEMA )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.table\", CUSTOM_OUTBOX_EVENT_TABLE_NAME )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassumeTrue( \"This test only makes sense if the database supports schemas\",\n\t\t\t\tgetNameQualifierSupport().supportsSchemas() );\n\t\tassumeTrue( \"This test only makes sense if the dialect supports creating schemas\",\n\t\t\t\tgetDialect().canCreateSchema() );\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isZero();\n\t\tassertThat( statementInspector.countByKey( CUSTOM_AGENT_TABLE_NAME ) ).isPositive();\n\n\t\tassertThat( statementInspector.countByKey( CUSTOM_SCHEMA ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidGenerator() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\", \"time\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 1 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomUuidDataType() {\n\t\tKeysStatementInspector statementInspector = new KeysStatementInspector();\n\n\t\tbackendMock.expectAnySchema( IndexedEntity.INDEX );\n\t\tsessionFactory = ormSetupHelper.start()\n\t\t\t\t.withProperty( \"hibernate.search.coordination.outbox_event_finder.provider\", outboxEventFinder.provider() )\n\t\t\t\t// Allow ORM to create schema as we want to use non-default for this testcase:\n\t\t\t\t.withProperty( \"javax.persistence.create-database-schemas\", true )\n\t\t\t\t.withProperty( \"hibernate.search.coordination.entity.mapping.outboxevent.uuid_jdbc_type\", \"uuid-char\" )\n\t\t\t\t.withProperty( \"hibernate.session_factory.statement_inspector\", statementInspector )\n\t\t\t\t.setup( IndexedEntity.class );\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tint id = 1;\n\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\tIndexedEntity entity = new IndexedEntity();\n\t\t\tentity.setId( id );\n\t\t\tentity.setIndexedField( \"value for the field\" );\n\t\t\tsession.persist( entity );\n\n\t\t\tbackendMock.expectWorks( IndexedEntity.INDEX )\n\t\t\t\t\t.add( \"1\", f -> f.field( \"indexedField\", \"value for the field\" ) );\n\t\t} );\n\n\t\tawait().untilAsserted( () -> {\n\t\t\twith( sessionFactory ).runInTransaction( session -> {\n\t\t\t\t// check that correct UUIDs are generated by asserting the version:\n\t\t\t\tList<OutboxEvent> events = outboxEventFinder.findOutboxEventsNoFilter( session );\n\t\t\t\tassertThat( events )\n\t\t\t\t\t\t.hasSize( 1 )\n\t\t\t\t\t\t.extracting( OutboxEvent::getId )\n\t\t\t\t\t\t.extracting( UUID::version )\n\t\t\t\t\t\t.contains( 4 );\n\t\t\t} );\n\t\t} );\n\t\t// The events were hidden until now, to ensure they were not processed in separate batches.\n\t\t// Make them visible to Hibernate Search now.\n\t\toutboxEventFinder.showAllEventsUpToNow( sessionFactory );\n\t\toutboxEventFinder.awaitUntilNoMoreVisibleEvents( sessionFactory );\n\n\t\tbackendMock.verifyExpectationsMet();\n\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_OUTBOX_EVENT_TABLE_NAME ) ).isPositive();\n\t\tassertThat( statementInspector.countByKey( ORIGINAL_AGENT_TABLE_NAME ) ).isPositive();\n\t}\n\n\t@Test\n\tpublic void validMappingWithCustomFailingUuidGenerator() {\n\t\tassertThatThrownBy(\n\t\t\t\t() -> ormSetupHelper.start()\n\t\t\t\t\t\t.withProperty(\n\t\t\t\t\t\t\t\t\"hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy\",\n\t\t\t\t\t\t\t\t\"something-incompatible\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.setup( IndexedEntity.class )\n\t\t).isInstanceOf( SearchException.class )\n\t\t\t\t.hasMessageContainingAll(\n\t\t\t\t\t\t\"Invalid value for configuration property 'hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy'\",\n\t\t\t\t\t\t\"something-incompatible\",\n\t\t\t\t\t\t\"Valid names are: [auto, random, time]\"\n\t\t\t\t);\n\t}\n\n\tprivate Dialect getDialect() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getDialect();\n\t}\n\n\tprivate NameQualifierSupport getNameQualifierSupport() {\n\t\treturn sessionFactory.unwrap( SessionFactoryImplementor.class ).getJdbcServices()\n\t\t\t\t.getJdbcEnvironment().getNameQualifierSupport();\n\t}\n\n\t@Entity(name = IndexedEntity.INDEX)\n\t@Indexed(index = IndexedEntity.INDEX)\n\tpublic static class IndexedEntity {\n\t\tstatic final String INDEX = \"IndexedEntity\";\n\n\t\t@Id\n\t\tprivate Integer id;\n\n\t\t@Basic\n\t\t@GenericField\n\t\tprivate String indexedField;\n\n\t\tpublic IndexedEntity() {\n\t\t}\n\n\t\tpublic IndexedEntity(Integer id, String indexedField) {\n\t\t\tthis.id = id;\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\n\t\tpublic Integer getId() {\n\t\t\treturn id;\n\t\t}\n\n\t\tpublic void setId(Integer id) {\n\t\t\tthis.id = id;\n\t\t}\n\n\t\tpublic String getIndexedField() {\n\t\t\treturn indexedField;\n\t\t}\n\n\t\tpublic void setIndexedField(String indexedField) {\n\t\t\tthis.indexedField = indexedField;\n\t\t}\n\t}\n\n\tpublic static class KeysStatementInspector implements StatementInspector {\n\n\t\tprivate Map<String, List<String>> sqlByKey = new HashMap<>();\n\n\t\tpublic KeysStatementInspector() {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tsqlByKey.put( key, new ArrayList<>() );\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic String inspect(String sql) {\n\t\t\tfor ( String key : SQL_KEYS ) {\n\t\t\t\tif ( Arrays.stream( sql.split( \"[^A-Za-z0-9_-]\" ) ).anyMatch( token -> key.equals( token ) ) ) {\n\t\t\t\t\tsqlByKey.get( key ).add( sql );\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sql;\n\t\t}\n\n\t\tpublic int countByKey(String key) {\n\t\t\treturn sqlByKey.get( key ).size();\n\t\t}\n\t}\n}\n\nRefactoring Operation:\nExtract Method\n\nInstructions:\n1. Analyze the provided code and class content, apply relevant refactoring operation to the code to be refactored.\n2. If refactoring is performed, output the refactored_method_code in the following format:\n##########################\nrefactored_method_code\n##########################\n\n\n\n"}, {"type": "Move Method", "description": "Move Method\tpublic mappingContainsExpectedEntities() : void from class org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurerIT to public mappingContainsExpectedEntities() : void from class org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoEntryPointsIT", "diffLocations": [{"filePath": "documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/StandalonePojoConfigurerIT.java", "startLine": 60, "endLine": 66, "startColumn": 0, "endColumn": 0}, {"filePath": "documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/StandalonePojoEntryPointsIT.java", "startLine": 72, "endLine": 78, "startColumn": 0, "endColumn": 0}], "sourceCodeBeforeRefactoring": "@Test\n\tpublic void mappingContainsExpectedEntities() {\n\t\tassertThat( theSearchMapping.allIndexedEntities() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n\t\t;\n\t}", "filePathBefore": "documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/StandalonePojoConfigurerIT.java", "isPureRefactoring": true, "commitId": "2b1681e3aa7954b7bc13ca4a75761f30d915b03a", "packageNameBefore": "org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints", "classNameBefore": "org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurerIT", "methodNameBefore": "org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurerIT#mappingContainsExpectedEntities", "classSignatureBefore": "public class StandalonePojoConfigurerIT ", "methodNameBeforeSet": ["org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurerIT#mappingContainsExpectedEntities"], "classNameBeforeSet": ["org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurerIT"], "classSignatureBeforeSet": ["public class StandalonePojoConfigurerIT "], "purityCheckResultList": [{"isPure": true, "purityComment": "Identical statements", "description": "There is no replacement! - all mapped", "mappingState": 1}], "sourceCodeBeforeForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport org.hibernate.search.documentation.testsupport.BackendConfigurations;\nimport org.hibernate.search.documentation.testsupport.TestConfiguration;\nimport org.hibernate.search.mapper.pojo.standalone.entity.SearchIndexedEntity;\nimport org.hibernate.search.mapper.pojo.standalone.mapping.CloseableSearchMapping;\nimport org.hibernate.search.mapper.pojo.standalone.mapping.SearchMapping;\nimport org.hibernate.search.util.impl.integrationtest.common.TestConfigurationProvider;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class StandalonePojoConfigurerIT {\n\n\tprivate CloseableSearchMapping theSearchMapping;\n\n\t@Rule\n\tpublic TestConfigurationProvider configurationProvider = new TestConfigurationProvider();\n\n\t@Before\n\tpublic void setup() {\n\t\t// tag::setup[]\n\t\tCloseableSearchMapping searchMapping = SearchMapping.builder() // <1>\n\t\t\t\t.property(\n\t\t\t\t\t\t\"hibernate.search.mapping.configurer\", // <2>\n\t\t\t\t\t\t\"class:org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurer\"\n\t\t\t\t)\n\t\t\t\t.property(\n\t\t\t\t\t\t\"hibernate.search.backend.hosts\", // <3>\n\t\t\t\t\t\t\"elasticsearch.mycompany.com\"\n\t\t\t\t).property( \"hibernate.search.mapping.multi_tenancy.enabled\", true )\n\t\t\t\t// end::setup[]\n\t\t\t\t.properties( TestConfiguration.standalonePojoMapperProperties(\n\t\t\t\t\t\tconfigurationProvider,\n\t\t\t\t\t\tBackendConfigurations.simple()\n\t\t\t\t) )\n\t\t\t\t// tag::setup[]\n\t\t\t\t.build(); // <4>\n\t\t// end::setup[]\n\t\tthis.theSearchMapping = searchMapping;\n\t}\n\n\t@After\n\tpublic void cleanup() {\n\t\tif ( theSearchMapping != null ) {\n\t\t\ttheSearchMapping.close();\n\t\t}\n\t}\n\n\t@Test\n\tpublic void mappingContainsExpectedEntities() {\n\t\tassertThat( theSearchMapping.allIndexedEntities() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n\t\t;\n\t}\n}\n", "filePathAfter": "documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/StandalonePojoEntryPointsIT.java", "sourceCodeAfterForWhole": "/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport java.util.Arrays;\n\nimport org.hibernate.search.documentation.testsupport.BackendConfigurations;\nimport org.hibernate.search.documentation.testsupport.TestConfiguration;\nimport org.hibernate.search.engine.backend.work.execution.DocumentCommitStrategy;\nimport org.hibernate.search.engine.backend.work.execution.DocumentRefreshStrategy;\nimport org.hibernate.search.mapper.pojo.standalone.entity.SearchIndexedEntity;\nimport org.hibernate.search.mapper.pojo.standalone.mapping.CloseableSearchMapping;\nimport org.hibernate.search.mapper.pojo.standalone.mapping.SearchMapping;\nimport org.hibernate.search.mapper.pojo.standalone.scope.SearchScope;\nimport org.hibernate.search.mapper.pojo.standalone.session.SearchSession;\nimport org.hibernate.search.util.impl.integrationtest.common.TestConfigurationProvider;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class StandalonePojoEntryPointsIT {\n\n\tprivate CloseableSearchMapping theSearchMapping;\n\n\t@Rule\n\tpublic TestConfigurationProvider configurationProvider = new TestConfigurationProvider();\n\n\t@Before\n\tpublic void setup() {\n\t\t// tag::setup[]\n\t\tCloseableSearchMapping searchMapping = SearchMapping.builder() // <1>\n\t\t\t\t.property(\n\t\t\t\t\t\t\"hibernate.search.mapping.configurer\", // <2>\n\t\t\t\t\t\t\"class:org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurer\"\n\t\t\t\t)\n\t\t\t\t.property(\n\t\t\t\t\t\t\"hibernate.search.backend.hosts\", // <3>\n\t\t\t\t\t\t\"elasticsearch.mycompany.com\"\n\t\t\t\t)\n\t\t\t\t// end::setup[]\n\t\t\t\t.properties( TestConfiguration.standalonePojoMapperProperties(\n\t\t\t\t\t\tconfigurationProvider,\n\t\t\t\t\t\tBackendConfigurations.simple()\n\t\t\t\t) )\n\t\t\t\t// tag::setup[]\n\t\t\t\t.build(); // <4>\n\t\t// end::setup[]\n\t\tthis.theSearchMapping = searchMapping;\n\t}\n\n\t@After\n\tpublic void cleanup() {\n\t\tif ( theSearchMapping != null ) {\n\t\t\t// tag::shutdown[]\n\t\t\tCloseableSearchMapping searchMapping = /* ... */ // <1>\n\t\t\t\t\t// end::shutdown[]\n\t\t\t\t\ttheSearchMapping;\n\t\t\t// tag::shutdown[]\n\t\t\tsearchMapping.close(); // <2>\n\t\t\t// end::shutdown[]\n\t\t}\n\t}\n\n\t@Test\n\tpublic void mappingContainsExpectedEntities() {\n\t\tassertThat( theSearchMapping.allIndexedEntities() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n\t\t;\n\t}\n\n\t@Test\n\tpublic void searchSession() {\n\t\t// tag::searchSession-simple[]\n\t\tSearchMapping searchMapping = /* ... */ // <1>\n\t\t\t\t// end::searchSession-simple[]\n\t\t\t\ttheSearchMapping;\n\t\t// tag::searchSession-simple[]\n\t\ttry ( SearchSession searchSession = searchMapping.createSession() ) { // <2>\n\t\t\t// ...\n\t\t\t// end::searchSession-simple[]\n\t\t\tassertThat( searchSession ).isNotNull();\n\t\t\tassertThat( searchSession.isOpen() ).isTrue();\n\t\t\t// tag::searchSession-simple[]\n\t\t}\n\t\t// end::searchSession-simple[]\n\t}\n\n\t@Test\n\tpublic void searchSession_withOptions() {\n\t\t// tag::searchSession-withOptions[]\n\t\tSearchMapping searchMapping = /* ... */ // <1>\n\t\t\t\t// end::searchSession-withOptions[]\n\t\t\t\ttheSearchMapping;\n\t\t// tag::searchSession-withOptions[]\n\t\ttry ( SearchSession searchSession = searchMapping.createSessionWithOptions() // <2>\n\t\t\t\t.commitStrategy( DocumentCommitStrategy.FORCE ) // <3>\n\t\t\t\t.refreshStrategy( DocumentRefreshStrategy.FORCE )\n\t\t\t\t.tenantId( \"myTenant\" )\n\t\t\t\t.build() ) { // <4>\n\t\t\t// ...\n\t\t\t// end::searchSession-withOptions[]\n\t\t\tassertThat( searchSession ).isNotNull();\n\t\t\tassertThat( searchSession.isOpen() ).isTrue();\n\t\t\t// tag::searchSession-withOptions[]\n\t\t}\n\t\t// end::searchSession-withOptions[]\n\t}\n\n\t@Test\n\tpublic void searchScope_fromSearchMapping() {\n\t\tSearchMapping searchMapping = theSearchMapping;\n\t\t// tag::searchScope-fromSearchMapping[]\n\t\tSearchScope<Book> bookScope = searchMapping.scope( Book.class );\n\t\tSearchScope<Person> associateAndManagerScope = searchMapping.scope( Arrays.asList( Associate.class, Manager.class ) );\n\t\tSearchScope<Person> personScope = searchMapping.scope( Person.class );\n\t\tSearchScope<Object> allScope = searchMapping.scope( Object.class );\n\t\t// end::searchScope-fromSearchMapping[]\n\t\tassertThat( bookScope.includedTypes() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.containsExactlyInAnyOrder( \"Book\" );\n\t\tassertThat( associateAndManagerScope.includedTypes() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.containsExactlyInAnyOrder( \"Manager\", \"Associate\" );\n\t\tassertThat( personScope.includedTypes() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.containsExactlyInAnyOrder( \"Manager\", \"Associate\" );\n\t\tassertThat( allScope.includedTypes() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.containsExactlyInAnyOrder( \"Book\", \"Manager\", \"Associate\" );\n\t}\n\n\t@Test\n\tpublic void searchScope_fromSearchSession() {\n\t\tSearchMapping searchMapping = theSearchMapping;\n\t\ttry ( SearchSession searchSession = searchMapping.createSession() ) {\n\t\t\tSearchScope<Book> bookScope = searchSession.scope( Book.class );\n\t\t\tSearchScope<Person> associateAndManagerScope = searchSession.scope( Arrays.asList( Associate.class, Manager.class ) );\n\t\t\tSearchScope<Person> personScope = searchSession.scope( Person.class );\n\t\t\tSearchScope<Object> allScope = searchSession.scope( Object.class );\n\t\t\t// end::searchScope-fromSearchSession[]\n\t\t\tassertThat( bookScope.includedTypes() )\n\t\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t\t.containsExactlyInAnyOrder( \"Book\" );\n\t\t\tassertThat( associateAndManagerScope.includedTypes() )\n\t\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t\t.containsExactlyInAnyOrder( \"Manager\", \"Associate\" );\n\t\t\tassertThat( personScope.includedTypes() )\n\t\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t\t.containsExactlyInAnyOrder( \"Manager\", \"Associate\" );\n\t\t\tassertThat( allScope.includedTypes() )\n\t\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t\t.containsExactlyInAnyOrder( \"Book\", \"Manager\", \"Associate\" );\n\t\t}\n\t}\n\n}\n", "diffSourceCodeSet": [], "invokedMethodSet": [], "sourceCodeAfterRefactoring": "@Test\n\tpublic void mappingContainsExpectedEntities() {\n\t\tassertThat( theSearchMapping.allIndexedEntities() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n\t\t;\n\t}", "diffSourceCode": "-   60: \t@Test\n-   61: \tpublic void mappingContainsExpectedEntities() {\n-   62: \t\tassertThat( theSearchMapping.allIndexedEntities() )\n-   63: \t\t\t\t.extracting( SearchIndexedEntity::name )\n-   64: \t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n-   65: \t\t;\n-   66: \t}\n+   60: \tpublic void cleanup() {\n+   61: \t\tif ( theSearchMapping != null ) {\n+   62: \t\t\t// tag::shutdown[]\n+   63: \t\t\tCloseableSearchMapping searchMapping = /* ... */ // <1>\n+   64: \t\t\t\t\t// end::shutdown[]\n+   65: \t\t\t\t\ttheSearchMapping;\n+   66: \t\t\t// tag::shutdown[]\n+   72: \t@Test\n+   73: \tpublic void mappingContainsExpectedEntities() {\n+   74: \t\tassertThat( theSearchMapping.allIndexedEntities() )\n+   75: \t\t\t\t.extracting( SearchIndexedEntity::name )\n+   76: \t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n+   77: \t\t;\n+   78: \t}\n", "uniqueId": "2b1681e3aa7954b7bc13ca4a75761f30d915b03a_60_66__72_78", "moveFileExist": true, "testResult": true, "coverageInfo": {"testMethod": {"missed": 0, "covered": 1}}, "compileResultBefore": true, "compileResultCurrent": true, "compileJDK": 17, "refactoringMinerResult": false, "compileAndTestResult": false, "refactoredCode": "To perform the requested refactoring, we will move the `mappingContainsExpectedEntities` method from the `StandalonePojoConfigurerIT` class to an existing test utility class. Given the project structure, it seems appropriate to move this method to a test support class, such as `TestConfiguration`, which is already present in the project.\n\n### Target File Path\nThe target file path for the moved method will be:\n```\ndocumentation/src/test/java/org/hibernate/search/documentation/testsupport/TestConfiguration.java\n```\n\n### Moved Class Code\nWe will add the `mappingContainsExpectedEntities` method as a public static method in the `TestConfiguration` class. Here is the code that will be added:\n\n```java\npublic static void assertMappingContainsExpectedEntities(CloseableSearchMapping searchMapping) {\n    assertThat(searchMapping.allIndexedEntities())\n            .extracting(SearchIndexedEntity::name)\n            .contains(\"Book\", \"Associate\", \"Manager\");\n}\n```\n\n### Refactored Method Code\nWe will update the `StandalonePojoConfigurerIT` class to call the newly moved method. Here is the refactored method code:\n\n```java\n@Test\npublic void mappingContainsExpectedEntities() {\n    TestConfiguration.assertMappingContainsExpectedEntities(theSearchMapping);\n}\n```\n\n### Final Output\nHere is the complete output in the requested format:\n\n##########################\ndocumentation/src/test/java/org/hibernate/search/documentation/testsupport/TestConfiguration.java\n##########################\npublic static void assertMappingContainsExpectedEntities(CloseableSearchMapping searchMapping) {\n    assertThat(searchMapping.allIndexedEntities())\n            .extracting(SearchIndexedEntity::name)\n            .contains(\"Book\", \"Associate\", \"Manager\");\n}\n##########################\n@Test\npublic void mappingContainsExpectedEntities() {\n    TestConfiguration.assertMappingContainsExpectedEntities(theSearchMapping);\n}\n##########################", "prompt": "Task: You are an expert software engineer. You are given a code to be refactored. The objective is to refactor this code by performing given refactoring operation. This refactoring will improve code readability, maintainability, and modularity.\n\nCode to be Refactored:\n@Test\n\tpublic void mappingContainsExpectedEntities() {\n\t\tassertThat( theSearchMapping.allIndexedEntities() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n\t\t;\n\t}\n\nClass content:\n/*\n * Hibernate Search, full-text search for your domain model\n *\n * License: GNU Lesser General Public License (LGPL), version 2.1 or later\n * See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.\n */\npackage org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport org.hibernate.search.documentation.testsupport.BackendConfigurations;\nimport org.hibernate.search.documentation.testsupport.TestConfiguration;\nimport org.hibernate.search.mapper.pojo.standalone.entity.SearchIndexedEntity;\nimport org.hibernate.search.mapper.pojo.standalone.mapping.CloseableSearchMapping;\nimport org.hibernate.search.mapper.pojo.standalone.mapping.SearchMapping;\nimport org.hibernate.search.util.impl.integrationtest.common.TestConfigurationProvider;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\n\npublic class StandalonePojoConfigurerIT {\n\n\tprivate CloseableSearchMapping theSearchMapping;\n\n\t@Rule\n\tpublic TestConfigurationProvider configurationProvider = new TestConfigurationProvider();\n\n\t@Before\n\tpublic void setup() {\n\t\t// tag::setup[]\n\t\tCloseableSearchMapping searchMapping = SearchMapping.builder() // <1>\n\t\t\t\t.property(\n\t\t\t\t\t\t\"hibernate.search.mapping.configurer\", // <2>\n\t\t\t\t\t\t\"class:org.hibernate.search.documentation.mapper.pojo.standalone.entrypoints.StandalonePojoConfigurer\"\n\t\t\t\t)\n\t\t\t\t.property(\n\t\t\t\t\t\t\"hibernate.search.backend.hosts\", // <3>\n\t\t\t\t\t\t\"elasticsearch.mycompany.com\"\n\t\t\t\t).property( \"hibernate.search.mapping.multi_tenancy.enabled\", true )\n\t\t\t\t// end::setup[]\n\t\t\t\t.properties( TestConfiguration.standalonePojoMapperProperties(\n\t\t\t\t\t\tconfigurationProvider,\n\t\t\t\t\t\tBackendConfigurations.simple()\n\t\t\t\t) )\n\t\t\t\t// tag::setup[]\n\t\t\t\t.build(); // <4>\n\t\t// end::setup[]\n\t\tthis.theSearchMapping = searchMapping;\n\t}\n\n\t@After\n\tpublic void cleanup() {\n\t\tif ( theSearchMapping != null ) {\n\t\t\ttheSearchMapping.close();\n\t\t}\n\t}\n\n\t@Test\n\tpublic void mappingContainsExpectedEntities() {\n\t\tassertThat( theSearchMapping.allIndexedEntities() )\n\t\t\t\t.extracting( SearchIndexedEntity::name )\n\t\t\t\t.contains( \"Book\", \"Associate\", \"Manager\" )\n\t\t;\n\t}\n}\n\nRefactoring Operation:\nMove Method\n\nProject Structure:\n['documentation/src/test/java/org/hibernate/search/documentation/analysis/AdvancedElasticsearchAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/AdvancedLuceneAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/AnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/CustomSimilarityLuceneAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/DefaultOverridingElasticsearchAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/DefaultOverridingLuceneAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/ElasticsearchAnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/LuceneAnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/LuceneClassesAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/MyElasticsearchAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/analysis/MyLuceneAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/client/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/client/ElasticsearchGetClientIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/client/ElasticsearchHttpClientConfigurerIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/client/HttpClientConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/indexmanager/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/indexmanager/ElasticsearchIndexManagerIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/layout/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/layout/CustomLayoutStrategy.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/layout/ElasticsearchCustomLayoutStrategyIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/layout/MyApplicationClock.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/mapping/ElasticsearchCustomIndexMappingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/setting/ElasticsearchCustomIndexSettingsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/type/asnative/CompanyServer.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/type/asnative/ElasticsearchNativeTypeIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/elasticsearch/type/asnative/IpAddressValueBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/analyzer/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/analyzer/LuceneGetAnalyzerIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/indexmanager/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/indexmanager/LuceneGetIndexSizeIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/lowlevel/LuceneLowLevelIndexReaderIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/type/asnative/LuceneNativeTypeIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/type/asnative/PageRankValueBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/backend/lucene/type/asnative/WebPage.java', 'documentation/src/test/java/org/hibernate/search/documentation/configuration/ElasticsearchConfigurationIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/alternative/alternativebinder/AlternativeBinderIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/alternative/alternativebinder/BlogEntry.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/alternative/alternativebinder/Language.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/alternative/alternativebinder/LanguageAlternativeBinderDelegate.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/alternative/alternativebinder/MultiLanguageField.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/fromotherentity/DependenciesFromOtherEntityIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/fromotherentity/ScientificPaper.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/fromotherentity/ScientificPapersReferencedByBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/property/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/property/BookEdition.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/property/BookEditionsForSalePropertyBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/property/DependenciesContainersPropertyIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/simple/BookEdition.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/simple/BookEditionsForSaleTypeBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/containers/simple/DependenciesContainersSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/simple/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/simple/AuthorFullNameBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/dependencies/simple/DependenciesSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/dynamic/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/dynamic/DocumentModelDslDynamicIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/dynamic/MultiTypeUserMetadataBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/dynamic/UserMetadataBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/object/DocumentModelDslObjectIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/object/Invoice.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/object/InvoiceLineItem.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/object/InvoiceLineItemCategory.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/object/InvoiceLineItemsDetailBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/object/InvoiceLineItemsSummaryBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/simple/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/simple/DocumentModelDslSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/simple/ISBNBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/simple/MultiValuedNamesBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/document/model/dsl/simple/SingleValuedNamesBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/binder/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/binder/BookId.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/binder/BookIdBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/binder/IdentifierBinderIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/compatible/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/compatible/BookOrMagazineId.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/compatible/BookOrMagazineIdBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/compatible/IdentifierBridgeCompatibleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/compatible/Magazine.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/ormcontext/IdentifierBridgeOrmContextIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/ormcontext/MyData.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/ormcontext/MyDataIdentifierBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/ormcontext/MyEntity.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/IdentifierBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/OffsetDocumentId.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/OffsetIdentifierBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/context/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/context/IdentifierBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/param/context/OffsetIdentifierBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/simple/BookId.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/simple/BookIdBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/identifierbridge/simple/IdentifierBridgeSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/namedpredicate/ItemStock.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/namedpredicate/NamedPredicateIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/namedpredicate/SkuIdentifierBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/bridgedelement/Invoice.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/bridgedelement/InvoiceLineItemsSummaryBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/bridgedelement/PropertyBridgeBridgedElementIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/ormcontext/MyData.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/ormcontext/MyDataPropertyBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/ormcontext/MyEntity.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/ormcontext/PropertyBridgeOrmContextIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/Invoice.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/InvoiceLineItem.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/InvoiceLineItemCategory.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/InvoiceLineItemsSummaryBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/InvoiceLineItemsSummaryBinding.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/PropertyBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/context/Invoice.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/context/InvoiceLineItemsSummaryBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/param/context/PropertyBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/simple/Invoice.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/simple/InvoiceLineItem.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/simple/InvoiceLineItemCategory.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/simple/InvoiceLineItemsSummaryBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/propertybridge/simple/PropertyBridgeSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/BridgeResolverIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/EnumLabelBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/EnumLabelService.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/Genre.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/ISBNValueBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/MyCoordinates.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/MyCoordinatesBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/MyDefaultBridgesConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/MyProductId.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/resolver/MyProductIdBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/conditionalindexing/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/conditionalindexing/BookStatusRoutingBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/conditionalindexing/RoutingBridgeConditionalIndexingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/conditionalindexing/Status.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/ormcontext/MyData.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/ormcontext/MyEntity.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/ormcontext/MyEntityRoutingBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/ormcontext/RoutingBridgeOrmContextIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/routingkey/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/routingkey/BookGenreRoutingBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/routingkey/Genre.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/routingbridge/routingkey/RoutingBridgeRoutingKeyIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/ormcontext/MyData.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/ormcontext/MyEntity.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/ormcontext/MyEntityTypeBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/ormcontext/TypeBridgeOrmContextIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/FullNameBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/FullNameBinding.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/TypeBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/context/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/context/FullNameBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/param/context/TypeBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/simple/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/simple/FullNameBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/typebridge/simple/TypeBridgeSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/dslconverter/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/dslconverter/ISBNBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/dslconverter/IndexFieldTypeDslDslConverterIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/projectionconverter/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/projectionconverter/ISBNBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/projectionconverter/IndexFieldTypeDslProjectionConverterIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/simple/ISBNBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/types/dsl/simple/IndexFieldTypeDslSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/binder/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/binder/ISBNValueBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/binder/ValueBridgeBinderIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/compatible/Book1.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/compatible/Book2.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/compatible/ISBNValueBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/compatible/ValueBridgeCompatibleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/indexnullas/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/indexnullas/ISBNValueBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/indexnullas/ValueBridgeIndexNullAsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/ormcontext/MyData.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/ormcontext/MyDataValueBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/ormcontext/MyEntity.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/ormcontext/ValueBridgeOrmContextIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/BooleanAsStringBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/BooleanAsStringField.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/ValueBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/context/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/context/BooleanAsStringBinder.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/param/context/ValueBridgeParamIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/projection/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/projection/ISBNValueBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/projection/ValueBridgeProjectionIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/simple/ISBNValueBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/bridge/valuebridge/simple/ValueBridgeSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/containerextractor/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/containerextractor/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/containerextractor/BookFormat.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/containerextractor/ContainerExtractorIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/containerextractor/MyCollectionSizeBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/directfieldmapping/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/directfieldmapping/HibernateOrmSimpleMappingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entityindexmapping/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entityindexmapping/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entityindexmapping/HibernateOrmIndexedIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entityindexmapping/User.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entrypoints/Associate.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entrypoints/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entrypoints/HibernateOrmEntryPointsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entrypoints/Manager.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/entrypoints/Person.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/customanalysis/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/customanalysis/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/customanalysis/GettingStartedCustomAnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/customanalysis/MyElasticsearchAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/customanalysis/MyLuceneAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/defaultanalysis/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/defaultanalysis/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withouthsearch/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withouthsearch/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/gettingstarted/withouthsearch/GettingStartedWithoutHibernateSearchIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/identifiermapping/customtype/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/identifiermapping/customtype/ISBNIdentifierBridge.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/identifiermapping/customtype/IdentifierMappingCustomTypeIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/identifiermapping/naturalid/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/identifiermapping/naturalid/IdentifierMappingNaturalIdIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/filteredassociation/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/filteredassociation/BookEdition.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/filteredassociation/FilteredAssociationIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/includepaths/Human.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/includepaths/IndexedEmbeddedIncludePathsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/includepathsanddepth/Human.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/includepathsanddepth/IndexedEmbeddedIncludePathsAndDepthIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/none/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/none/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/none/IndexedEmbeddedNoneIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/onelevel/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/onelevel/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/onelevel/IndexedEmbeddedOneLevelIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/structure/flattened/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/structure/flattened/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/structure/flattened/IndexedEmbeddedStructureFlattenedIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/structure/nested/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/structure/nested/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/structure/nested/IndexedEmbeddedStructureNestedIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/twolevels/Address.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/twolevels/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/twolevels/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedembedded/twolevels/IndexedEmbeddedTwoLevelsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedentities/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexedentities/SearchMappingIndexedEntitiesIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexing/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexing/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmAutomaticIndexingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmBatchJsr352IT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmManualIndexingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmMassIndexerIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/programmatic/simple/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/programmatic/simple/MySearchMappingConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/programmatic/simple/ProgrammaticMappingSimpleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/associationinverseside/AssociationInverseSideIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/associationinverseside/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/associationinverseside/BookEdition.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/derivedfrom/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/derivedfrom/DerivedFromIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/no/correct/ReindexOnUpdateNoIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/no/correct/Sensor.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/no/correct/SensorStatus.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/no/incorrect/ReindexOnUpdateNoIncorrectIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/no/incorrect/Sensor.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/no/incorrect/SensorStatus.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/shallow/correct/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/shallow/correct/BookCategory.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/shallow/correct/ReindexOnUpdateShallowIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/shallow/incorrect/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/shallow/incorrect/BookCategory.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/reindexing/reindexonupdate/shallow/incorrect/ReindexOnUpdateShallowIncorrectIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/schema/management/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/schema/management/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/schema/management/HibernateOrmSchemaManagerIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/genericfield/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/genericfield/GeoPointGenericFieldIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/genericfield/MyCoordinates.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/multiple/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/multiple/GeoPointBindingMultipleIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/property/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/property/GeoPointBindingPropertyIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/property/MyCoordinates.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/type/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/orm/spatial/geopointbinding/type/GeoPointBindingTypeIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/Associate.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/Manager.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/Person.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/StandalonePojoConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/entrypoints/StandalonePojoEntryPointsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/customanalysis/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/customanalysis/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/customanalysis/GettingStartedCustomAnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/customanalysis/MyElasticsearchAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/customanalysis/MyLuceneAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/defaultanalysis/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/defaultanalysis/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withouthsearch/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/gettingstarted/withouthsearch/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/MyMassLoadingStrategy.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/MySelectionLoadingStrategy.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/StandalonePojoMassLoadingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/StandalonePojoSelectionLoadingIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/mydatastore/MyDatastore.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/mydatastore/MyDatastoreConnection.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/loading/mydatastore/MyDatastoreCursor.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/mapping/config/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/mapping/config/MappingConfigurationIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/mapping/config/MySearchMappingConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/multitenancy/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/mapper/pojo/standalone/multitenancy/StandalonePojoMultiTenancyIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/reporting/failurehandler/FailureHandlerIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/reporting/failurehandler/MyFailureHandler.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/aggregation/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/aggregation/BookEdition.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/aggregation/ElasticsearchAggregationDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/aggregation/Genre.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/converter/DslConverterIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/converter/ProjectionConverterIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/paths/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/paths/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/paths/FieldPathsIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/Address.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/ElasticsearchPredicateDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/EmbeddableGeoPoint.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/Genre.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/LucenePredicateDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/ElasticsearchProjectionDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/EmbeddableGeoPoint.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/Genre.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/LuceneProjectionDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/Associate.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/ElasticsearchQueryDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/LuceneQueryDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/Manager.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/Person.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/query/QueryDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/Author.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/Book.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/ElasticsearchSortDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/EmbeddableGeoPoint.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/Genre.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/LuceneSortDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/search/sort/SortDslIT.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/BackendConfigurations.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/DocumentationElasticsearchBackendConfiguration.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/DocumentationLuceneBackendConfiguration.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/DocumentationSetupHelper.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/ElasticsearchSimpleMappingAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/LuceneSimpleMappingAnalysisConfigurer.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/TestConfiguration.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/data/ISBN.java', 'documentation/src/test/java/org/hibernate/search/documentation/testsupport/data/ISBNAttributeConverter.java', 'documentation/src/test/java17/org/hibernate/search/documentation/mapper/orm/projection/Author.java', 'documentation/src/test/java17/org/hibernate/search/documentation/mapper/orm/projection/Book.java', 'documentation/src/test/java17/org/hibernate/search/documentation/mapper/orm/projection/MyAuthorProjectionClassMultiConstructor.java', 'documentation/src/test/java17/org/hibernate/search/documentation/mapper/orm/projection/MyAuthorProjectionRecordMultiConstructor.java', 'documentation/src/test/java17/org/hibernate/search/documentation/mapper/orm/projection/MyBookProjection.java', 'documentation/src/test/java17/org/hibernate/search/documentation/mapper/orm/projection/ProjectionConstructorMappingJava17IT.java', 'documentation/src/test/java17/org/hibernate/search/documentation/search/projection/MyAuthorProjection.java', 'documentation/src/test/java17/org/hibernate/search/documentation/search/projection/MyBookProjection.java', 'documentation/src/test/java17/org/hibernate/search/documentation/search/projection/ProjectionDslJava17IT.java']\n\nInstructions:\n1. Analyze the provided code, class content, and project structure, apply move method refactoring to the code to be refactored, output the target file path, moved class code, and refactored method code.\nNeed to move to an existing java file\nThe moved method code should be updated to the public static method.\nThe refactored method code should use the moved class to call the moved method.\nThe target file path should be the path of the existing class where the method is moved to.\n\n2. If refactoring is performed, output the target file path, moved class code, and refactored method code in the following format:\n##########################\ntarget_file_path\n##########################\nmoved_class_code\n##########################\nrefactored_method_code\n##########################\n\n\n\n"}]